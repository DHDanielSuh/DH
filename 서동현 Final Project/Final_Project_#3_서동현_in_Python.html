<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>Final Project #3_서동현</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#9635;-&#48708;&#51592;&#45768;&#49828;-&#45936;&#51060;&#53552;&#47560;&#51060;&#45789;-FINAL-EXAM">&#9635; &#48708;&#51592;&#45768;&#49828; &#45936;&#51060;&#53552;&#47560;&#51060;&#45789; FINAL EXAM<a class="anchor-link" href="#&#9635;-&#48708;&#51592;&#45768;&#49828;-&#45936;&#51060;&#53552;&#47560;&#51060;&#45789;-FINAL-EXAM">&#182;</a></h1><h3 id="&#47928;&#51228;-3">&#47928;&#51228; 3<a class="anchor-link" href="#&#47928;&#51228;-3">&#182;</a></h3><h3 id="&#47785;&#54364;:-&#44397;&#54924;-&#51032;&#50896;&#46308;&#51032;-Ideo_self-&#44050;-&#50696;&#52769;">&#47785;&#54364;: &#44397;&#54924; &#51032;&#50896;&#46308;&#51032; Ideo_self &#44050; &#50696;&#52769;<a class="anchor-link" href="#&#47785;&#54364;:-&#44397;&#54924;-&#51032;&#50896;&#46308;&#51032;-Ideo_self-&#44050;-&#50696;&#52769;">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#49324;&#50857;&#54620;-Data-set:-data1.csv">&#49324;&#50857;&#54620; Data set: data1.csv<a class="anchor-link" href="#&#49324;&#50857;&#54620;-Data-set:-data1.csv">&#182;</a></h3><h3 id="Ideo_self-&#50640;-NA-&#44050;&#51060;-&#51080;&#45716;-&#45936;&#51060;&#53552;&#47484;-Test-set&#51004;&#47196;-&#48372;&#44256;-&#45208;&#47672;&#51648;-&#45936;&#51060;&#53552;&#47484;-Train-set&#51004;&#47196;-&#48372;&#50520;&#45796;.--Train-set&#51012;-&#53685;&#54644;-&#47784;&#45944;&#46308;&#51012;-&#54617;&#49845;&#49884;&#53412;&#44256;-&#54617;&#49845;&#54620;-&#47784;&#45944;&#51012;-&#53664;&#45824;&#47196;-Test-set&#51032;-Ideo_self-&#44050;&#51012;-&#52628;&#51221;&#54644;-&#48372;&#50520;&#45796;.">Ideo_self &#50640; NA &#44050;&#51060; &#51080;&#45716; &#45936;&#51060;&#53552;&#47484; Test set&#51004;&#47196; &#48372;&#44256; &#45208;&#47672;&#51648; &#45936;&#51060;&#53552;&#47484; Train set&#51004;&#47196; &#48372;&#50520;&#45796;.  Train set&#51012; &#53685;&#54644; &#47784;&#45944;&#46308;&#51012; &#54617;&#49845;&#49884;&#53412;&#44256; &#54617;&#49845;&#54620; &#47784;&#45944;&#51012; &#53664;&#45824;&#47196; Test set&#51032; Ideo_self &#44050;&#51012; &#52628;&#51221;&#54644; &#48372;&#50520;&#45796;.<a class="anchor-link" href="#Ideo_self-&#50640;-NA-&#44050;&#51060;-&#51080;&#45716;-&#45936;&#51060;&#53552;&#47484;-Test-set&#51004;&#47196;-&#48372;&#44256;-&#45208;&#47672;&#51648;-&#45936;&#51060;&#53552;&#47484;-Train-set&#51004;&#47196;-&#48372;&#50520;&#45796;.--Train-set&#51012;-&#53685;&#54644;-&#47784;&#45944;&#46308;&#51012;-&#54617;&#49845;&#49884;&#53412;&#44256;-&#54617;&#49845;&#54620;-&#47784;&#45944;&#51012;-&#53664;&#45824;&#47196;-Test-set&#51032;-Ideo_self-&#44050;&#51012;-&#52628;&#51221;&#54644;-&#48372;&#50520;&#45796;.">&#182;</a></h3><p>다음 모델들의 테스트 성능을 비교해 본다.</p>
<ol>
<li>Logistic regression</li>
<li>k-nearest neighbor classifier</li>
<li>naive Bayes classifier</li>
<li>Decision tree</li>
<li>Random forest</li>
<li>SVM</li>
<li>Xgboost</li>
<li>SoftMax</li>
<li>Keras + Relu + SoftMax</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="0.-Data-preprocessing">0. Data preprocessing<a class="anchor-link" href="#0.-Data-preprocessing">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[374]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[375]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data1.xlsx&#39;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[376]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[376]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>281.0</th>
      <td>1012.0</td>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>393.0</th>
      <td>556.0</td>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>604.0</th>
      <td>642.0</td>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>956.0</th>
      <td>403.0</td>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>212.0</th>
      <td>776.0</td>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ID-column-&#50526;&#50640;-&#51080;&#45716;-&#44050;&#46308;&#51008;-&#45800;&#49692;-index-&#44050;&#51060;&#48064;&#47196;-ID-column&#51012;-&#49352;&#47196;&#50868;-index&#47484;-&#44050;&#51004;&#47196;-&#48148;&#45012;&#51456;&#45796;.">ID column &#50526;&#50640; &#51080;&#45716; &#44050;&#46308;&#51008; &#45800;&#49692; index &#44050;&#51060;&#48064;&#47196; ID column&#51012; &#49352;&#47196;&#50868; index&#47484; &#44050;&#51004;&#47196; &#48148;&#45012;&#51456;&#45796;.<a class="anchor-link" href="#ID-column-&#50526;&#50640;-&#51080;&#45716;-&#44050;&#46308;&#51008;-&#45800;&#49692;-index-&#44050;&#51060;&#48064;&#47196;-ID-column&#51012;-&#49352;&#47196;&#50868;-index&#47484;-&#44050;&#51004;&#47196;-&#48148;&#45012;&#51456;&#45796;.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[377]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># data = data.set_index(&quot;id&quot;).sort_index()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[378]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[378]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>767.0</th>
      <td>1.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>594.0</th>
      <td>1.0</td>
      <td>1982.0</td>
      <td>34.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>869.0</th>
      <td>1.0</td>
      <td>1965.0</td>
      <td>51.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>719.0</th>
      <td>1.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>783.0</th>
      <td>1.0</td>
      <td>1956.0</td>
      <td>60.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>8.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-&#45236;&#50640;-&#47784;&#46304;-column-&#44050;&#51060;-NA&#51064;-&#44050;&#51012;-&#44152;&#47084;&#51456;&#45796;.">Data &#45236;&#50640; &#47784;&#46304; column &#44050;&#51060; NA&#51064; &#44050;&#51012; &#44152;&#47084;&#51456;&#45796;.<a class="anchor-link" href="#Data-&#45236;&#50640;-&#47784;&#46304;-column-&#44050;&#51060;-NA&#51064;-&#44050;&#51012;-&#44152;&#47084;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[379]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[380]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[380]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1054, 18)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#44208;&#44284;&#47932;&#51012;-&#50896;&#54616;&#45716;-&#47784;&#50577;&#51004;&#47196;-&#48372;&#50668;&#51452;&#44592;-&#50948;&#54620;-&#50741;&#49496;&#51012;-&#44148;&#45796;.">&#44208;&#44284;&#47932;&#51012; &#50896;&#54616;&#45716; &#47784;&#50577;&#51004;&#47196; &#48372;&#50668;&#51452;&#44592; &#50948;&#54620; &#50741;&#49496;&#51012; &#44148;&#45796;.<a class="anchor-link" href="#&#44208;&#44284;&#47932;&#51012;-&#50896;&#54616;&#45716;-&#47784;&#50577;&#51004;&#47196;-&#48372;&#50668;&#51452;&#44592;-&#50948;&#54620;-&#50741;&#49496;&#51012;-&#44148;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[381]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># 결과물을 잘 보여주기 위한 옵션, column 숫자를 표현한 것 같다. 10 단위로</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>        <span class="c1"># 결과물을 잘 보여주기 위한 옵션, 숫자 소수점 표현하는 것 </span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[381]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[382]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[382]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1054.000</td>
      <td>1054.000</td>
      <td>1054.000</td>
      <td>1054.000</td>
      <td>1054.000</td>
      <td>1054.000</td>
      <td>1054.000</td>
      <td>827.000</td>
      <td>854.000</td>
      <td>843.000</td>
      <td>877.000</td>
      <td>784.000</td>
      <td>921.000</td>
      <td>776.000</td>
      <td>944.000</td>
      <td>966.000</td>
      <td>934.000</td>
      <td>899.000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.415</td>
      <td>1971.749</td>
      <td>44.251</td>
      <td>4.014</td>
      <td>5.653</td>
      <td>3.124</td>
      <td>1.787</td>
      <td>0.657</td>
      <td>0.485</td>
      <td>0.537</td>
      <td>0.719</td>
      <td>0.256</td>
      <td>0.385</td>
      <td>0.454</td>
      <td>0.469</td>
      <td>0.269</td>
      <td>0.793</td>
      <td>5.158</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.493</td>
      <td>13.580</td>
      <td>13.580</td>
      <td>1.387</td>
      <td>4.406</td>
      <td>1.045</td>
      <td>2.098</td>
      <td>0.475</td>
      <td>0.500</td>
      <td>0.499</td>
      <td>0.450</td>
      <td>0.437</td>
      <td>0.487</td>
      <td>0.498</td>
      <td>0.499</td>
      <td>0.444</td>
      <td>0.405</td>
      <td>2.270</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000</td>
      <td>1937.000</td>
      <td>19.000</td>
      <td>2.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000</td>
      <td>1960.000</td>
      <td>33.000</td>
      <td>3.000</td>
      <td>1.000</td>
      <td>2.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>4.000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000</td>
      <td>1970.000</td>
      <td>46.000</td>
      <td>4.000</td>
      <td>5.000</td>
      <td>3.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>5.000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.000</td>
      <td>1983.000</td>
      <td>56.000</td>
      <td>5.000</td>
      <td>8.000</td>
      <td>4.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>6.000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.000</td>
      <td>1997.000</td>
      <td>79.000</td>
      <td>6.000</td>
      <td>17.000</td>
      <td>5.000</td>
      <td>15.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>10.000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[383]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[383]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>sex          float64
birth        float64
age1         float64
age          float64
area         float64
edu          float64
income       float64
k2           float64
k3           float64
k4           float64
k6           float64
k7           float64
k8           float64
k10          float64
k12          float64
k13          float64
k14          float64
ideo_self    float64
dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[384]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Float64Index: 1054 entries, 1012.0 to 345.0
Data columns (total 18 columns):
sex          1054 non-null float64
birth        1054 non-null float64
age1         1054 non-null float64
age          1054 non-null float64
area         1054 non-null float64
edu          1054 non-null float64
income       1054 non-null float64
k2           827 non-null float64
k3           854 non-null float64
k4           843 non-null float64
k6           877 non-null float64
k7           784 non-null float64
k8           921 non-null float64
k10          776 non-null float64
k12          944 non-null float64
k13          966 non-null float64
k14          934 non-null float64
ideo_self    899 non-null float64
dtypes: float64(18)
memory usage: 156.5 KB
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[385]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[385]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>767.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>594.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>869.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>719.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>783.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>846.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>276.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>754.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>710.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>394.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1050.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>450.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>536.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>590.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>651.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>687.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>913.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>176.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>165.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>945.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>649.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>86.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>557.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>215.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>561.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>982.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>236.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>909.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>166.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>381.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1016.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>845.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>924.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>72.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>620.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>204.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>228.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>21.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>951.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>612.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>621.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>636.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>326.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>705.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>219.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>222.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>714.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>751.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>654.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>170.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>927.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>646.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>331.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>562.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>345.0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>1054 rows × 18 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="NA-&#44050;&#46308;&#51012;-&#52628;&#52769;&#54616;&#44592;-&#50948;&#54620;-base-&#45936;&#51060;&#53552;&#47484;-&#51105;&#50500;&#51456;&#45796;.">NA &#44050;&#46308;&#51012; &#52628;&#52769;&#54616;&#44592; &#50948;&#54620; base &#45936;&#51060;&#53552;&#47484; &#51105;&#50500;&#51456;&#45796;.<a class="anchor-link" href="#NA-&#44050;&#46308;&#51012;-&#52628;&#52769;&#54616;&#44592;-&#50948;&#54620;-base-&#45936;&#51060;&#53552;&#47484;-&#51105;&#50500;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[386]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># k 질문들만 잡고 NA 값 추측</span>
<span class="c1"># x_impute = data.values[:,7:-1]</span>

<span class="c1"># 전체 데이터 잡고 NA값 추측 </span>
<span class="n">x_impute</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_impute</span><span class="p">)</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[386]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0     False
1     False
2     False
3     False
4     False
5     False
6     False
7      True
8      True
9      True
10     True
11     True
12     True
13     True
14     True
15     True
16     True
dtype: bool</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[387]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_impute</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[387]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1054, 17)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="NA&#51032;-&#44050;&#51004;&#47196;-KNN,-SoftImpute,-SimpleFill,-MICE-4&#44060;&#51032;-imputer&#47484;-&#50424;-&#50696;&#51221;&#51060;&#45796;.">NA&#51032; &#44050;&#51004;&#47196; KNN, SoftImpute, SimpleFill, MICE 4&#44060;&#51032; imputer&#47484; &#50424; &#50696;&#51221;&#51060;&#45796;.<a class="anchor-link" href="#NA&#51032;-&#44050;&#51004;&#47196;-KNN,-SoftImpute,-SimpleFill,-MICE-4&#44060;&#51032;-imputer&#47484;-&#50424;-&#50696;&#51221;&#51060;&#45796;.">&#182;</a></h2><ul>
<li><strong>Manuel for KNN:</strong> Nearest neighbor imputations which weights samples using the mean squared difference on features for which two rows both have observed data.</li>
<li><strong>Manuel for SimpleFill:</strong> Replaces missing entries with the mean or median of each column.</li>
<li><strong>Thesis for SoftImpute:</strong> [click] <a href="http://web.stanford.edu/~hastie/Papers/mazumder10a.pdf">http://web.stanford.edu/~hastie/Papers/mazumder10a.pdf</a></li>
<li><strong>Thesis for MICE:</strong> [click] <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[388]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fancyimpute</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">KNN</span><span class="p">,</span>
    <span class="n">SoftImpute</span><span class="p">,</span>
    <span class="n">MICE</span>
<span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MICE-imputer&#47196;-missing-Value&#47484;-&#52376;&#47532;&#54664;&#45796;.">MICE imputer&#47196; missing Value&#47484; &#52376;&#47532;&#54664;&#45796;.<a class="anchor-link" href="#MICE-imputer&#47196;-missing-Value&#47484;-&#52376;&#47532;&#54664;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[389]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_impute_filled</span> <span class="o">=</span> <span class="n">MICE</span><span class="p">()</span><span class="o">.</span><span class="n">complete</span><span class="p">(</span><span class="n">x_impute</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[MICE] Completing matrix with shape (1054, 17)
[MICE] Starting imputation round 1/110, elapsed time 0.002
[MICE] Starting imputation round 2/110, elapsed time 0.008
[MICE] Starting imputation round 3/110, elapsed time 0.014
[MICE] Starting imputation round 4/110, elapsed time 0.021
[MICE] Starting imputation round 5/110, elapsed time 0.028
[MICE] Starting imputation round 6/110, elapsed time 0.035
[MICE] Starting imputation round 7/110, elapsed time 0.040
[MICE] Starting imputation round 8/110, elapsed time 0.045
[MICE] Starting imputation round 9/110, elapsed time 0.050
[MICE] Starting imputation round 10/110, elapsed time 0.055
[MICE] Starting imputation round 11/110, elapsed time 0.060
[MICE] Starting imputation round 12/110, elapsed time 0.066
[MICE] Starting imputation round 13/110, elapsed time 0.073
[MICE] Starting imputation round 14/110, elapsed time 0.080
[MICE] Starting imputation round 15/110, elapsed time 0.085
[MICE] Starting imputation round 16/110, elapsed time 0.090
[MICE] Starting imputation round 17/110, elapsed time 0.095
[MICE] Starting imputation round 18/110, elapsed time 0.102
[MICE] Starting imputation round 19/110, elapsed time 0.107
[MICE] Starting imputation round 20/110, elapsed time 0.112
[MICE] Starting imputation round 21/110, elapsed time 0.116
[MICE] Starting imputation round 22/110, elapsed time 0.120
[MICE] Starting imputation round 23/110, elapsed time 0.124
[MICE] Starting imputation round 24/110, elapsed time 0.129
[MICE] Starting imputation round 25/110, elapsed time 0.133
[MICE] Starting imputation round 26/110, elapsed time 0.137
[MICE] Starting imputation round 27/110, elapsed time 0.142
[MICE] Starting imputation round 28/110, elapsed time 0.146
[MICE] Starting imputation round 29/110, elapsed time 0.150
[MICE] Starting imputation round 30/110, elapsed time 0.154
[MICE] Starting imputation round 31/110, elapsed time 0.159
[MICE] Starting imputation round 32/110, elapsed time 0.164
[MICE] Starting imputation round 33/110, elapsed time 0.169
[MICE] Starting imputation round 34/110, elapsed time 0.174
[MICE] Starting imputation round 35/110, elapsed time 0.178
[MICE] Starting imputation round 36/110, elapsed time 0.183
[MICE] Starting imputation round 37/110, elapsed time 0.187
[MICE] Starting imputation round 38/110, elapsed time 0.192
[MICE] Starting imputation round 39/110, elapsed time 0.196
[MICE] Starting imputation round 40/110, elapsed time 0.200
[MICE] Starting imputation round 41/110, elapsed time 0.207
[MICE] Starting imputation round 42/110, elapsed time 0.211
[MICE] Starting imputation round 43/110, elapsed time 0.215
[MICE] Starting imputation round 44/110, elapsed time 0.219
[MICE] Starting imputation round 45/110, elapsed time 0.224
[MICE] Starting imputation round 46/110, elapsed time 0.228
[MICE] Starting imputation round 47/110, elapsed time 0.232
[MICE] Starting imputation round 48/110, elapsed time 0.237
[MICE] Starting imputation round 49/110, elapsed time 0.242
[MICE] Starting imputation round 50/110, elapsed time 0.247
[MICE] Starting imputation round 51/110, elapsed time 0.251
[MICE] Starting imputation round 52/110, elapsed time 0.255
[MICE] Starting imputation round 53/110, elapsed time 0.259
[MICE] Starting imputation round 54/110, elapsed time 0.264
[MICE] Starting imputation round 55/110, elapsed time 0.269
[MICE] Starting imputation round 56/110, elapsed time 0.273
[MICE] Starting imputation round 57/110, elapsed time 0.276
[MICE] Starting imputation round 58/110, elapsed time 0.280
[MICE] Starting imputation round 59/110, elapsed time 0.285
[MICE] Starting imputation round 60/110, elapsed time 0.289
[MICE] Starting imputation round 61/110, elapsed time 0.293
[MICE] Starting imputation round 62/110, elapsed time 0.298
[MICE] Starting imputation round 63/110, elapsed time 0.302
[MICE] Starting imputation round 64/110, elapsed time 0.306
[MICE] Starting imputation round 65/110, elapsed time 0.310
[MICE] Starting imputation round 66/110, elapsed time 0.315
[MICE] Starting imputation round 67/110, elapsed time 0.319
[MICE] Starting imputation round 68/110, elapsed time 0.323
[MICE] Starting imputation round 69/110, elapsed time 0.327
[MICE] Starting imputation round 70/110, elapsed time 0.332
[MICE] Starting imputation round 71/110, elapsed time 0.337
[MICE] Starting imputation round 72/110, elapsed time 0.341
[MICE] Starting imputation round 73/110, elapsed time 0.346
[MICE] Starting imputation round 74/110, elapsed time 0.350
[MICE] Starting imputation round 75/110, elapsed time 0.354
[MICE] Starting imputation round 76/110, elapsed time 0.359
[MICE] Starting imputation round 77/110, elapsed time 0.363
[MICE] Starting imputation round 78/110, elapsed time 0.367
[MICE] Starting imputation round 79/110, elapsed time 0.372
[MICE] Starting imputation round 80/110, elapsed time 0.378
[MICE] Starting imputation round 81/110, elapsed time 0.384
[MICE] Starting imputation round 82/110, elapsed time 0.390
[MICE] Starting imputation round 83/110, elapsed time 0.395
[MICE] Starting imputation round 84/110, elapsed time 0.400
[MICE] Starting imputation round 85/110, elapsed time 0.408
[MICE] Starting imputation round 86/110, elapsed time 0.414
[MICE] Starting imputation round 87/110, elapsed time 0.421
[MICE] Starting imputation round 88/110, elapsed time 0.425
[MICE] Starting imputation round 89/110, elapsed time 0.430
[MICE] Starting imputation round 90/110, elapsed time 0.434
[MICE] Starting imputation round 91/110, elapsed time 0.441
[MICE] Starting imputation round 92/110, elapsed time 0.447
[MICE] Starting imputation round 93/110, elapsed time 0.453
[MICE] Starting imputation round 94/110, elapsed time 0.458
[MICE] Starting imputation round 95/110, elapsed time 0.465
[MICE] Starting imputation round 96/110, elapsed time 0.470
[MICE] Starting imputation round 97/110, elapsed time 0.474
[MICE] Starting imputation round 98/110, elapsed time 0.479
[MICE] Starting imputation round 99/110, elapsed time 0.484
[MICE] Starting imputation round 100/110, elapsed time 0.488
[MICE] Starting imputation round 101/110, elapsed time 0.492
[MICE] Starting imputation round 102/110, elapsed time 0.497
[MICE] Starting imputation round 103/110, elapsed time 0.501
[MICE] Starting imputation round 104/110, elapsed time 0.506
[MICE] Starting imputation round 105/110, elapsed time 0.511
[MICE] Starting imputation round 106/110, elapsed time 0.516
[MICE] Starting imputation round 107/110, elapsed time 0.520
[MICE] Starting imputation round 108/110, elapsed time 0.524
[MICE] Starting imputation round 109/110, elapsed time 0.530
[MICE] Starting imputation round 110/110, elapsed time 0.534
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[390]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_impute_filled</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[390]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1054, 17)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[391]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_impute_filled</span><span class="p">)</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[391]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
dtype: bool</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Set&#50640;&#49436;-Missing-Value&#47484;-&#48148;&#44992;-colums&#46308;&#51012;-&#48516;&#47448;&#54644;&#51456;&#45796;.">Data Set&#50640;&#49436; Missing Value&#47484; &#48148;&#44992; colums&#46308;&#51012; &#48516;&#47448;&#54644;&#51456;&#45796;.<a class="anchor-link" href="#Data-Set&#50640;&#49436;-Missing-Value&#47484;-&#48148;&#44992;-colums&#46308;&#51012;-&#48516;&#47448;&#54644;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[392]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">array</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">values</span>
<span class="c1"># k 질문들만 잡고 NA 값 찾는 방법</span>
<span class="c1"># array[:, 7:-1].shape</span>

<span class="c1"># 전체 데이터를 잡고 NA값 찾는 방법</span>
<span class="n">array</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[392]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1054, 17)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Impute-&#46108;-&#45936;&#51060;&#53552;&#47484;-Data-Set&#50640;-&#51201;&#50857;&#49884;&#53020;&#51456;&#45796;.">Impute &#46108; &#45936;&#51060;&#53552;&#47484; Data Set&#50640; &#51201;&#50857;&#49884;&#53020;&#51456;&#45796;.<a class="anchor-link" href="#Impute-&#46108;-&#45936;&#51060;&#53552;&#47484;-Data-Set&#50640;-&#51201;&#50857;&#49884;&#53020;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[393]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">array</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_impute_filled</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ideo_self-column&#51012;-&#51228;&#50808;&#54620;-&#48376;-Data-Set&#50640;-&#45908;-&#51060;&#49345;-Missing-Value-&#44032;-&#50630;&#45796;&#45716;-&#44163;&#51012;-&#54869;&#51064;&#54624;-&#49688;-&#51080;&#45796;.">Ideo_self column&#51012; &#51228;&#50808;&#54620; &#48376; Data Set&#50640; &#45908; &#51060;&#49345; Missing Value &#44032; &#50630;&#45796;&#45716; &#44163;&#51012; &#54869;&#51064;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#Ideo_self-column&#51012;-&#51228;&#50808;&#54620;-&#48376;-Data-Set&#50640;-&#45908;-&#51060;&#49345;-Missing-Value-&#44032;-&#50630;&#45796;&#45716;-&#44163;&#51012;-&#54869;&#51064;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[394]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">array</span><span class="p">)</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[394]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17     True
dtype: bool</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[395]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[395]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.421</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.765</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>0.661</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.264</td>
      <td>0.0</td>
      <td>0.447</td>
      <td>0.478</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>767.0</th>
      <td>1.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.530</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>594.0</th>
      <td>1.0</td>
      <td>1982.0</td>
      <td>34.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.618</td>
      <td>0.509</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.229</td>
      <td>0.0</td>
      <td>0.479</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>869.0</th>
      <td>1.0</td>
      <td>1965.0</td>
      <td>51.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>719.0</th>
      <td>1.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.216</td>
      <td>0.0</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>783.0</th>
      <td>1.0</td>
      <td>1956.0</td>
      <td>60.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>8.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Impute-&#46108;-&#44050;&#51060;-&#54869;&#47456;&#47196;-&#45208;&#50772;&#44592;-&#46412;&#47928;&#50640;-0.5-&#51060;&#49345;&#51032;-&#44050;&#51008;-1&#47196;-&#45824;&#52404;&#54616;&#44256;-0.5-&#51060;&#54616;&#51032;-&#44050;&#51008;-0&#51004;&#47196;-&#45824;&#52404;&#54644;&#51456;&#45796;.">Impute &#46108; &#44050;&#51060; &#54869;&#47456;&#47196; &#45208;&#50772;&#44592; &#46412;&#47928;&#50640; 0.5 &#51060;&#49345;&#51032; &#44050;&#51008; 1&#47196; &#45824;&#52404;&#54616;&#44256; 0.5 &#51060;&#54616;&#51032; &#44050;&#51008; 0&#51004;&#47196; &#45824;&#52404;&#54644;&#51456;&#45796;.<a class="anchor-link" href="#Impute-&#46108;-&#44050;&#51060;-&#54869;&#47456;&#47196;-&#45208;&#50772;&#44592;-&#46412;&#47928;&#50640;-0.5-&#51060;&#49345;&#51032;-&#44050;&#51008;-1&#47196;-&#45824;&#52404;&#54616;&#44256;-0.5-&#51060;&#54616;&#51032;-&#44050;&#51008;-0&#51004;&#47196;-&#45824;&#52404;&#54644;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[396]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1054</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">array</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="n">array</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">array</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[397]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[397]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>sex          False
birth        False
age1         False
age          False
area         False
edu          False
income       False
k2           False
k3           False
k4           False
k6           False
k7           False
k8           False
k10          False
k12          False
k13          False
k14          False
ideo_self     True
dtype: bool</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#54869;&#47456;&#47196;-&#46108;-Impute-&#44050;&#51060;-&#50500;&#45772;-0-&#44284;-1-&#47196;-&#44396;&#49457;&#46108;-&#44050;&#51012;-&#48380;-&#49688;-&#51080;&#45796;.">&#54869;&#47456;&#47196; &#46108; Impute &#44050;&#51060; &#50500;&#45772; 0 &#44284; 1 &#47196; &#44396;&#49457;&#46108; &#44050;&#51012; &#48380; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#&#54869;&#47456;&#47196;-&#46108;-Impute-&#44050;&#51060;-&#50500;&#45772;-0-&#44284;-1-&#47196;-&#44396;&#49457;&#46108;-&#44050;&#51012;-&#48380;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[398]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[398]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ideo_self-&#44032;-class-&#48324;&#47196;-&#47751;-&#44060;&#50473;-&#51080;&#45716;&#51648;-&#54869;&#51064;&#54644;&#48376;&#45796;.">Ideo_self &#44032; class &#48324;&#47196; &#47751; &#44060;&#50473; &#51080;&#45716;&#51648; &#54869;&#51064;&#54644;&#48376;&#45796;.<a class="anchor-link" href="#Ideo_self-&#44032;-class-&#48324;&#47196;-&#47751;-&#44060;&#50473;-&#51080;&#45716;&#51648;-&#54869;&#51064;&#54644;&#48376;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[399]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ideo_self_counts</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;ideo_self&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">ideo_self_counts</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[399]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>ideo_self
0.0      31
1.0      22
2.0      41
3.0     101
4.0      98
5.0     282
6.0     101
7.0      87
8.0      63
9.0      21
10.0     52
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[400]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[400]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>k6</th>
      <th>k7</th>
      <th>k8</th>
      <th>k10</th>
      <th>k12</th>
      <th>k13</th>
      <th>k14</th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Encoding-categorical-variables">Encoding categorical variables<a class="anchor-link" href="#Encoding-categorical-variables">&#182;</a></h2><ul>
<li>Categorical variable: 값이 nominal인 변수</li>
<li>한 variable에 category가 총 C개가 존재하는 경우, 이를 C개의 binary dummy variables로 변환하여 수치형 데이터로 변환할 수 있다.</li>
<li>모든 variable의 숫자 값이 category 값이기 때문에 <strong>One hot encoding</strong>을 통해 binary dummy variables로 변환해준다. </li>
<li>Using <code>pandas.get_dummies</code><ul>
<li>[click]: <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html">http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[401]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#from sklearn.preprocessing import OneHotEncoder</span>
<span class="c1">#encoder = OneHotEncoder()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[402]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Sex_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">sex</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;sex&#39;</span><span class="p">)</span>
<span class="n">Sex_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[402]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>471.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>119.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>103.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>301.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>475.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>970.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>100.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>568.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>560.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>442.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[403]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Age_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">age</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;age&#39;</span><span class="p">)</span>
<span class="n">Age_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[403]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>954.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>175.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>410.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>914.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>727.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>886.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>904.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>566.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>777.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>745.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[404]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Area_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">area</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;area&#39;</span><span class="p">)</span>
<span class="n">Area_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[404]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>area_3.0</th>
      <th>area_4.0</th>
      <th>area_5.0</th>
      <th>area_6.0</th>
      <th>area_7.0</th>
      <th>area_8.0</th>
      <th>area_9.0</th>
      <th>area_10.0</th>
      <th>area_11.0</th>
      <th>area_12.0</th>
      <th>area_13.0</th>
      <th>area_14.0</th>
      <th>area_15.0</th>
      <th>area_16.0</th>
      <th>area_17.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>307.0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>735.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>480.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>108.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>383.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>158.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>174.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>270.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>970.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[405]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Edu_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">edu</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;education&#39;</span><span class="p">)</span>
<span class="n">Edu_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[405]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>education_1.0</th>
      <th>education_2.0</th>
      <th>education_3.0</th>
      <th>education_4.0</th>
      <th>education_5.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>147.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>891.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>944.0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>424.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>11.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>462.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>812.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>517.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>361.0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[406]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Income_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">income</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;income&#39;</span><span class="p">)</span>
<span class="n">Income_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[406]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>income_1.0</th>
      <th>income_2.0</th>
      <th>income_3.0</th>
      <th>income_4.0</th>
      <th>income_5.0</th>
      <th>income_6.0</th>
      <th>income_7.0</th>
      <th>income_8.0</th>
      <th>income_9.0</th>
      <th>income_10.0</th>
      <th>income_11.0</th>
      <th>income_12.0</th>
      <th>income_14.0</th>
      <th>income_15.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>261.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>954.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>451.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>541.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>573.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>154.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>65.0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>821.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>199.0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[407]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k2_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k2</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k2&#39;</span><span class="p">)</span>
<span class="n">k2_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[407]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k2_0.0</th>
      <th>k2_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>606.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>681.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>736.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>482.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>995.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>281.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1046.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>919.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1031.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>968.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[408]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k3_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k3</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k3&#39;</span><span class="p">)</span>
<span class="n">k3_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[408]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k3_0.0</th>
      <th>k3_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>500.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>182.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>867.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>170.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>666.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>155.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>865.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>807.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>88.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>432.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[409]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k4_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k4</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k4&#39;</span><span class="p">)</span>
<span class="n">k4_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[409]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k4_0.0</th>
      <th>k4_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>224.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>647.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>493.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1043.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>832.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>653.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>765.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>103.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>782.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>504.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[410]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k6_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k6</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k6&#39;</span><span class="p">)</span>
<span class="n">k6_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[410]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k6_0.0</th>
      <th>k6_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>472.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>944.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>430.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>561.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>501.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>271.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>866.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>822.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>487.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[411]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k7_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k7</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k7&#39;</span><span class="p">)</span>
<span class="n">k7_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[411]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k7_0.0</th>
      <th>k7_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>808.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>310.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>926.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>283.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>717.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>912.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>757.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>400.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>833.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>634.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[412]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k8_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k8</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k8&#39;</span><span class="p">)</span>
<span class="n">k8_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[412]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>627.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>670.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>423.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>594.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>145.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>451.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>521.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>915.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>983.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>325.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[413]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k10_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k10</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k10&#39;</span><span class="p">)</span>
<span class="n">k10_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[413]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>463.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>360.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>382.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>75.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>606.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>204.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>482.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>336.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>370.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>549.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[414]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k12_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k12</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k12&#39;</span><span class="p">)</span>
<span class="n">k12_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[414]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>463.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>337.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>74.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>552.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>809.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>170.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>823.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>208.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>331.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>546.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[415]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k13_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k13</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k13&#39;</span><span class="p">)</span>
<span class="n">k13_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[415]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>484.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>681.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>187.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>109.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1027.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>68.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>244.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>579.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>905.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>941.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[416]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k14_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">k14</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;k14&#39;</span><span class="p">)</span>
<span class="n">k14_dummies</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[416]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>713.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>657.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>709.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>234.0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>571.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>957.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>187.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>710.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>915.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>427.0</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dummy-Variable&#47196;-&#48320;&#44221;&#46108;-variables&#47484;-Data-set&#50640;-&#52628;&#44032;&#54644;&#51452;&#44256;-&#44536;-&#54028;&#51068;-&#51060;&#47492;&#51012;-new_data&#46972;&#44256;-&#52845;&#54620;&#45796;.">Dummy Variable&#47196; &#48320;&#44221;&#46108; variables&#47484; Data set&#50640; &#52628;&#44032;&#54644;&#51452;&#44256; &#44536; &#54028;&#51068; &#51060;&#47492;&#51012; new_data&#46972;&#44256; &#52845;&#54620;&#45796;.<a class="anchor-link" href="#Dummy-Variable&#47196;-&#48320;&#44221;&#46108;-variables&#47484;-Data-set&#50640;-&#52628;&#44032;&#54644;&#51452;&#44256;-&#44536;-&#54028;&#51068;-&#51060;&#47492;&#51012;-new_data&#46972;&#44256;-&#52845;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[417]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data</span><span class="p">,</span>  <span class="n">Sex_dummies</span><span class="p">,</span> <span class="n">Age_dummies</span><span class="p">,</span> <span class="n">Area_dummies</span><span class="p">,</span> <span class="n">Edu_dummies</span><span class="p">,</span> <span class="n">Income_dummies</span><span class="p">,</span> <span class="n">k2_dummies</span><span class="p">,</span> <span class="n">k3_dummies</span><span class="p">,</span> <span class="n">k4_dummies</span><span class="p">,</span> <span class="n">k6_dummies</span><span class="p">,</span> <span class="n">k7_dummies</span><span class="p">,</span> <span class="n">k8_dummies</span><span class="p">,</span> <span class="n">k10_dummies</span><span class="p">,</span> <span class="n">k12_dummies</span><span class="p">,</span> <span class="n">k13_dummies</span><span class="p">,</span> <span class="n">k14_dummies</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">new_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[417]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>birth</th>
      <th>age1</th>
      <th>age</th>
      <th>area</th>
      <th>edu</th>
      <th>income</th>
      <th>k2</th>
      <th>k3</th>
      <th>k4</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1.0</td>
      <td>1994.0</td>
      <td>22.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1.0</td>
      <td>1957.0</td>
      <td>59.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1.0</td>
      <td>1990.0</td>
      <td>26.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>2.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1.0</td>
      <td>1978.0</td>
      <td>38.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>767.0</th>
      <td>1.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>594.0</th>
      <td>1.0</td>
      <td>1982.0</td>
      <td>34.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>869.0</th>
      <td>1.0</td>
      <td>1965.0</td>
      <td>51.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>719.0</th>
      <td>1.0</td>
      <td>1966.0</td>
      <td>50.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>783.0</th>
      <td>1.0</td>
      <td>1956.0</td>
      <td>60.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 81 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dummy-variable&#47196;-&#51060;&#48120;-&#48320;&#44221;&#46108;-variables&#46308;&#51008;-&#45908;-&#51060;&#49345;-&#54596;&#50836;&#54616;&#51648;-&#50506;&#44592;-&#46412;&#47928;&#50640;-new_data-set&#50640;&#49436;-&#51228;&#44144;&#54644;&#51456;&#45796;.">Dummy variable&#47196; &#51060;&#48120; &#48320;&#44221;&#46108; variables&#46308;&#51008; &#45908; &#51060;&#49345; &#54596;&#50836;&#54616;&#51648; &#50506;&#44592; &#46412;&#47928;&#50640; new_data set&#50640;&#49436; &#51228;&#44144;&#54644;&#51456;&#45796;.<a class="anchor-link" href="#Dummy-variable&#47196;-&#51060;&#48120;-&#48320;&#44221;&#46108;-variables&#46308;&#51008;-&#45908;-&#51060;&#49345;-&#54596;&#50836;&#54616;&#51648;-&#50506;&#44592;-&#46412;&#47928;&#50640;-new_data-set&#50640;&#49436;-&#51228;&#44144;&#54644;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[418]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_data</span> <span class="o">=</span> <span class="n">new_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;birth&#39;</span><span class="p">,</span> <span class="s1">&#39;area&#39;</span><span class="p">,</span> <span class="s1">&#39;sex&#39;</span><span class="p">,</span> <span class="s1">&#39;age1&#39;</span><span class="p">,</span><span class="s1">&#39;edu&#39;</span><span class="p">,</span> <span class="s1">&#39;income&#39;</span><span class="p">,</span><span class="s1">&#39;k2&#39;</span><span class="p">,</span><span class="s1">&#39;k3&#39;</span><span class="p">,</span><span class="s1">&#39;k4&#39;</span><span class="p">,</span><span class="s1">&#39;k6&#39;</span><span class="p">,</span><span class="s1">&#39;k7&#39;</span><span class="p">,</span><span class="s1">&#39;k8&#39;</span><span class="p">,</span><span class="s1">&#39;k10&#39;</span><span class="p">,</span><span class="s1">&#39;k12&#39;</span><span class="p">,</span><span class="s1">&#39;k13&#39;</span><span class="p">,</span><span class="s1">&#39;k14&#39;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">new_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[418]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ideo_self</th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>5.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>7.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>10.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>3.0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>6.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>767.0</th>
      <td>5.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>594.0</th>
      <td>5.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>869.0</th>
      <td>5.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>719.0</th>
      <td>4.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>783.0</th>
      <td>8.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 64 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="New_data&#50640;&#49436;-Ideo_self&#51032;-&#44050;&#51060;-NA&#51064;-row&#44032;-ID-Number-24-&#48512;&#53552;&#51060;&#44592;-&#46412;&#47928;&#50640;-NA-&#44050;&#51064;-rows&#46308;&#51012;-&#46384;&#47196;-&#48516;&#47448;&#54644;&#51456;&#45796;.">New_data&#50640;&#49436; Ideo_self&#51032; &#44050;&#51060; NA&#51064; row&#44032; ID Number 24 &#48512;&#53552;&#51060;&#44592; &#46412;&#47928;&#50640; NA &#44050;&#51064; rows&#46308;&#51012; &#46384;&#47196; &#48516;&#47448;&#54644;&#51456;&#45796;.<a class="anchor-link" href="#New_data&#50640;&#49436;-Ideo_self&#51032;-&#44050;&#51060;-NA&#51064;-row&#44032;-ID-Number-24-&#48512;&#53552;&#51060;&#44592;-&#46412;&#47928;&#50640;-NA-&#44050;&#51064;-rows&#46308;&#51012;-&#46384;&#47196;-&#48516;&#47448;&#54644;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[419]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_data</span><span class="p">[</span><span class="mi">24</span><span class="p">:]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[419]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ideo_self</th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>107.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>111.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>118.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>182.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>281.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>289.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>339.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>357.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>415.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>447.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>629.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>727.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>755.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>120.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>129.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>168.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>202.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>499.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>613.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>801.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>809.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>986.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>87.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>103.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>119.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>141.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>768.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>805.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>857.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>982.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>236.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>909.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>166.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>381.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1016.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>845.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>924.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>72.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>620.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>204.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>228.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>21.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>951.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>612.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>621.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>636.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>326.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>705.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>219.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>222.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>714.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>751.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>654.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>170.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>927.0</th>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>646.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>331.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>562.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>345.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>155 rows × 64 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="New_data&#51032;-ID-Number-24-&#48512;&#53552;&#45716;-&#47784;&#46160;-NA-&#44050;&#51060;-&#54252;&#54632;&#46104;&#50612;-&#51080;&#45716;-&#44163;&#51012;-&#48380;-&#49688;-&#51080;&#45796;.">New_data&#51032; ID Number 24 &#48512;&#53552;&#45716; &#47784;&#46160; NA &#44050;&#51060; &#54252;&#54632;&#46104;&#50612; &#51080;&#45716; &#44163;&#51012; &#48380; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#New_data&#51032;-ID-Number-24-&#48512;&#53552;&#45716;-&#47784;&#46160;-NA-&#44050;&#51060;-&#54252;&#54632;&#46104;&#50612;-&#51080;&#45716;-&#44163;&#51012;-&#48380;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[420]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_data</span><span class="p">[</span><span class="mi">24</span><span class="p">:]</span><span class="o">.</span><span class="n">ideo_self</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[420]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>id
24.0      True
107.0     True
111.0     True
118.0     True
182.0     True
281.0     True
289.0     True
339.0     True
357.0     True
415.0     True
447.0     True
629.0     True
727.0     True
755.0     True
120.0     True
129.0     True
168.0     True
202.0     True
499.0     True
613.0     True
801.0     True
809.0     True
986.0     True
87.0      True
103.0     True
119.0     True
141.0     True
768.0     True
805.0     True
857.0     True
          ... 
982.0     True
236.0     True
909.0     True
166.0     True
381.0     True
1016.0    True
845.0     True
924.0     True
72.0      True
620.0     True
204.0     True
228.0     True
21.0      True
951.0     True
612.0     True
621.0     True
636.0     True
326.0     True
705.0     True
219.0     True
222.0     True
714.0     True
751.0     True
654.0     True
170.0     True
927.0     True
646.0     True
331.0     True
562.0     True
345.0     True
Name: ideo_self, Length: 155, dtype: bool</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ideo_self&#51032;-NA-&#44050;&#51012;-&#44592;&#51456;&#51004;&#47196;-Train-data&#50752;-Test-data&#47484;-&#45208;&#45600;&#51456;&#45796;.">Ideo_self&#51032; NA &#44050;&#51012; &#44592;&#51456;&#51004;&#47196; Train data&#50752; Test data&#47484; &#45208;&#45600;&#51456;&#45796;.<a class="anchor-link" href="#Ideo_self&#51032;-NA-&#44050;&#51012;-&#44592;&#51456;&#51004;&#47196;-Train-data&#50752;-Test-data&#47484;-&#45208;&#45600;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[421]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">new_data</span><span class="p">[:</span><span class="mi">199</span><span class="p">]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">new_data</span><span class="p">[</span><span class="mi">24</span><span class="p">:]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[422]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[422]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ideo_self</th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>5.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>7.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>10.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>3.0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>6.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 64 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[423]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[423]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ideo_self</th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>107.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>111.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>118.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>182.0</th>
      <td>NaN</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 64 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-Data&#47484;-X&#50752;-Y&#47484;-&#45208;&#45600;&#51452;&#44592;-&#50948;&#54644;-Train-data&#51032;-columns-&#51060;&#47492;&#44284;-&#44079;&#49688;&#47484;-&#54869;&#51064;&#54620;&#45796;.">Train Data&#47484; X&#50752; Y&#47484; &#45208;&#45600;&#51452;&#44592; &#50948;&#54644; Train data&#51032; columns &#51060;&#47492;&#44284; &#44079;&#49688;&#47484; &#54869;&#51064;&#54620;&#45796;.<a class="anchor-link" href="#Train-Data&#47484;-X&#50752;-Y&#47484;-&#45208;&#45600;&#51452;&#44592;-&#50948;&#54644;-Train-data&#51032;-columns-&#51060;&#47492;&#44284;-&#44079;&#49688;&#47484;-&#54869;&#51064;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[424]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 변수명 가져오기</span>
<span class="n">col_names</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[425]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Ideo_self column은 첫 번째 column이다. </span>
<span class="n">col_names</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[425]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;ideo_self&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[426]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Ideo_self를 기준으로 X와 Y를 나눠준다. </span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">col_names</span><span class="p">[:</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[427]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_X</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[427]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>area_3.0</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 63 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[428]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_Y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[428]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1012.0</th>
      <td>5.0</td>
    </tr>
    <tr>
      <th>556.0</th>
      <td>7.0</td>
    </tr>
    <tr>
      <th>642.0</th>
      <td>10.0</td>
    </tr>
    <tr>
      <th>403.0</th>
      <td>3.0</td>
    </tr>
    <tr>
      <th>776.0</th>
      <td>6.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test-Data&#47484;-X&#50752;-Y&#47484;-&#45208;&#45600;&#51452;&#44592;-&#50948;&#54644;-Test-data&#51032;-columns-&#51060;&#47492;&#44284;-&#44079;&#49688;&#47484;-&#54869;&#51064;&#54620;&#45796;.">Test Data&#47484; X&#50752; Y&#47484; &#45208;&#45600;&#51452;&#44592; &#50948;&#54644; Test data&#51032; columns &#51060;&#47492;&#44284; &#44079;&#49688;&#47484; &#54869;&#51064;&#54620;&#45796;.<a class="anchor-link" href="#Test-Data&#47484;-X&#50752;-Y&#47484;-&#45208;&#45600;&#51452;&#44592;-&#50948;&#54644;-Test-data&#51032;-columns-&#51060;&#47492;&#44284;-&#44079;&#49688;&#47484;-&#54869;&#51064;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[429]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 변수명 가져오기</span>
<span class="n">col_names</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[430]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Ideo_self column은 첫 번째 column이다. </span>
<span class="n">col_names</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[430]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;ideo_self&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[431]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Ideo_self를 기준으로 X와 Y를 나눠준다. </span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">col_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<span class="n">test_Y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">col_names</span><span class="p">[:</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[432]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_X</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[432]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex_1.0</th>
      <th>sex_2.0</th>
      <th>age_2.0</th>
      <th>age_3.0</th>
      <th>age_4.0</th>
      <th>age_5.0</th>
      <th>age_6.0</th>
      <th>area_1.0</th>
      <th>area_2.0</th>
      <th>area_3.0</th>
      <th>...</th>
      <th>k8_0.0</th>
      <th>k8_1.0</th>
      <th>k10_0.0</th>
      <th>k10_1.0</th>
      <th>k12_0.0</th>
      <th>k12_1.0</th>
      <th>k13_0.0</th>
      <th>k13_1.0</th>
      <th>k14_0.0</th>
      <th>k14_1.0</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>107.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>111.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>118.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>182.0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 63 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[433]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_Y</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[433]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ideo_self</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24.0</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>107.0</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>111.0</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>118.0</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>182.0</th>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-Split-Train-data">1. Split Train data<a class="anchor-link" href="#1.-Split-Train-data">&#182;</a></h1><ol>
<li>Training set (70%)</li>
<li>Validation set (30%)</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model&#50640;-&#54617;&#49845;&#49884;&#53412;&#44592;-&#50948;&#54644;-Train-set&#51032;-X&#50752;-Y-&#44050;&#51012;-array-&#44050;&#51004;&#47196;-&#48148;&#45012;&#51456;&#45796;.">Model&#50640; &#54617;&#49845;&#49884;&#53412;&#44592; &#50948;&#54644; Train set&#51032; X&#50752; Y &#44050;&#51012; array &#44050;&#51004;&#47196; &#48148;&#45012;&#51456;&#45796;.<a class="anchor-link" href="#Model&#50640;-&#54617;&#49845;&#49884;&#53412;&#44592;-&#50948;&#54644;-Train-set&#51032;-X&#50752;-Y-&#44050;&#51012;-array-&#44050;&#51004;&#47196;-&#48148;&#45012;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[434]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_X</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">values</span>
<span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">values</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[435]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Y 값을 numpy.ravel 함수를 써서 reshape 시켜준다. Return a contiguous flattened array.</span>

<span class="n">train_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[436]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_X</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[436]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[1, 0, 1, ..., 0, 0, 1],
       [1, 0, 0, ..., 1, 0, 1],
       [1, 0, 1, ..., 0, 0, 1],
       ..., 
       [0, 1, 0, ..., 0, 0, 1],
       [0, 1, 1, ..., 1, 1, 0],
       [1, 0, 1, ..., 0, 0, 1]], dtype=uint8)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[437]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_Y</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[437]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([  5.,   7.,  10.,   3.,   6.,   5.,   5.,   5.,   4.,   8.,   3.,
         3.,   5.,   1.,   7.,   4.,   3.,   4.,   9.,   4.,   5.,   3.,
         7.,   6.,   3.,   3.,   9.,   5.,   3.,   4.,   4.,   5.,   5.,
         5.,  10.,   5.,   0.,   2.,   5.,   5.,   6.,   0.,   2.,   3.,
         2.,   2.,   5.,   4.,   6.,   2.,   5.,   6.,   4.,   5.,   6.,
         1.,   8.,   0.,   4.,   3.,   3.,   4.,   5.,   8.,   7.,   5.,
         5.,   5.,   5.,   3.,   6.,   6.,   8.,   3.,   5.,   0.,   7.,
         5.,   6.,   2.,   8.,   4.,   3.,   7.,   3.,   5.,   4.,   0.,
         5.,   5.,   6.,   8.,   5.,   2.,   5.,   5.,   6.,   3.,   4.,
         7.,   6.,   5.,   5.,   6.,   4.,   5.,   6.,   5.,   5.,   1.,
         7.,   5.,   4.,   3.,   7.,   6.,  10.,   5.,   5.,   5.,   6.,
         6.,   0.,   4.,   3.,  10.,   3.,   1.,   7.,   4.,   6.,   5.,
         6.,   4.,   5.,   5.,   5.,   5.,   5.,   1.,   2.,   3.,   4.,
         6.,   5.,   4.,  10.,   8.,   7.,   6.,   6.,   5.,   5.,   7.,
         4.,   8.,  10.,  10.,   3.,   7.,   5.,   6.,  10.,   7.,   5.,
         4.,   8.,   3.,   5.,   6.,   7.,   8.,   7.,   7.,   6.,   4.,
         5.,   5.,   0.,   5.,   5.,   0.,   3.,   6.,   5.,   2.,   5.,
         2.,   6.,   3.,   5.,   2.,   4.,   5.,   3.,   2.,   6.,   5.,
         5.,  10.,   5.,   1.,   7.,   5.,   6.,   8.,   5.,   7.,   3.,
         3.,   5.,   7.,   4.,   5.,   6.,   0.,   1.,   8.,   4.,   5.,
         5.,   6.,   6.,   5.,   3.,   6.,   5.,   4.,   5.,   5.,   5.,
         7.,   6.,   4.,   8.,   4.,   5.,   1.,   5.,   4.,   5.,   6.,
         3.,   5.,   4.,   4.,   8.,  10.,   5.,   5.,   5.,   7.,   7.,
         7.,   5.,   4.,   5.,   5.,   5.,   8.,   3.,   4.,   6.,   6.,
         6.,   7.,   9.,   6.,   5.,   5.,   7.,   0.,   5.,   5.,   6.,
         1.,  10.,   4.,   7.,   8.,   7.,   3.,   4.,   3.,   7.,   8.,
         5.,   3.,   5.,   3.,   5.,   6.,   7.,   3.,   4.,   8.,   5.,
         8.,   2.,   8.,   4.,   6.,   5.,   0.,   6.,  10.,   2.,   5.,
         7.,   3.,   6.,   6.,   5.,   5.,   7.,   4.,   8.,   5.,   5.,
         5.,   7.,   3.,   5.,   3.,   3.,   6.,  10.,   6.,   6.,   7.,
         2.,   5.,  10.,   9.,   9.,   3.,   5.,   5.,   6.,   5.,   5.,
         9.,   7.,   5.,   6.,  10.,   6.,   4.,   6.,   5.,   5.,   7.,
         3.,   4.,   6.,   4.,   5.,   1.,   5.,   7.,   3.,   3.,   4.,
         4.,   8.,   4.,   5.,   5.,   5.,   5.,   7.,   9.,   6.,   5.,
         6.,   5.,   4.,   7.,   2.,   3.,   4.,   6.,   5.,   4.,   3.,
         7.,   7.,   5.,   6.,  10.,   7.,   5.,  10.,   7.,   5.,   5.,
         5.,   5.,   3.,   6.,   0.,   5.,   5.,   5.,   4.,   0.,   2.,
        10.,   6.,   6.,   7.,   1.,  10.,   5.,   7.,   1.,   5.,   0.,
         1.,   4.,   5.,   5.,   8.,   7.,   5.,   5.,   9.,   2.,   5.,
         7.,   2.,   3.,   4.,   8.,   5.,   1.,   6.,   5.,   3.,   4.,
         9.,   2.,  10.,   8.,   7.,  10.,   5.,   5.,   5.,   4.,   8.,
         3.,   5.,   5.,   5.,   6.,   3.,   3.,   7.,   7.,   5.,   3.,
         8.,   6.,   2.,   7.,   3.,   3.,   4.,   7.,   6.,   8.,   5.,
         5.,   8.,   3.,   3.,   6.,   5.,   5.,   5.,   8.,   5.,  10.,
         5.,  10.,   8.,   5.,   5.,   8.,   6.,   6.,   6.,   6.,   5.,
         5.,   5.,   5.,   5.,   8.,   7.,   5.,   0.,   5.,   5.,   5.,
         7.,   5.,   5.,   4.,   6.,   5.,   3.,   8.,   7.,   8.,   6.,
         5.,   4.,   9.,   7.,   5.,   5.,   0.,   5.,   5.,   3.,   5.,
         4.,   7.,   5.,   8.,   4.,   3.,  10.,   5.,   3.,   4.,   9.,
         5.,   0.,   5.,   5.,   5.,  10.,   2.,   5.,   5.,   8.,  10.,
         5.,   6.,   3.,   5.,   5.,   5.,  10.,   5.,   0.,   0.,   8.,
         6.,   2.,  10.,   5.,   0.,   5.,  10.,   4.,  10.,   4.,   9.,
         6.,   8.,   3.,   5.,   0.,  10.,   5.,   7.,   4.,   3.,   4.,
         6.,   8.,   2.,   5.,   6.,   8.,  10.,   5.,   4.,   5.,   2.,
         5.,   4.,   5.,   5.,   8.,   4.,   3.,   1.,   6.,   5.,   8.,
         8.,   4.,   0.,   6.,   3.,   3.,   5.,   2.,   5.,   6.,   7.,
         5.,   5.,   5.,   2.,   3.,   6.,   5.,   5.,   7.,   5.,   5.,
         5.,   6.,   4.,   6.,   5.,   5.,   5.,   4.,   8.,   5.,   0.,
        10.,   8.,   5.,   5.,   6.,   4.,   5.,   9.,   3.,   3.,   2.,
         4.,   9.,   5.,   2.,   8.,   0.,   4.,   3.,   3.,   6.,   3.,
         5.,   9.,   4.,   3.,   9.,   4.,   4.,   8.,   5.,  10.,   3.,
        10.,   6.,   2.,   6.,   0.,   1.,   7.,   1.,   5.,   1.,   7.,
         7.,   5.,   5.,   3.,   7.,   5.,   2.,   7.,   5.,   0.,   4.,
         3.,   5.,   6.,   8.,   3.,   5.,   5.,   3.,   7.,   5.,   4.,
         5.,   7.,   1.,   8.,   3.,   5.,   5.,  10.,   8.,   0.,   5.,
         9.,   4.,   3.,   7.,   3.,   3.,   4.,   1.,   5.,   2.,   0.,
        10.,   2.,   5.,   6.,   2.,   5.,   3.,  10.,   5.,   6.,   7.,
         5.,   6.,   6.,   7.,   5.,   3.,   8.,   4.,  10.,   4.,   8.,
         5.,   9.,   4.,   8.,   3.,   1.,   5.,   5.,   5.,  10.,   5.,
        10.,   5.,   5.,   9.,   5.,   5.,  10.,   3.,   2.,   4.,   5.,
         5.,  10.,   3.,   5.,   7.,   4.,   4.,   6.,   4.,   7.,   3.,
         6.,   5.,   5.,   3.,   5.,   5.,   6.,   5.,   3.,   6.,   9.,
         7.,   0.,   7.,   4.,   3.,   5.,   5.,   5.,   8.,   5.,   4.,
         8.,   4.,   8.,   7.,   5.,   5.,   7.,   3.,   3.,   5.,   8.,
         8.,   7.,   7.,   5.,   5.,   4.,   5.,   5.,   6.,   5.,   3.,
         4.,   2.,  10.,   3.,  10.,   5.,   4.,   8.,  10.,   8.,   5.,
         2.,   5.,   5.,   6.,   5.,   7.,   2.,   5.,   7.,   5.,   7.,
         0.,   2.,   4.,   5.,   7.,   7.,   6.,   6.,   4.,  10.,   0.,
         4.,   6.,  10.,   2.,   5.,   8.,   3.,   3.,   4.,   3.,   5.,
         7.,   5.,   5.,  10.,   8.,  10.,   5.,   6.,   5.,   1.,   3.,
         5.,   5.,   5.,  10.,   5.,   5.,   9.,   3.,   7.,   5.,   7.,
         4.,  10.,   7.,   5.,   3.,   2.,   4.,   5.])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model&#50640;-&#54617;&#49845;&#49884;&#53412;&#44592;-&#50948;&#54644;-Test-set&#51032;-X&#50752;-Y-&#44050;&#51012;-array-&#44050;&#51004;&#47196;-&#48148;&#45012;&#51456;&#45796;.">Model&#50640; &#54617;&#49845;&#49884;&#53412;&#44592; &#50948;&#54644; Test set&#51032; X&#50752; Y &#44050;&#51012; array &#44050;&#51004;&#47196; &#48148;&#45012;&#51456;&#45796;.<a class="anchor-link" href="#Model&#50640;-&#54617;&#49845;&#49884;&#53412;&#44592;-&#50948;&#54644;-Test-set&#51032;-X&#50752;-Y-&#44050;&#51012;-array-&#44050;&#51004;&#47196;-&#48148;&#45012;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[438]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_X</span> <span class="o">=</span> <span class="n">test_X</span><span class="o">.</span><span class="n">values</span>
<span class="n">test_Y</span> <span class="o">=</span> <span class="n">test_Y</span><span class="o">.</span><span class="n">values</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[439]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Y 값을 numpy.ravel 함수를 써서 reshape 시켜준다. Return a contiguous flattened array.</span>

<span class="n">test_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">test_Y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[440]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_X</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[440]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[1, 0, 0, ..., 1, 0, 1],
       [1, 0, 0, ..., 1, 0, 1],
       [1, 0, 0, ..., 0, 0, 1],
       ..., 
       [1, 0, 0, ..., 0, 1, 0],
       [1, 0, 0, ..., 0, 0, 1],
       [1, 0, 0, ..., 0, 0, 1]], dtype=uint8)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[441]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_Y</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[441]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,
        nan])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Skitlearn-library&#47484;-&#53685;&#54644;-Train-set&#51012;-Train-&#44284;-Validataion-&#51004;&#47196;-&#45208;&#45600;&#51456;&#45796;.">Skitlearn library&#47484; &#53685;&#54644; Train set&#51012; Train &#44284; Validataion &#51004;&#47196; &#45208;&#45600;&#51456;&#45796;.<a class="anchor-link" href="#Skitlearn-library&#47484;-&#53685;&#54644;-Train-set&#51012;-Train-&#44284;-Validataion-&#51004;&#47196;-&#45208;&#45600;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[442]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[443]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">,</span> <span class="n">train_Y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> 
                                                        <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
                                                        <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[444]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Train, Validation Set의 shape을 확인해준다.</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_Y_val</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(629, 63)
(270, 63)
(629,)
(270,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Fit-the-model-and-compare-validation-AUCs-and-prediction-probability">2. Fit the model and compare validation AUCs and prediction probability<a class="anchor-link" href="#2.-Fit-the-model-and-compare-validation-AUCs-and-prediction-probability">&#182;</a></h1><p>비교하고자 하는 classifiers들은 다음과 같음</p>
<ol>
<li>Logistic regression</li>
<li>k-nearest neighbor classifier</li>
<li>naive Bayes classifier</li>
<li>Decision tree</li>
<li>Random forest</li>
<li>SVM</li>
<li>Xgboost</li>
<li>SoftMax</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="k">import</span> <span class="n">pprint</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="k">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="k">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.1.-Logistic-regression">2.1. Logistic regression<a class="anchor-link" href="#2.1.-Logistic-regression">&#182;</a></h2><p>Manual for <code>sklearn.linear_model.LogisticRegression</code>: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">click</a></p>
<p>다음 parameter들에 대해 validation data에 대한 Score값과 AUC값을 이용해 최적 모형 parameter를 찾는다.</p>
<ol>
<li>penalty</li>
<li>C</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># C가 클수록 weak regularization</span>
<span class="n">penalty_set</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]</span>
<span class="n">C_set</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">,</span> <span class="mf">1e4</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">penalty</span> <span class="ow">in</span> <span class="n">penalty_set</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">C_set</span><span class="p">:</span>
        <span class="n">logreg_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s2">&quot;multinomial&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;saga&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
        <span class="n">logreg_model</span> <span class="o">=</span> <span class="n">logreg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="c1">#         Y_val_score = model.decision_function(train_X_val)</span>
        <span class="n">Y_val_score</span> <span class="o">=</span> <span class="n">logreg_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">val_proba</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">))</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">Y_val_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">result1</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">logreg_model</span><span class="p">,</span> <span class="n">penalty</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">val_proba</span><span class="p">,</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>c:\users\daniel\python36\lib\site-packages\sklearn\linear_model\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result1</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[82]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(LogisticRegression(C=0.1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 0.1, &#39;0.0926&#39;, 0.70113207547169809),
 (LogisticRegression(C=1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 1, &#39;0.1704&#39;, 0.62792452830188683),
 (LogisticRegression(C=10, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 10, &#39;0.1630&#39;, 0.64830188679245282),
 (LogisticRegression(C=100.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 100.0, &#39;0.1333&#39;, 0.49886792452830186),
 (LogisticRegression(C=1000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 1000.0, &#39;0.1407&#39;, 0.59849056603773587),
 (LogisticRegression(C=10000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 10000.0, &#39;0.1111&#39;, 0.49660377358490571),
 (LogisticRegression(C=100000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 100000.0, &#39;0.1444&#39;, 0.50641509433962262),
 (LogisticRegression(C=1000000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 1000000.0, &#39;0.1444&#39;, 0.49660377358490571),
 (LogisticRegression(C=0.1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 0.1, &#39;0.1741&#39;, 0.71169811320754717),
 (LogisticRegression(C=1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 1, &#39;0.1556&#39;, 0.65811320754716984),
 (LogisticRegression(C=10, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 10, &#39;0.1519&#39;, 0.64000000000000001),
 (LogisticRegression(C=100.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 100.0, &#39;0.1444&#39;, 0.53811320754716985),
 (LogisticRegression(C=1000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 1000.0, &#39;0.1667&#39;, 0.49056603773584911),
 (LogisticRegression(C=10000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 10000.0, &#39;0.1889&#39;, 0.51018867924528299),
 (LogisticRegression(C=100000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 100000.0, &#39;0.1481&#39;, 0.44150943396226416),
 (LogisticRegression(C=1000000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 1000000.0, &#39;0.1296&#39;, 0.49358490566037738)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logreg_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result1</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logreg_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[84]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(LogisticRegression(C=10000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 10000.0, &#39;0.1889&#39;, 0.51018867924528299),
 (LogisticRegression(C=0.1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 0.1, &#39;0.1741&#39;, 0.71169811320754717),
 (LogisticRegression(C=1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 1, &#39;0.1704&#39;, 0.62792452830188683),
 (LogisticRegression(C=1000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 1000.0, &#39;0.1667&#39;, 0.49056603773584911),
 (LogisticRegression(C=10, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 10, &#39;0.1630&#39;, 0.64830188679245282),
 (LogisticRegression(C=1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 1, &#39;0.1556&#39;, 0.65811320754716984),
 (LogisticRegression(C=10, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 10, &#39;0.1519&#39;, 0.64000000000000001),
 (LogisticRegression(C=100000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 100000.0, &#39;0.1481&#39;, 0.44150943396226416),
 (LogisticRegression(C=100000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 100000.0, &#39;0.1444&#39;, 0.50641509433962262),
 (LogisticRegression(C=1000000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 1000000.0, &#39;0.1444&#39;, 0.49660377358490571),
 (LogisticRegression(C=100.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 100.0, &#39;0.1444&#39;, 0.53811320754716985),
 (LogisticRegression(C=1000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 1000.0, &#39;0.1407&#39;, 0.59849056603773587),
 (LogisticRegression(C=100.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 100.0, &#39;0.1333&#39;, 0.49886792452830186),
 (LogisticRegression(C=1000000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l2&#39;, 1000000.0, &#39;0.1296&#39;, 0.49358490566037738),
 (LogisticRegression(C=10000.0, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 10000.0, &#39;0.1111&#39;, 0.49660377358490571),
 (LogisticRegression(C=0.1, class_weight=&#39;balanced&#39;, dual=False,
            fit_intercept=True, intercept_scaling=1, max_iter=10000,
            multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l1&#39;,
            random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
            warm_start=False), &#39;l1&#39;, 0.1, &#39;0.0926&#39;, 0.70113207547169809)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_logreg_result</span> <span class="o">=</span> <span class="n">logreg_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_logreg_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(LogisticRegression(C=10000.0, class_weight=&#39;balanced&#39;, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=10000,
          multi_class=&#39;multinomial&#39;, n_jobs=1, penalty=&#39;l2&#39;,
          random_state=None, solver=&#39;saga&#39;, tol=0.0001, verbose=0,
          warm_start=False), &#39;l2&#39;, 10000.0, &#39;0.1889&#39;, 0.51018867924528299)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_logreg_model</span> <span class="o">=</span> <span class="n">best_logreg_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_logreg_model</span> <span class="o">=</span> <span class="n">best_logreg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.60740740741
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>c:\users\daniel\python36\lib\site-packages\sklearn\linear_model\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[  5.60834164e-04   1.55556775e-08   6.58633385e-09   3.23814553e-04
    5.79178781e-01   3.20140647e-01   9.96933820e-02   3.37284159e-05
    5.76094152e-05   4.79657571e-16   1.11815127e-05]
 [  1.84085578e-01   4.88950725e-02   2.68903498e-02   1.63449381e-01
    1.20663205e-01   1.70211796e-01   7.29739931e-02   1.10316393e-01
    8.20697705e-02   7.56245155e-09   2.04444534e-02]
 [  3.39018770e-02   9.52643399e-08   1.38967107e-02   5.22160024e-01
    6.00760717e-02   1.40356018e-02   2.74834495e-02   1.34108169e-01
    1.83073561e-02   6.78903050e-14   1.76030645e-01]
 [  9.13434298e-05   7.85303602e-06   8.77125666e-06   8.50996102e-05
    3.69908209e-01   5.63249447e-02   3.60182850e-01   2.13325140e-01
    6.21700301e-05   1.28692605e-12   3.61884931e-06]
 [  4.62929946e-02   1.99816391e-06   2.37491031e-03   7.91961128e-02
    1.35791031e-02   3.49176640e-02   1.80278575e-02   2.89808081e-01
    8.65812317e-02   2.30851196e-12   4.29220047e-01]
 [  4.52292278e-03   2.23997166e-04   4.20848947e-06   9.25041495e-04
    2.91216322e-03   4.06737635e-03   3.11385827e-02   3.35893829e-02
    1.54662511e-01   4.15376567e-01   3.52577247e-01]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[ 4  0  3  4 10  9  6  4 10  5  2  2  7  8  0  1  1  4  8  9  8  0  0  6 10
  8  0  0  3  0  1  5  6  5  1  4  7  0  8  5  0  5  4  5  4 10  3  5  3  1
  3  4 10  5  8  9  2  7  8  4  5  0  6  5 10  7  0  6  0  8  8  0  3  1  1
  5  7 10  1  7  0  5  7  5  0 10  9  3 10  5 10  2  1  8  2  1  6  8  7  3
  0  6  5  5  3  7  2  4  7  6  0  7  2  1 10  3  6  7  4  8  9  8  5  5  0
  0  1  3  1  0  5  9  0  8  3  0 10  0  1  8  8  2  6  1  5  3  4  7  0  0
  6  9  3  3  4  1  2  0  1  8  6  8  1  1  0  3  0  7  5  2  2  0 10  6 10
  9 10 10  2  0  7  0  9 10 10  7  1  7  7  5  2  9  0  4  0  3 10 10  2  6
  7  1  1 10  2  9  1  9  5  8  3  8 10  3  3  0  7  6  2  0  0  5  2  0  3
  3  3  8  1  4  6  7  1  6  2  8  6  7  8  0  0  9  6  8  3 10  6  1  8  8
  4  1 10  0  5  1  9  8  2  0  2  5  4  3  8  9  0  4  5  7]
예측:
[  4.   0.   3.   4.  10.   9.   6.   4.  10.   5.   2.   2.   7.   8.   0.
   1.   1.   4.   8.   9.   8.   0.   0.   6.  10.   8.   0.   0.   3.   0.
   1.   5.   6.   5.   1.   4.   7.   0.   8.   5.   0.   5.   4.   5.   4.
  10.   3.   5.   3.   1.   3.   4.  10.   5.   8.   9.   2.   7.   8.   4.
   5.   0.   6.   5.  10.   7.   0.   6.   0.   8.   8.   0.   3.   1.   1.
   5.   7.  10.   1.   7.   0.   5.   7.   5.   0.  10.   9.   3.  10.   5.
  10.   2.   1.   8.   2.   1.   6.   8.   7.   3.   0.   6.   5.   5.   3.
   7.   2.   4.   7.   6.   0.   7.   2.   1.  10.   3.   6.   7.   4.   8.
   9.   8.   5.   5.   0.   0.   1.   3.   1.   0.   5.   9.   0.   8.   3.
   0.  10.   0.   1.   8.   8.   2.   6.   1.   5.   3.   4.   7.   0.   0.
   6.   9.   3.   3.   4.   1.   2.   0.   1.   8.   6.   8.   1.   1.   0.
   3.   0.   7.   5.   2.   2.   0.  10.   6.  10.   9.  10.  10.   2.   0.
   7.   0.   9.  10.  10.   7.   1.   7.   7.   5.   2.   9.   0.   4.   0.
   3.  10.  10.   2.   6.   7.   1.   1.  10.   2.   9.   1.   9.   5.   8.
   3.   8.  10.   3.   3.   0.   7.   6.   2.   0.   0.   5.   2.   0.   3.
   3.   3.   8.   1.   4.   6.   7.   1.   6.   2.   8.   6.   7.   8.   0.
   0.   9.   6.   8.   3.  10.   6.   1.   8.   8.   4.   1.  10.   0.   5.
   1.   9.   8.   2.   0.   2.   5.   4.   3.   8.   9.   0.   4.   5.   7.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[146]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="n">argmax_dec_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 결정 함수의 인덱스: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">argmax_dec_func</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;인덱스를 classses_에 연결: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">argmax_dec_func</span><span class="p">][:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
가장 큰 결정 함수의 인덱스: [ 0  1 10  8  0  6  9  1  2  3]
인덱스를 classses_에 연결: [  0.   1.  10.   8.   0.   6.   9.   1.   2.   3.]
Validation set의 예측: [  5.   5.   5.   3.  10.  10.   4.   5.  10.   5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.14
Test set의 예측: [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[447]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 전체 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 예측: [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.   1.   4.   9.   8.   0.
  10.  10.  10.  10.   9.   3.   7.   8.   7.   7.   0.   2.   3.   2.  10.
   5.  10.   0.   2.   0.   3.   3.   3.   6.   6.   2.   6.  10.   5.   2.
   0.   8.  10.   7.   8.   8.  10.   9.   1.   8.   0.   5.   4.   9.   7.
   2.   2.   7.   7.   2.   2.   0.   0.   5.   0.   1.   1.   9.   1.   1.
   2.   0.  10.   1.   3.   6.   0.   4.   8.   5.   5.   3.   1.   3.   4.
   0.   0.   5.  10.   6.   3.   5.   5.   4.   5.   4.   3.  10.   6.   5.
   5.   3.  10.  10.  10.   2.  10.  10.   3.   7.   1.   3.   7.   6.   5.
   6.   6.   4.   8.   7.   5.   8.   3.   3.   2.   0.   5.   0.  10.   6.
   6.   6.   6.   5.   7.   0.   7.   1.   3.   0.   0.   5.   7.   5.   1.
   0.   7.   5.   5.   7.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.2.-k-nearest-neighbor-classifier">2.2. k-nearest neighbor classifier<a class="anchor-link" href="#2.2.-k-nearest-neighbor-classifier">&#182;</a></h2><p>Manual for <code>sklearn.neighbors.KNeighborsClassifier</code>: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">click</a></p>
<p>다음 parameter들에 대해 validation data에 대한 Score값과 AUC값을 이용해 최적 모형 parameter를 찾는다.</p>
<ol>
<li>n_neighbors</li>
<li>weights</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights_set</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">]</span>
<span class="n">n_neighbors_set</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">weights</span> <span class="ow">in</span> <span class="n">weights_set</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">n_neighbors</span> <span class="ow">in</span> <span class="n">n_neighbors_set</span><span class="p">:</span>
        <span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
        <span class="n">Y_val_score</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">val_proba</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">))</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">Y_val_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1">#result.append(&quot;모델: {}, 최적 Weight: {}, 최적 N_neighbor: {}, 최적 AUC 값: {}&quot;.format(model, weights, n_neighbors, auc(fpr, tpr)))</span>
        <span class="c1">#result.append((&quot;모델&quot;, model, &quot;최적 Weigth&quot;, weights, &quot;최적 N_neighbor&quot;, n_neighbors, &quot;최적 AUC 값&quot;, auc(fpr, tpr)))       </span>
        <span class="n">result2</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">knn_model</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="p">,</span> <span class="n">val_proba</span><span class="p">,</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>        
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result2</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[95]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=1, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 1, &#39;0.2222&#39;, 0.48490566037735849),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=3, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 3, &#39;0.1889&#39;, 0.46981132075471699),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 5, &#39;0.2148&#39;, 0.45283018867924529),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=7, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 7, &#39;0.2556&#39;, 0.43018867924528303),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=9, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 9, &#39;0.2778&#39;, 0.40754716981132078),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=11, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 11, &#39;0.2741&#39;, 0.48905660377358495),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=13, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 13, &#39;0.2815&#39;, 0.46188679245283021),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=15, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 15, &#39;0.2889&#39;, 0.45169811320754716),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=1, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  1,
  &#39;0.2222&#39;,
  0.48490566037735849),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=3, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  3,
  &#39;0.2111&#39;,
  0.46981132075471699),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  5,
  &#39;0.2259&#39;,
  0.45283018867924529),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=7, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  7,
  &#39;0.2556&#39;,
  0.43018867924528303),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=9, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  9,
  &#39;0.2778&#39;,
  0.40754716981132078),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=11, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  11,
  &#39;0.2852&#39;,
  0.4747169811320755),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=13, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  13,
  &#39;0.3000&#39;,
  0.44452830188679249),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=15, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  15,
  &#39;0.2889&#39;,
  0.43622641509433963)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">knn_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result2</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">knn_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[97]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=13, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  13,
  &#39;0.3000&#39;,
  0.44452830188679249),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=15, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 15, &#39;0.2889&#39;, 0.45169811320754716),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=15, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  15,
  &#39;0.2889&#39;,
  0.43622641509433963),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=11, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  11,
  &#39;0.2852&#39;,
  0.4747169811320755),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=13, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 13, &#39;0.2815&#39;, 0.46188679245283021),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=9, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 9, &#39;0.2778&#39;, 0.40754716981132078),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=9, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  9,
  &#39;0.2778&#39;,
  0.40754716981132078),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=11, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 11, &#39;0.2741&#39;, 0.48905660377358495),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=7, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 7, &#39;0.2556&#39;, 0.43018867924528303),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=7, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  7,
  &#39;0.2556&#39;,
  0.43018867924528303),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  5,
  &#39;0.2259&#39;,
  0.45283018867924529),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=1, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 1, &#39;0.2222&#39;, 0.48490566037735849),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=1, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  1,
  &#39;0.2222&#39;,
  0.48490566037735849),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 5, &#39;0.2148&#39;, 0.45283018867924529),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=3, p=2,
             weights=&#39;distance&#39;),
  &#39;distance&#39;,
  3,
  &#39;0.2111&#39;,
  0.46981132075471699),
 (KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
             metric_params=None, n_jobs=1, n_neighbors=3, p=2,
             weights=&#39;uniform&#39;), &#39;uniform&#39;, 3, &#39;0.1889&#39;, 0.46981132075471699)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_knn_result</span> <span class="o">=</span> <span class="n">knn_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_knn_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
           metric_params=None, n_jobs=1, n_neighbors=13, p=2,
           weights=&#39;distance&#39;), &#39;distance&#39;, 13, &#39;0.3000&#39;, 0.44452830188679249)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_knn_model</span> <span class="o">=</span> <span class="n">best_knn_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_knn_model</span> <span class="o">=</span> <span class="n">best_knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.44444444444
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[ 0.          0.          0.07789386  0.16783795  0.14756425  0.53703356
   0.          0.06967039  0.          0.          0.        ]
 [ 0.07667647  0.          0.          0.16521483  0.13716304  0.39901119
   0.          0.          0.06858152  0.07667647  0.07667647]
 [ 0.          0.          0.          0.31415892  0.2975756   0.38826547
   0.          0.          0.          0.          0.        ]
 [ 0.06825092  0.          0.          0.41175885  0.07880937  0.36237149
   0.          0.07880937  0.          0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.          0.
   0.          0.          0.          1.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.24078923  0.24078923  0.15184215  0.08894707  0.27763231]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[ 5  5  5  3 10 10  4  5 10  5  3  5  3  7  5  1  5  5  5  8  5  5  5  7  5
  8  5  5  5  5  5  4  7  5  5  4  7  5  8  5  3  5  4  5  5  8  4  5  4  5
  4  4  5  5  6  8  8  6  8  3  4  5  5  5  6  7  3  5  5  6  5  3  5  4  5
  5  7  5  5  4  5  5  5  5  5  5  5  5  8  5  5  4  4  7  5  5  5  7  7  3
  5  3  5  5  5  7  4  3  5  5  5  7  4  0  5  4  5  5  4  5  7  8  5  5  5
  5  1  3  5  5  5  8  5  6  2  5  5  5  5  8  7  5  5  5  5  5  4  4  5  5
  3  8  4  3  4  5  5  5  5 10  7  8  5  5  5  5  5  7  5  5  4  5  9  5  8
  9  7 10  4  5  5  3  5  5  7  5  5  5  5  5  5  6  5  5  5  2  5  5  5 10
  7  5  5  7  5  7  5  7  5  8  4  7  5  3  3  5  5  7  5  3  5  5  3  4  3
  3  5  8  5  5  7  5  3  5  2  3  5  7  6  5  4  5  6  6  5  4  5  5  5  5
  5  5  8  5  5  5  9  9  5  4  2  5  5  5  5  5  5  3  3  8]
예측:
[  5.   5.   5.   3.  10.  10.   4.   5.  10.   5.   3.   5.   3.   7.   5.
   1.   5.   5.   5.   8.   5.   5.   5.   7.   5.   8.   5.   5.   5.   5.
   5.   4.   7.   5.   5.   4.   7.   5.   8.   5.   3.   5.   4.   5.   5.
   8.   4.   5.   4.   5.   4.   4.   5.   5.   6.   8.   8.   6.   8.   3.
   4.   5.   5.   5.   6.   7.   3.   5.   5.   6.   5.   3.   5.   4.   5.
   5.   7.   5.   5.   4.   5.   5.   5.   5.   5.   5.   5.   5.   8.   5.
   5.   4.   4.   7.   5.   5.   5.   7.   7.   3.   5.   3.   5.   5.   5.
   7.   4.   3.   5.   5.   5.   7.   4.   0.   5.   4.   5.   5.   4.   5.
   7.   8.   5.   5.   5.   5.   1.   3.   5.   5.   5.   8.   5.   6.   2.
   5.   5.   5.   5.   8.   7.   5.   5.   5.   5.   5.   4.   4.   5.   5.
   3.   8.   4.   3.   4.   5.   5.   5.   5.  10.   7.   8.   5.   5.   5.
   5.   5.   7.   5.   5.   4.   5.   9.   5.   8.   9.   7.  10.   4.   5.
   5.   3.   5.   5.   7.   5.   5.   5.   5.   5.   5.   6.   5.   5.   5.
   2.   5.   5.   5.  10.   7.   5.   5.   7.   5.   7.   5.   7.   5.   8.
   4.   7.   5.   3.   3.   5.   5.   7.   5.   3.   5.   5.   3.   4.   3.
   3.   5.   8.   5.   5.   7.   5.   3.   5.   2.   3.   5.   7.   6.   5.
   4.   5.   6.   6.   5.   4.   5.   5.   5.   5.   5.   5.   8.   5.   5.
   5.   9.   9.   5.   4.   2.   5.   5.   5.   5.   5.   5.   3.   3.   8.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[149]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># KNN 에는 decision function이 없어 predict_proba만 실행한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
Validation set의 예측: [  5.   5.   5.   3.  10.  10.   4.   5.  10.   5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.30
Test set의 예측: [ 8.  8.  5.  8.  5.  8.  6.  5.  5.  9.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[448]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 전체 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 전체 예측: [  8.   8.   5.   8.   5.   8.   6.   5.   5.   9.   5.   7.   9.   9.   4.
   5.  10.   5.   7.   9.   2.   7.   7.   5.   7.   5.   3.   4.   5.   5.
   5.   5.   3.   5.   5.   3.   5.   5.   5.   5.   5.   5.   6.   5.   3.
   3.   6.   8.   7.   8.   6.   8.   8.   3.   7.   5.   5.   4.   7.   5.
   3.   3.   5.   5.   3.   5.   5.   3.   5.   5.   7.   3.   5.   5.   5.
   5.   5.   5.   4.   3.   5.   5.   4.   3.   5.   5.   4.   3.   3.   5.
   5.   5.   5.   5.   5.   3.   5.   5.   3.   5.   7.  10.   5.   7.   5.
   5.   5.   5.   3.   6.   5.   5.   5.   3.   7.   5.   5.   5.   5.   5.
   5.   5.   5.   5.   7.   5.   5.   4.   5.   3.   5.   5.   5.  10.   7.
   6.   6.   3.   5.   7.   5.   7.   5.   3.   5.   4.   5.   5.   5.   5.
   5.   5.   3.   5.   5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.3.-Naive-Bayes-classifier">2.3. Naive Bayes classifier<a class="anchor-link" href="#2.3.-Naive-Bayes-classifier">&#182;</a></h2><p>Manual for <code>sklearn.naive_bayes.GaussianNB</code>: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html">click</a></p>
<p>클래스에 대한 prior 정보를 조절하여 fitting</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[110]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">priors_set</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[112]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result3</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">priors</span> <span class="ow">in</span> <span class="n">priors_set</span><span class="p">:</span>
    <span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">(</span><span class="n">priors</span><span class="o">=</span><span class="n">priors</span><span class="p">)</span>
    <span class="n">nb_model</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
    <span class="n">Y_val_score</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">val_proba</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nb_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">))</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">Y_val_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">result3</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">nb_model</span><span class="p">,</span> <span class="n">priors</span><span class="p">,</span> <span class="n">val_proba</span><span class="p">,</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>      
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[113]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nb_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result3</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[114]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nb_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[114]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(GaussianNB(priors=None), None, &#39;0.0407&#39;, 0.41509433962264147)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#47484;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#47484; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#47484;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[115]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_nb_result</span> <span class="o">=</span> <span class="n">nb_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_nb_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(GaussianNB(priors=None), None, &#39;0.0407&#39;, 0.41509433962264147)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[116]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_nb_model</span> <span class="o">=</span> <span class="n">best_nb_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_nb_model</span> <span class="o">=</span> <span class="n">best_nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3.63333333333
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[117]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[  0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000
    1.00000000e+000   1.01965017e-021   1.10735610e-010   0.00000000e+000
    0.00000000e+000   0.00000000e+000   0.00000000e+000]
 [  6.74125497e-021   1.00000000e+000   2.34265007e-026   1.19001308e-048
    4.63787703e-057   4.20133704e-075   5.41084928e-051   2.32878512e-048
    1.22315821e-026   0.00000000e+000   8.86517791e-017]
 [  7.80119602e-012   0.00000000e+000   6.42837030e-024   5.62250955e-039
    3.61514108e-060   5.05984467e-072   6.01166964e-048   4.18391334e-036
    1.50208970e-021   0.00000000e+000   1.00000000e+000]
 [  0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000
    4.64192734e-012   5.47937668e-056   1.43183284e-002   9.85681672e-001
    0.00000000e+000   0.00000000e+000   0.00000000e+000]
 [  5.50349893e-015   0.00000000e+000   4.11658468e-027   1.48661662e-046
    4.02357104e-066   1.72442672e-073   3.64016074e-052   4.50974671e-037
    4.10174579e-019   0.00000000e+000   1.00000000e+000]
 [  1.10225358e-054   5.19572500e-040   3.91866432e-079   7.37580945e-087
    5.50883743e-090   8.04661256e-107   4.17917728e-075   9.69523269e-070
    1.07790387e-043   1.00000000e+000   2.45257679e-032]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[118]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[ 4  1 10  7 10  9  0  1 10  1  1  0  7  9  1  1  1  4  1  9  1  1  1  9  9
  8  0  1  1  1  1  5  1 10  9  8  9  0  9  9  0  9  1  5 10 10  3  3  1  1
  1 10  1 10  0  9  0  9 10  1  5  9  9  1  1  9  0  7  9  9  9  0  1  1  1
 10  9  9  1  1  9  1 10  9  1  1  9  0 10 10  1  1  1 10  2  1  9 10  1  0
  0  6  9  6  3  9  0  7  7  1  1  7  0  1 10  1  1 10  2 10  9  9  1  9  9
 10  1  1  9  1  5  9  9  1 10  9  1  9  9  1  9  1  9  1 10  1  1  7  0  1
  1  9  0  1  7  9  0 10  1 10  9  1  1  9  1  3 10  9  1  1  1 10 10  1  9
  9 10 10 10  9  7  0  9  9 10  7  1  1  7 10  1  0  0  1  0 10 10  1  1  1
  1  9  1 10  2  9  1  9  7  9 10  9  1  1  1 10  9  6  1  0  1 10  1  1  1
  3  1  9  1 10  9  7  1  9  0  1 10  9  1  1  0  9  1  9  1 10  6  1 10  1
  9  1  9  1  0  1  9  1  1  0  1  9  9  1  1  9  9 10  9  7]
예측:
[  4.   1.  10.   7.  10.   9.   0.   1.  10.   1.   1.   0.   7.   9.   1.
   1.   1.   4.   1.   9.   1.   1.   1.   9.   9.   8.   0.   1.   1.   1.
   1.   5.   1.  10.   9.   8.   9.   0.   9.   9.   0.   9.   1.   5.  10.
  10.   3.   3.   1.   1.   1.  10.   1.  10.   0.   9.   0.   9.  10.   1.
   5.   9.   9.   1.   1.   9.   0.   7.   9.   9.   9.   0.   1.   1.   1.
  10.   9.   9.   1.   1.   9.   1.  10.   9.   1.   1.   9.   0.  10.  10.
   1.   1.   1.  10.   2.   1.   9.  10.   1.   0.   0.   6.   9.   6.   3.
   9.   0.   7.   7.   1.   1.   7.   0.   1.  10.   1.   1.  10.   2.  10.
   9.   9.   1.   9.   9.  10.   1.   1.   9.   1.   5.   9.   9.   1.  10.
   9.   1.   9.   9.   1.   9.   1.   9.   1.  10.   1.   1.   7.   0.   1.
   1.   9.   0.   1.   7.   9.   0.  10.   1.  10.   9.   1.   1.   9.   1.
   3.  10.   9.   1.   1.   1.  10.  10.   1.   9.   9.  10.  10.  10.   9.
   7.   0.   9.   9.  10.   7.   1.   1.   7.  10.   1.   0.   0.   1.   0.
  10.  10.   1.   1.   1.   1.   9.   1.  10.   2.   9.   1.   9.   7.   9.
  10.   9.   1.   1.   1.  10.   9.   6.   1.   0.   1.  10.   1.   1.   1.
   3.   1.   9.   1.  10.   9.   7.   1.   9.   0.   1.  10.   9.   1.   1.
   0.   9.   1.   9.   1.  10.   6.   1.  10.   1.   9.   1.   9.   1.   0.
   1.   9.   1.   1.   0.   1.   9.   9.   1.   1.   9.   9.  10.   9.   7.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[148]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># GaussianNB는 Decision Function이 없어 predict_proba만 실행한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
Validation set의 예측: [  4.   1.  10.   7.  10.   9.   0.   1.  10.   1.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.04
Test set의 예측: [  9.  10.   1.   1.   9.   9.   9.   1.   1.   9.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[449]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 전체 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 전체 예측: [  9.  10.   1.   1.   9.   9.   9.   1.   1.   9.   1.  10.   9.   1.   9.
   9.   9.   1.  10.   9.   1.   9.   9.   9.   9.   9.   1.   3.   1.   9.
   1.   1.   1.   9.  10.   1.   1.   1.   1.   1.   1.   0.   9.  10.   1.
   1.   9.  10.   9.  10.   9.  10.   9.   1.   1.  10.  10.   0.   9.   1.
   1.   1.   1.   9.   1.   0.   1.  10.   9.   0.   9.   1.   9.   1.   1.
   1.   9.   1.   1.   1.  10.  10.   0.   1.   1.   9.   1.   1.   9.   1.
   1.   9.   9.   1.   9.   2.   9.   1.   1.   8.   4.  10.  10.   6.  10.
  10.  10.  10.  10.  10.  10.  10.   1.   0.   2.   1.   8.   2.   0.   5.
  10.  10.  10.   9.  10.   9.  10.  10.   8.  10.   0.   9.   0.  10.   9.
   1.   9.   6.   9.   9.   1.   9.   9.   1.   1.   1.   1.   7.   9.   1.
   1.   7.   7.   7.   7.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.4.-Decision-tree">2.4. Decision tree<a class="anchor-link" href="#2.4.-Decision-tree">&#182;</a></h2><p>Manual for <code>sklearn.tree.DecisionTreeClassifier</code>: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">click</a></p>
<p>다음 parameter들에 대해 validation data에 대한 Score값과 AUC값을 이용해 최적 모형 parameter를 찾는다.</p>
<ol>
<li>max_depth</li>
<li>class_weight</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[122]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">class_weight_set</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">]</span>
<span class="n">max_depth_set</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[123]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result4</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">class_weight</span> <span class="ow">in</span> <span class="n">class_weight_set</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="n">max_depth_set</span><span class="p">:</span>
        <span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>
        <span class="n">dt_model</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
        <span class="n">Y_val_score</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">val_proba</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dt_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">))</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">Y_val_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">result4</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dt_model</span><span class="p">,</span> <span class="n">class_weight</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">val_proba</span><span class="p">,</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[124]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dt_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result4</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[125]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dt_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[125]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), None, 3, &#39;0.2889&#39;, 0.82415094339622641),
 (DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=4,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), None, 4, &#39;0.2667&#39;, 0.789056603773585),
 (DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=7,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), None, 7, &#39;0.2593&#39;, 0.54113207547169817),
 (DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=6,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), None, 6, &#39;0.2481&#39;, 0.61018867924528308),
 (DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), None, 5, &#39;0.2444&#39;, 0.7652830188679246),
 (DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=4,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), &#39;balanced&#39;, 4, &#39;0.2296&#39;, 0.72377358490566035),
 (DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=6,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), &#39;balanced&#39;, 6, &#39;0.1185&#39;, 0.34452830188679245),
 (DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=7,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), &#39;balanced&#39;, 7, &#39;0.1074&#39;, 0.41207547169811326),
 (DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), &#39;balanced&#39;, 3, &#39;0.0815&#39;, 0.85056603773584916),
 (DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter=&#39;best&#39;), &#39;balanced&#39;, 5, &#39;0.0815&#39;, 0.78000000000000003)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[126]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_dt_result</span> <span class="o">=</span> <span class="n">dt_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_dt_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=3,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter=&#39;best&#39;), None, 3, &#39;0.2889&#39;, 0.82415094339622641)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[127]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_dt_model</span> <span class="o">=</span> <span class="n">best_dt_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_dt_model</span> <span class="o">=</span> <span class="n">best_dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.61111111111
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[128]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[ 0.          0.          0.          0.          0.8         0.2         0.
   0.          0.          0.          0.        ]
 [ 0.04433498  0.02955665  0.02463054  0.07881773  0.08866995  0.49753695
   0.09359606  0.08866995  0.01477833  0.00492611  0.03448276]
 [ 0.03809524  0.00952381  0.01904762  0.16190476  0.17142857  0.31428571
   0.1047619   0.12380952  0.02857143  0.00952381  0.01904762]
 [ 0.03809524  0.00952381  0.01904762  0.16190476  0.17142857  0.31428571
   0.1047619   0.12380952  0.02857143  0.00952381  0.01904762]
 [ 0.04433498  0.02955665  0.02463054  0.07881773  0.08866995  0.49753695
   0.09359606  0.08866995  0.01477833  0.00492611  0.03448276]
 [ 0.01680672  0.00840336  0.          0.02521008  0.04201681  0.14285714
   0.13445378  0.19327731  0.22689076  0.1092437   0.10084034]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[129]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[ 4  5  5  5  5  8  5  3 10  5  3  3  5  8  8  3  3  8  8  8  5  5  5  5  5
  8  5  5  3  5  3  5  5  5  5  3  5  3  8  5  5  5  3  5  5 10  5  5  5  3
  5  3  5  5  8  8  3  5  8  5  4  5  5  5  5  5  5  8  5  8  8  3  5  3  3
  5  5  8  3  5  5  5  5  5  5  5  5  3 10  5  5  3  3  8  3  5  8  8  5  3
  3  5  5  5  5  5  3  3  5  5  5  8  3  3  5  3 10  5  5  8  8  8  5  5  5
  5  3  3  5  5  3  8  5  5  3  5  5  5  5  8  8  3  5  5  8  3  5  3  3  5
  5  8  3  3  5  5  5  5  5 10  5  8  3  5  8  3  5  5  5  5  5  5  8  5  8
  8  8  8  3  5  3  3  5  5 10  5  5  5  5  5  3  8  5 10  5  3  5  3  3  8
  5  5  5  8  3  8  3  8  3  8  3  5  5  3  3  3  5 10  3  5  5  5  3  8  3
  3  3  8  5  5  5  5  3  5  3  8  5  5  8  5  5  8  8  8  3  3  4  5 10 10
  5  5  8  5  5  5  8  8  5  3  3  5  5  3 10  5  5  5  5  8]
예측:
[  4.   5.   5.   5.   5.   8.   5.   3.  10.   5.   3.   3.   5.   8.   8.
   3.   3.   8.   8.   8.   5.   5.   5.   5.   5.   8.   5.   5.   3.   5.
   3.   5.   5.   5.   5.   3.   5.   3.   8.   5.   5.   5.   3.   5.   5.
  10.   5.   5.   5.   3.   5.   3.   5.   5.   8.   8.   3.   5.   8.   5.
   4.   5.   5.   5.   5.   5.   5.   8.   5.   8.   8.   3.   5.   3.   3.
   5.   5.   8.   3.   5.   5.   5.   5.   5.   5.   5.   5.   3.  10.   5.
   5.   3.   3.   8.   3.   5.   8.   8.   5.   3.   3.   5.   5.   5.   5.
   5.   3.   3.   5.   5.   5.   8.   3.   3.   5.   3.  10.   5.   5.   8.
   8.   8.   5.   5.   5.   5.   3.   3.   5.   5.   3.   8.   5.   5.   3.
   5.   5.   5.   5.   8.   8.   3.   5.   5.   8.   3.   5.   3.   3.   5.
   5.   8.   3.   3.   5.   5.   5.   5.   5.  10.   5.   8.   3.   5.   8.
   3.   5.   5.   5.   5.   5.   5.   8.   5.   8.   8.   8.   8.   3.   5.
   3.   3.   5.   5.  10.   5.   5.   5.   5.   5.   3.   8.   5.  10.   5.
   3.   5.   3.   3.   8.   5.   5.   5.   8.   3.   8.   3.   8.   3.   8.
   3.   5.   5.   3.   3.   3.   5.  10.   3.   5.   5.   5.   3.   8.   3.
   3.   3.   8.   5.   5.   5.   5.   3.   5.   3.   8.   5.   5.   8.   5.
   5.   8.   8.   8.   3.   3.   4.   5.  10.  10.   5.   5.   8.   5.   5.
   5.   8.   8.   5.   3.   3.   5.   5.   3.  10.   5.   5.   5.   5.   8.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[150]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Decision Tree Classifier은 Decision Function이 없어 predict_proba만 실행한다. </span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
Validation set의 예측: [  4.   5.   5.   5.   5.   8.   5.   3.  10.   5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.29
Test set의 예측: [  8.  10.   3.   8.   5.   8.   8.   3.   5.   8.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[450]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 전체 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 전체 예측: [  8.  10.   3.   8.   5.   8.   8.   3.   5.   8.   5.   3.   8.   8.   5.
   8.   8.   3.  10.   8.   3.   5.   8.   5.   5.   5.   3.   3.   3.   5.
   5.  10.   3.   5.   5.   3.   5.   3.   5.   5.   5.   5.   8.   5.   3.
   5.   8.   8.   5.  10.   8.  10.   8.   3.   8.   5.   5.   3.   8.   5.
   3.   3.   5.   5.   3.   5.   5.   3.   5.   5.   5.   3.   5.   3.   3.
   3.   5.   5.   3.   3.   5.   3.   3.   5.   5.   5.   3.   3.   5.   3.
   5.   8.   5.   8.   5.   4.   5.   5.  10.   5.   5.   5.   5.   5.   5.
   5.   5.   5.   3.  10.   5.  10.   3.   3.   5.   5.   5.   5.   3.   4.
   5.   5.   5.   5.   5.   5.   5.   3.   5.   3.   5.   5.   5.  10.   8.
   8.   5.   3.   5.   8.   3.   8.   5.   3.   5.   5.   5.   5.   5.   5.
   5.   5.   3.   5.   5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.5.-Random-forest">2.5. Random forest<a class="anchor-link" href="#2.5.-Random-forest">&#182;</a></h2><p>Manual for <code>sklearn.ensemble.RandomForestClassifier</code>: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">click</a></p>
<p>다음 parameter들에 대해 validation data에 대한 Score값과 AUC값을 이용해 최적 모형 parameter를 찾는다.</p>
<ol>
<li>n_estimators</li>
<li>max_features</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[365]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_estimators_set</span> <span class="o">=</span> <span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">]</span>
<span class="n">max_depth_set</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">max_features_set</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[366]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result5</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">n_estimators</span> <span class="ow">in</span> <span class="n">n_estimators_set</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">max_features</span> <span class="ow">in</span> <span class="n">max_features_set</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="n">max_depth_set</span><span class="p">:</span>
            <span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="n">max_features</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">rf_model</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
            <span class="n">Y_val_score</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">val_proba</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rf_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">))</span>
            <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">Y_val_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">result5</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">,</span> <span class="n">max_features</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">val_proba</span><span class="p">,</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[367]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rf_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result5</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[368]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rf_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[368]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;auto&#39;,
  3,
  &#39;0.3481&#39;,
  0.81433962264150939),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;sqrt&#39;,
  3,
  &#39;0.3481&#39;,
  0.81433962264150939),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;log2&#39;,
  4,
  &#39;0.3481&#39;,
  0.83849056603773586),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;log2&#39;,
  4,
  &#39;0.3481&#39;,
  0.82339622641509436),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;log2&#39;,
  5,
  &#39;0.3444&#39;,
  0.75547169811320758),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;auto&#39;,
  3,
  &#39;0.3407&#39;,
  0.80301886792452837),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;sqrt&#39;,
  3,
  &#39;0.3407&#39;,
  0.80301886792452837),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;log2&#39;,
  4,
  &#39;0.3407&#39;,
  0.81283018867924539),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;auto&#39;,
  3,
  &#39;0.3407&#39;,
  0.82339622641509436),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;sqrt&#39;,
  3,
  &#39;0.3407&#39;,
  0.82339622641509436),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;auto&#39;,
  3,
  &#39;0.3407&#39;,
  0.81962264150943398),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;sqrt&#39;,
  3,
  &#39;0.3407&#39;,
  0.81962264150943398),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;log2&#39;,
  4,
  &#39;0.3370&#39;,
  0.85358490566037726),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;auto&#39;,
  3,
  &#39;0.3370&#39;,
  0.80528301886792453),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;sqrt&#39;,
  3,
  &#39;0.3370&#39;,
  0.80528301886792453),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;log2&#39;,
  4,
  &#39;0.3370&#39;,
  0.77735849056603767),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;auto&#39;,
  3,
  &#39;0.3370&#39;,
  0.82566037735849063),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;sqrt&#39;,
  3,
  &#39;0.3370&#39;,
  0.82566037735849063),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;log2&#39;,
  4,
  &#39;0.3370&#39;,
  0.77886792452830189),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;auto&#39;,
  4,
  &#39;0.3370&#39;,
  0.77584905660377357),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;sqrt&#39;,
  4,
  &#39;0.3370&#39;,
  0.77584905660377357),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;log2&#39;,
  4,
  &#39;0.3370&#39;,
  0.77056603773584909),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;log2&#39;,
  5,
  &#39;0.3333&#39;,
  0.78113207547169816),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;log2&#39;,
  3,
  &#39;0.3333&#39;,
  0.8143396226415095),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;log2&#39;,
  5,
  &#39;0.3333&#39;,
  0.7449056603773585),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;auto&#39;,
  3,
  &#39;0.3333&#39;,
  0.80679245283018874),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;auto&#39;,
  4,
  &#39;0.3333&#39;,
  0.75018867924528299),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;auto&#39;,
  5,
  &#39;0.3333&#39;,
  0.75924528301886796),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;sqrt&#39;,
  3,
  &#39;0.3333&#39;,
  0.80679245283018874),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;sqrt&#39;,
  4,
  &#39;0.3333&#39;,
  0.75018867924528299),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;sqrt&#39;,
  5,
  &#39;0.3333&#39;,
  0.75924528301886796),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;log2&#39;,
  5,
  &#39;0.3333&#39;,
  0.73207547169811327),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;auto&#39;,
  4,
  &#39;0.3333&#39;,
  0.76754716981132076),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;sqrt&#39;,
  4,
  &#39;0.3333&#39;,
  0.76754716981132076),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;log2&#39;,
  5,
  &#39;0.3333&#39;,
  0.7313207547169811),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;auto&#39;,
  4,
  &#39;0.3296&#39;,
  0.7871698113207547),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;sqrt&#39;,
  4,
  &#39;0.3296&#39;,
  0.7871698113207547),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;log2&#39;,
  3,
  &#39;0.3296&#39;,
  0.8260377358490566),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;log2&#39;,
  7,
  &#39;0.3296&#39;,
  0.63471698113207542),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;log2&#39;,
  3,
  &#39;0.3296&#39;,
  0.80150943396226415),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;auto&#39;,
  4,
  &#39;0.3296&#39;,
  0.74641509433962261),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;sqrt&#39;,
  4,
  &#39;0.3296&#39;,
  0.74641509433962261),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;log2&#39;,
  3,
  &#39;0.3296&#39;,
  0.8075471698113208),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;log2&#39;,
  5,
  &#39;0.3296&#39;,
  0.73358490566037737),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;auto&#39;,
  4,
  &#39;0.3296&#39;,
  0.7735849056603773),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;sqrt&#39;,
  4,
  &#39;0.3296&#39;,
  0.7735849056603773),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;log2&#39;,
  3,
  &#39;0.3296&#39;,
  0.81811320754716987),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;log2&#39;,
  5,
  &#39;0.3296&#39;,
  0.73283018867924532),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;auto&#39;,
  5,
  &#39;0.3259&#39;,
  0.7939622641509434),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;sqrt&#39;,
  5,
  &#39;0.3259&#39;,
  0.7939622641509434),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;auto&#39;,
  4,
  &#39;0.3259&#39;,
  0.77509433962264151),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=4, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;sqrt&#39;,
  4,
  &#39;0.3259&#39;,
  0.77509433962264151),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;log2&#39;,
  6,
  &#39;0.3259&#39;,
  0.72905660377358494),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;log2&#39;,
  7,
  &#39;0.3259&#39;,
  0.63471698113207542),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;auto&#39;,
  5,
  &#39;0.3259&#39;,
  0.75622641509433963),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;auto&#39;,
  6,
  &#39;0.3259&#39;,
  0.66339622641509433),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;sqrt&#39;,
  5,
  &#39;0.3259&#39;,
  0.75622641509433963),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;sqrt&#39;,
  6,
  &#39;0.3259&#39;,
  0.66339622641509433),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;log2&#39;,
  3,
  &#39;0.3259&#39;,
  0.8158490566037736),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=3, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;log2&#39;,
  3,
  &#39;0.3259&#39;,
  0.82037735849056603),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;auto&#39;,
  6,
  &#39;0.3222&#39;,
  0.67471698113207546),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;auto&#39;,
  7,
  &#39;0.3222&#39;,
  0.65962264150943395),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;sqrt&#39;,
  6,
  &#39;0.3222&#39;,
  0.67471698113207546),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;sqrt&#39;,
  7,
  &#39;0.3222&#39;,
  0.65962264150943395),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;auto&#39;,
  6,
  &#39;0.3222&#39;,
  0.66339622641509433),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;sqrt&#39;,
  6,
  &#39;0.3222&#39;,
  0.66339622641509433),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;auto&#39;,
  6,
  &#39;0.3222&#39;,
  0.6807547169811321),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;auto&#39;,
  7,
  &#39;0.3222&#39;,
  0.60452830188679241),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;sqrt&#39;,
  6,
  &#39;0.3222&#39;,
  0.6807547169811321),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;sqrt&#39;,
  7,
  &#39;0.3222&#39;,
  0.60452830188679241),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;auto&#39;,
  5,
  &#39;0.3222&#39;,
  0.72754716981132073),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;sqrt&#39;,
  5,
  &#39;0.3222&#39;,
  0.72754716981132073),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;log2&#39;,
  6,
  &#39;0.3222&#39;,
  0.67547169811320762),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;auto&#39;,
  5,
  &#39;0.3222&#39;,
  0.72754716981132073),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;sqrt&#39;,
  5,
  &#39;0.3222&#39;,
  0.72754716981132073),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;log2&#39;,
  6,
  &#39;0.3222&#39;,
  0.67698113207547173),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;auto&#39;,
  5,
  &#39;0.3222&#39;,
  0.72830188679245289),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;sqrt&#39;,
  5,
  &#39;0.3222&#39;,
  0.72830188679245289),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;log2&#39;,
  6,
  &#39;0.3222&#39;,
  0.67773584905660378),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;auto&#39;,
  5,
  &#39;0.3185&#39;,
  0.78188679245283033),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=5, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;sqrt&#39;,
  5,
  &#39;0.3185&#39;,
  0.78188679245283033),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;auto&#39;,
  7,
  &#39;0.3185&#39;,
  0.60679245283018868),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;sqrt&#39;,
  7,
  &#39;0.3185&#39;,
  0.60679245283018868),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  40,
  &#39;log2&#39;,
  6,
  &#39;0.3148&#39;,
  0.76150943396226412),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;log2&#39;,
  6,
  &#39;0.3148&#39;,
  0.74415094339622645),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;auto&#39;,
  6,
  &#39;0.3148&#39;,
  0.66415094339622649),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;sqrt&#39;,
  6,
  &#39;0.3148&#39;,
  0.66415094339622649),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;auto&#39;,
  6,
  &#39;0.3148&#39;,
  0.66943396226415097),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;sqrt&#39;,
  6,
  &#39;0.3148&#39;,
  0.66943396226415097),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;auto&#39;,
  7,
  &#39;0.3111&#39;,
  0.62641509433962261),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  60,
  &#39;sqrt&#39;,
  7,
  &#39;0.3111&#39;,
  0.62641509433962261),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;log2&#39;,
  6,
  &#39;0.3111&#39;,
  0.74867924528301888),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  90,
  &#39;log2&#39;,
  7,
  &#39;0.3111&#39;,
  0.62867924528301888),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;auto&#39;,
  7,
  &#39;0.3111&#39;,
  0.62037735849056608),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;sqrt&#39;,
  7,
  &#39;0.3111&#39;,
  0.62037735849056608),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;auto&#39;,
  6,
  &#39;0.3111&#39;,
  0.6724528301886793),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;auto&#39;,
  7,
  &#39;0.3111&#39;,
  0.60830188679245289),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=6, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;sqrt&#39;,
  6,
  &#39;0.3111&#39;,
  0.6724528301886793),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;sqrt&#39;,
  7,
  &#39;0.3111&#39;,
  0.60830188679245289),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;auto&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;auto&#39;,
  7,
  &#39;0.3111&#39;,
  0.60754716981132084),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;sqrt&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;sqrt&#39;,
  7,
  &#39;0.3111&#39;,
  0.60754716981132084),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  5000,
  &#39;log2&#39;,
  7,
  &#39;0.3074&#39;,
  0.62113207547169813),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  100,
  &#39;log2&#39;,
  7,
  &#39;0.3037&#39;,
  0.61056603773584905),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  1000,
  &#39;log2&#39;,
  7,
  &#39;0.3037&#39;,
  0.60075471698113214),
 (RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
              max_depth=7, max_features=&#39;log2&#39;, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,
              oob_score=False, random_state=0, verbose=0, warm_start=False),
  2000,
  &#39;log2&#39;,
  7,
  &#39;0.3037&#39;,
  0.62113207547169813)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[369]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_rf_result</span> <span class="o">=</span> <span class="n">rf_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_rf_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=3, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,
            oob_score=False, random_state=0, verbose=0, warm_start=False), 40, &#39;auto&#39;, 3, &#39;0.3481&#39;, 0.81433962264150939)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[370]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_rf_model</span> <span class="o">=</span> <span class="n">best_rf_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_rf_model</span> <span class="o">=</span> <span class="n">best_rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.47777777778
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[371]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[ 0.037794    0.04134552  0.0810511   0.15799053  0.12667703  0.33696219
   0.07172005  0.06360817  0.02906457  0.00861552  0.04517131]
 [ 0.0317589   0.02746014  0.04240984  0.13615567  0.12928781  0.34644488
   0.08536066  0.08555521  0.0400309   0.01227162  0.06326436]
 [ 0.0299223   0.0180217   0.03360752  0.17642014  0.14916486  0.28758057
   0.09755792  0.08362591  0.0404012   0.01998417  0.06371372]
 [ 0.04156436  0.02741359  0.05705389  0.14171847  0.13672469  0.34018336
   0.08785312  0.07537955  0.04012328  0.01363228  0.0383534 ]
 [ 0.02729711  0.01906506  0.02240029  0.0864641   0.09085905  0.33668817
   0.09152521  0.12495486  0.07482323  0.02754979  0.09837313]
 [ 0.01261111  0.00719262  0.00925334  0.04176916  0.05503545  0.1780624
   0.13145728  0.16474736  0.1857275   0.06627385  0.14786994]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[372]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[5 5 5 5 5 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 4 5 5 5 5 5 5 5 5 3 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 8 5 5 5 3
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3
 5 5 5 5 3 5 5 5 5 5 5 5 5 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 7 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 5 5 4 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5]
예측:
[ 5.  5.  5.  5.  5.  8.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  3.  5.  5.
  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  8.  5.  5.
  5.  3.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  8.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  3.  5.  5.  5.  5.  3.  5.  5.  5.  5.  5.  5.  5.  5.  8.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  7.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  3.  5.  5.  5.  4.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  3.  3.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[445]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Random Forest Classifier은 Decision Function이 없어 predict_proba만 실행한다. </span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_rf_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
Validation set의 예측: [ 5.  5.  5.  5.  5.  8.  5.  5.  5.  5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.34
Test set의 예측: [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[452]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 전체 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 전체 예측: [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.   1.   4.   9.   8.   0.
  10.  10.  10.  10.   9.   3.   7.   8.   7.   7.   0.   2.   3.   2.  10.
   5.  10.   0.   2.   0.   3.   3.   3.   6.   6.   2.   6.  10.   5.   2.
   0.   8.  10.   7.   8.   8.  10.   9.   1.   8.   0.   5.   4.   9.   7.
   2.   2.   7.   7.   2.   2.   0.   0.   5.   0.   1.   1.   9.   1.   1.
   2.   0.  10.   1.   3.   6.   0.   4.   8.   5.   5.   3.   1.   3.   4.
   0.   0.   5.  10.   6.   3.   5.   5.   4.   5.   4.   3.  10.   6.   5.
   5.   3.  10.  10.  10.   2.  10.  10.   3.   7.   1.   3.   7.   6.   5.
   6.   6.   4.   8.   7.   5.   8.   3.   3.   2.   0.   5.   0.  10.   6.
   6.   6.   6.   5.   7.   0.   7.   1.   3.   0.   0.   5.   7.   5.   1.
   0.   7.   5.   5.   7.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.6.-SVM">2.6. SVM<a class="anchor-link" href="#2.6.-SVM">&#182;</a></h2><p>Manual for <code>Support Vector Machines</code>: <a href="http://scikit-learn.org/stable/modules/svm.html">click</a></p>
<p>다음 parameter들에 대해 validation data에 대한 Score값과 AUC값을 이용해 최적 모형 parameter를 찾는다.</p>
<ol>
<li>gamma</li>
<li>C</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[161]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gamma_set</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">c_set</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[162]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result6</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">gamma_set</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="n">c_set</span><span class="p">:</span>
        <span class="n">svm_model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">decision_function_shape</span><span class="o">=</span><span class="s1">&#39;ovo&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">probability</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
        <span class="n">svm_model</span> <span class="o">=</span> <span class="n">svm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
        <span class="n">Y_val_score</span> <span class="o">=</span> <span class="n">svm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">val_proba</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svm_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">))</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">Y_val_score</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">result6</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">svm_model</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span><span class="n">val_proba</span><span class="p">,</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[163]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result6</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[164]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[164]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.1, 1, &#39;0.3370&#39;, 0.67320754716981135),
 (SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 1, 1, &#39;0.3296&#39;, 0.75471698113207553),
 (SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 1, 10, &#39;0.3296&#39;, 0.6807547169811321),
 (SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 1, 100, &#39;0.3296&#39;, 0.64226415094339617),
 (SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=10, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 10, 1, &#39;0.3296&#39;, 0.71471698113207549),
 (SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=10, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 10, 10, &#39;0.3296&#39;, 0.7011320754716982),
 (SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=10, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 10, 100, &#39;0.3296&#39;, 0.74188679245283018),
 (SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=100, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 100, 1, &#39;0.3296&#39;, 0.68679245283018864),
 (SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=100, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 100, 10, &#39;0.3296&#39;, 0.68830188679245285),
 (SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=100, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 100, 100, &#39;0.3296&#39;, 0.68830188679245285),
 (SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.001, 0.001, &#39;0.3259&#39;, 0.77207547169811319),
 (SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.001, 0.01, &#39;0.3259&#39;, 0.74641509433962261),
 (SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.001, 0.1, &#39;0.3259&#39;, 0.77735849056603779),
 (SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.001, 1, &#39;0.3259&#39;, 0.82188679245283025),
 (SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.001, 10, &#39;0.3259&#39;, 0.79471698113207556),
 (SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.01, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.01, 0.001, &#39;0.3259&#39;, 0.77811320754716973),
 (SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.01, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.01, 0.01, &#39;0.3259&#39;, 0.76452830188679255),
 (SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.01, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.01, 0.1, &#39;0.3259&#39;, 0.77283018867924524),
 (SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.01, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.01, 1, &#39;0.3259&#39;, 0.77283018867924524),
 (SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.1, 0.001, &#39;0.3259&#39;, 0.64000000000000001),
 (SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.1, 0.01, &#39;0.3259&#39;, 0.6807547169811321),
 (SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.1, 0.1, &#39;0.3259&#39;, 0.67094339622641508),
 (SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 1, 0.001, &#39;0.3259&#39;, 0.69735849056603771),
 (SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 1, 0.01, &#39;0.3259&#39;, 0.60075471698113203),
 (SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 1, 0.1, &#39;0.3259&#39;, 0.57358490566037734),
 (SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=10, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 10, 0.001, &#39;0.3259&#39;, 0.58264150943396231),
 (SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=10, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 10, 0.01, &#39;0.3259&#39;, 0.7181132075471699),
 (SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=10, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 10, 0.1, &#39;0.3259&#39;, 0.59094339622641523),
 (SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=100, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 100, 0.001, &#39;0.3259&#39;, 0.68830188679245285),
 (SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=100, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 100, 0.01, &#39;0.3259&#39;, 0.68905660377358491),
 (SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=100, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 100, 0.1, &#39;0.3259&#39;, 0.69056603773584901),
 (SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.01, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.01, 10, &#39;0.3148&#39;, 0.75698113207547169),
 (SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.001, 100, &#39;0.3074&#39;, 0.78792452830188675),
 (SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.01, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.01, 100, &#39;0.2963&#39;, 0.73433962264150943),
 (SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.1, 10, &#39;0.2741&#39;, 0.57811320754716977),
 (SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
    max_iter=10000, probability=True, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 0.1, 100, &#39;0.2630&#39;, 0.6724528301886793)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[165]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_svm_result</span> <span class="o">=</span> <span class="n">svm_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_svm_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovo&#39;, degree=3, gamma=0.1, kernel=&#39;rbf&#39;,
  max_iter=10000, probability=True, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 0.1, 1, &#39;0.3370&#39;, 0.67320754716981135)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[166]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_svm_model</span> <span class="o">=</span> <span class="n">best_svm_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">best_svm_model</span> <span class="o">=</span> <span class="n">best_svm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.41481481481
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[167]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[ 0.03209334  0.03704663  0.07595958  0.1672928   0.12689136  0.37956085
   0.06020029  0.05359231  0.02573618  0.00974114  0.03188551]
 [ 0.03236424  0.02113014  0.03650773  0.1447285   0.12281208  0.4516385
   0.0553937   0.05106364  0.02763964  0.01017355  0.04654828]
 [ 0.03337782  0.01505569  0.03225198  0.17332638  0.15115217  0.35532731
   0.07319967  0.06985921  0.03595549  0.00993884  0.05055545]
 [ 0.03269102  0.02321026  0.05559016  0.15125295  0.14084524  0.39428478
   0.06125568  0.08062878  0.02552933  0.00670129  0.02801052]
 [ 0.02737244  0.01370363  0.02056459  0.07529734  0.08683564  0.26291957
   0.09831925  0.16135768  0.08147286  0.02749569  0.1446613 ]
 [ 0.01826279  0.00902472  0.0099281   0.01610559  0.02908623  0.03503992
   0.17253747  0.2001462   0.2054169   0.06558695  0.23886513]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[168]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[ 5  5  5  5  5 10  5  5  5  5  5  5  5  7  5  3  5  5  5  8  5  5  5  5  5
  5  5  5  5  5  5  5  5  5  5  3  5  5  8  5  5  5  3  5  5  5  5  5  5  5
  3  3  5  5  5  7  4  7  8  5  5  5  5  5  5  5  5  5  5  8  7  5  5  3  5
  5  7  5  5  5  5  5  5  5  5  5  5  5  5  5  5  3  5  5  5  5  5  5  5  3
  5  5  5  5  5  5  5  3  5  5  5  8  3  3  5  3  5  5  5  5  7  8  5  5  5
  5  5  3  5  5  5  8  5  5  3  5  5  5  5  7  7  5  5  5  5  5  5  3  5  5
  5  7  3  3  5  5  5  5  5 10  5  7  5  5  5  5  5  7  5  5  5  5 10  5  8
  7  7 10  3  5  5  5  5  5  5  5  5  5  5  5  5  6  5  5  5  3  5  5  5  7
  5  5  5  5  5  5  5  7  5  5  3  7  5  3  3  5  5  7  3  5  5  5  5  5  3
  5  5  8  5  5  5  5  3  5  3  3  5  7  7  5  5  5  5  8  5  5  5  5  5  5
  5  5 10  5  5  5  7  6  5  3  5  5  5  5  5  5  5  3  5  8]
예측:
[  5.   5.   5.   5.   5.   8.   5.   5.   5.   5.   5.   5.   5.   8.   5.
   3.   5.   5.   5.   8.   5.   5.   5.   5.   5.   8.   5.   5.   5.   5.
   5.   5.   5.   5.   5.   4.   7.   5.   8.   5.   3.   5.   4.   5.   5.
   5.   5.   5.   5.   5.   3.   4.   5.   5.   5.   7.   4.   7.   8.   5.
   5.   5.   5.   5.   5.   7.   5.   5.   5.   8.   6.   5.   5.   3.   5.
   5.   7.   5.   5.   5.   5.   5.   5.   5.   5.   5.   5.   5.   5.   5.
   5.   3.   5.   7.   5.   5.   5.   5.   5.   3.   5.   5.   5.   5.   5.
   7.   5.   3.   5.   5.   5.   8.   4.   4.   5.   3.   5.   5.   5.   5.
   7.   8.   5.   5.   5.   5.   5.   3.   5.   5.   5.   8.   5.   5.   3.
   5.   5.   5.   5.   8.   7.   5.   5.   5.   5.   5.   4.   3.   5.   5.
   5.   8.   3.   3.   5.   5.   5.   5.   5.  10.   5.   7.   5.   5.   5.
   5.   5.   7.   5.   5.   5.   5.   7.   5.   8.   8.   7.  10.   3.   5.
   5.   5.   5.   5.  10.   5.   5.   5.   5.   5.   5.   6.   5.   5.   5.
   3.   5.   5.   5.   4.   5.   5.   5.   7.   5.   5.   5.   8.   5.   5.
   3.   7.   5.   3.   3.   5.   5.   5.   3.   5.   5.   5.   5.   5.   3.
   5.   5.   8.   5.   5.   5.   5.   3.   5.   3.   3.   5.   7.   7.   5.
   5.   5.   5.   8.   5.   5.   5.   5.   5.   5.   5.   5.   8.   5.   5.
   5.   6.   6.   5.   3.   5.   5.   5.   5.   5.   5.   5.   3.   5.   8.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[171]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="n">argmax_dec_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 결정 함수의 인덱스: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">argmax_dec_func</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_svm_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
가장 큰 결정 함수의 인덱스: [31 40 38 43 50 52 43 43 41 43]
Validation set의 예측: [ 5.  5.  5.  5.  5.  8.  5.  5.  5.  5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.34
Test set의 예측: [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[453]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_logreg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 예측: [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.   1.   4.   9.   8.   0.
  10.  10.  10.  10.   9.   3.   7.   8.   7.   7.   0.   2.   3.   2.  10.
   5.  10.   0.   2.   0.   3.   3.   3.   6.   6.   2.   6.  10.   5.   2.
   0.   8.  10.   7.   8.   8.  10.   9.   1.   8.   0.   5.   4.   9.   7.
   2.   2.   7.   7.   2.   2.   0.   0.   5.   0.   1.   1.   9.   1.   1.
   2.   0.  10.   1.   3.   6.   0.   4.   8.   5.   5.   3.   1.   3.   4.
   0.   0.   5.  10.   6.   3.   5.   5.   4.   5.   4.   3.  10.   6.   5.
   5.   3.  10.  10.  10.   2.  10.  10.   3.   7.   1.   3.   7.   6.   5.
   6.   6.   4.   8.   7.   5.   8.   3.   3.   2.   0.   5.   0.  10.   6.
   6.   6.   6.   5.   7.   0.   7.   1.   3.   0.   0.   5.   7.   5.   1.
   0.   7.   5.   5.   7.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.7.-Xgboost">2.7. Xgboost<a class="anchor-link" href="#2.7.-Xgboost">&#182;</a></h2><p>Manual for <code>Xgboost</code>: <a href="http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html">click</a></p>
<p>다음 parameter들에 대해 data에 대한 Score값과 AUC값을 이용해 최적 모형 parameter를 찾는다.</p>
<ol>
<li>max_depth</li>
<li>min_child_weight</li>
<li>gamma</li>
<li>subsample</li>
<li>colsample_bytree</li>
<li>reg_alpha </li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[173]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="k">import</span> <span class="n">XGBClassifier</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Grid-Search-CV-&#47484;-&#53685;&#54644;-parameter&#46308;&#51012;-&#52572;&#51201;&#51032;-&#44050;&#51004;&#47196;-&#51312;&#51221;&#54644;&#51456;&#45796;.">Grid Search CV &#47484; &#53685;&#54644; parameter&#46308;&#51012; &#52572;&#51201;&#51032; &#44050;&#51004;&#47196; &#51312;&#51221;&#54644;&#51456;&#45796;.<a class="anchor-link" href="#Grid-Search-CV-&#47484;-&#53685;&#54644;-parameter&#46308;&#51012;-&#52572;&#51201;&#51032;-&#44050;&#51004;&#47196;-&#51312;&#51221;&#54644;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[174]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># max_depth와 min_child_weight 범위 설정을 통해 최적 parameter 값을 찾는다. </span>

<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span>
 <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[175]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Grid Search를 통해 param_test1에 대한 최적 값을 찾는다. </span>

<span class="n">grid_search1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">XGBClassifier</span><span class="p">(),</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[175]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,
       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,
       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;binary:logistic&#39;, reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=1),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={&#39;max_depth&#39;: range(1, 20), &#39;min_child_weight&#39;: range(1, 20)},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=None, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[192]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최적 매개변수: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최고 교차 검증 점수: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search1</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>최적 매개변수: {&#39;max_depth&#39;: 2, &#39;min_child_weight&#39;: 19}
최고 교차 검증 점수: 0.36
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[177]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># gamma 범위 설정을 통해 최적 parameter 값을 찾는다. </span>

<span class="n">param_test2</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="mf">100.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[178]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Grid Search를 통해 param_test2에 대한 최적 값을 찾는다. </span>

<span class="n">grid_search2</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">8</span><span class="p">),</span> <span class="n">param_test2</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[178]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,
       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;binary:logistic&#39;, reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=1),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={&#39;gamma&#39;: [0.0, 0.01, 0.02, 0.03, 0.04]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=None, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[191]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최적 매개변수: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search2</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최고 교차 검증 점수: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search2</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>최적 매개변수: {&#39;gamma&#39;: 0.02}
최고 교차 검증 점수: 0.34
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[180]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># subsample 과 colsample_bytree 범위 설정을 통해 최적 parameter 값을 찾는다. </span>

<span class="n">param_test3</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;subsample&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">100.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)],</span>
 <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">100.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[181]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Grid Search를 통해 param_test3에 대한 최적 값을 찾는다. </span>

<span class="n">grid_search3</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">8</span><span class="p">),</span> <span class="n">param_test3</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[181]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,
       gamma=0.01, learning_rate=0.1, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;binary:logistic&#39;, reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=1),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={&#39;subsample&#39;: [0.06, 0.07, 0.08, 0.09], &#39;colsample_bytree&#39;: [0.06, 0.07, 0.08, 0.09]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=None, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[190]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최적 매개변수: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search3</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최고 교차 검증 점수: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search3</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>최적 매개변수: {&#39;colsample_bytree&#39;: 0.06, &#39;subsample&#39;: 0.08}
최고 교차 검증 점수: 0.31
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[183]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># reg_alpha 범위 설정을 통해 최적 parameter 값을 찾는다. </span>

<span class="n">param_test4</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[184]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Grid Search를 통해 param_test4에 대한 최적 값을 찾는다. </span>

<span class="n">grid_search4</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">colsample_bytree</span> <span class="o">=</span> <span class="mf">0.06</span><span class="p">,</span> <span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.09</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">8</span><span class="p">),</span> <span class="n">param_test4</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[184]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.06,
       gamma=0.01, learning_rate=0.1, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;binary:logistic&#39;, reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=0.09),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={&#39;reg_alpha&#39;: [1e-05, 0.01, 0.1, 1, 100, 0, 0.001, 0.005, 0.01, 0.05]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=None, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[189]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최적 매개변수: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search4</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최고 교차 검증 점수: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search4</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>최적 매개변수: {&#39;reg_alpha&#39;: 1e-05}
최고 교차 검증 점수: 0.31
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[186]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 최적 parameter 값을 이용해 Grid Search를 한 번 더 한다. </span>

<span class="n">param_test5</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:[</span><span class="mf">1e-05</span><span class="p">],</span> 
 <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:[</span><span class="mf">0.06</span><span class="p">],</span> 
 <span class="s1">&#39;subsample&#39;</span><span class="p">:[</span><span class="mf">0.09</span><span class="p">],</span> 
 <span class="s1">&#39;gamma&#39;</span><span class="p">:[</span><span class="mf">0.01</span><span class="p">],</span> 
 <span class="s1">&#39;max_depth&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">],</span>
 <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:[</span><span class="mi">8</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[187]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">reg_alpha</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">,</span> <span class="n">colsample_bytree</span> <span class="o">=</span> <span class="mf">0.06</span><span class="p">,</span> <span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.09</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">min_child_weight</span><span class="o">=</span> <span class="mi">8</span><span class="p">),</span> <span class="n">param_test5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[187]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.06,
       gamma=0.01, learning_rate=0.1, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;binary:logistic&#39;, reg_alpha=1e-05, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=0.09),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={&#39;reg_alpha&#39;: [1e-05], &#39;colsample_bytree&#39;: [0.06], &#39;subsample&#39;: [0.09], &#39;gamma&#39;: [0.01], &#39;max_depth&#39;: [2], &#39;min_child_weight&#39;: [8]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=None, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[188]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최고 성능 모델:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;최고 교차 검증 점수: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>최고 성능 모델:
XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.06,
       gamma=0.01, learning_rate=0.1, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;multi:softprob&#39;, reg_alpha=1e-05, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=0.09)
최고 교차 검증 점수: 0.31
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Xgboost-Classifier&#50640;-&#52572;&#51201;-parameter-&#44050;&#46308;&#51012;--apply&#54644;-fitting-&#49884;&#53416;&#45796;.">Xgboost Classifier&#50640; &#52572;&#51201; parameter &#44050;&#46308;&#51012;  apply&#54644; fitting &#49884;&#53416;&#45796;.<a class="anchor-link" href="#Xgboost-Classifier&#50640;-&#52572;&#51201;-parameter-&#44050;&#46308;&#51012;--apply&#54644;-fitting-&#49884;&#53416;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[193]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb1</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.09</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.06</span><span class="p">,</span>
 <span class="n">reg_alpha</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;multi:softmax&#39;</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[194]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[194]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.06,
       gamma=0.01, learning_rate=0.1, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=1000, nthread=4,
       objective=&#39;multi:softprob&#39;, reg_alpha=1e-05, reg_lambda=1,
       scale_pos_weight=1, seed=27, silent=True, subsample=0.09)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[195]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">mean_squared_error</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MSE-&#44050;&#51012;-&#52769;&#51221;&#54620;&#45796;.">MSE &#44050;&#51012; &#52769;&#51221;&#54620;&#45796;.<a class="anchor-link" href="#MSE-&#44050;&#51012;-&#52769;&#51221;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[196]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">xgb1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[196]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>4.8296296296296299</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[197]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">from</span> <span class="nn">matplotlib.pylab</span> <span class="k">import</span> <span class="n">rcParams</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">4</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Feature-Importance&#47484;-&#44536;&#47000;&#54532;&#47196;-&#44536;&#47140;-&#54869;&#51064;&#54620;&#45796;.">Feature Importance&#47484; &#44536;&#47000;&#54532;&#47196; &#44536;&#47140; &#54869;&#51064;&#54620;&#45796;.<a class="anchor-link" href="#Feature-Importance&#47484;-&#44536;&#47000;&#54532;&#47196;-&#44536;&#47140;-&#54869;&#51064;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[198]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">xgb1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[198]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a47fd49160&gt;</pre>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAtQAAAEWCAYAAABG5QDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[201]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Predict training set:</span>
<span class="n">dtrain_predictions</span> <span class="o">=</span> <span class="n">xgb1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">)</span>
<span class="n">dtrain_predprob</span> <span class="o">=</span> <span class="n">xgb1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">)</span>
<span class="c1">#Print model report:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Model Report&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy : </span><span class="si">%.4g</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">train_Y_train</span><span class="p">,</span> <span class="n">dtrain_predictions</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC Score (Train): </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">dtrain_predprob</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Model Report
Accuracy : 0.3132
AUC Score (Train): 0.495268
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#49457;&#45733;&#51012;-&#51328;-&#45908;-&#50732;&#47532;&#44592;-&#50948;&#54644;-Learning-rate&#51012;-&#45230;&#52628;&#44256;-n_estimator&#47484;-&#53685;&#54644;-tree&#47484;-&#45908;-&#52628;&#44032;&#54620;&#45796;">&#49457;&#45733;&#51012; &#51328; &#45908; &#50732;&#47532;&#44592; &#50948;&#54644; Learning rate&#51012; &#45230;&#52628;&#44256; n_estimator&#47484; &#53685;&#54644; tree&#47484; &#45908; &#52628;&#44032;&#54620;&#45796;<a class="anchor-link" href="#&#49457;&#45733;&#51012;-&#51328;-&#45908;-&#50732;&#47532;&#44592;-&#50948;&#54644;-Learning-rate&#51012;-&#45230;&#52628;&#44256;-n_estimator&#47484;-&#53685;&#54644;-tree&#47484;-&#45908;-&#52628;&#44032;&#54620;&#45796;">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[202]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb2</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.09</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.06</span><span class="p">,</span>
 <span class="n">reg_alpha</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;multi:softmax&#39;</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[203]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[203]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.06,
       gamma=0.01, learning_rate=0.01, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=10000, nthread=4,
       objective=&#39;multi:softprob&#39;, reg_alpha=1e-05, reg_lambda=1,
       scale_pos_weight=1, seed=27, silent=True, subsample=0.09)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MSE-&#44050;&#51012;-&#52769;&#51221;&#54620;&#45796;.">MSE &#44050;&#51012; &#52769;&#51221;&#54620;&#45796;.<a class="anchor-link" href="#MSE-&#44050;&#51012;-&#52769;&#51221;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[204]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">xgb2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[204]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>4.7555555555555555</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Feature-Importance&#47484;-&#44536;&#47000;&#54532;&#47196;-&#44536;&#47140;-&#54869;&#51064;&#54620;&#45796;.">Feature Importance&#47484; &#44536;&#47000;&#54532;&#47196; &#44536;&#47140; &#54869;&#51064;&#54620;&#45796;.<a class="anchor-link" href="#Feature-Importance&#47484;-&#44536;&#47000;&#54532;&#47196;-&#44536;&#47140;-&#54869;&#51064;&#54620;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[205]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">xgb2</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[205]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a47fc7d908&gt;</pre>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAtQAAAEWCAYAAABG5QDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[216]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Predict training set:</span>
<span class="n">dtrain_predictions</span> <span class="o">=</span> <span class="n">xgb2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)</span>
<span class="n">dtrain_predprob</span> <span class="o">=</span> <span class="n">xgb2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)</span>
<span class="c1">#Print model report:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Model Report&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy : </span><span class="si">%.4g</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">,</span> <span class="n">dtrain_predictions</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC Score (Train): </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">dtrain_predprob</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Model Report
Accuracy : 0.3296
AUC Score (Train): 0.492288
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[218]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xgb2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xgb2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xgb2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Validation set의 예측: [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.33
Test set의 예측: [ 4.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[263]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_xgb_result</span> <span class="o">=</span> <span class="n">xgb2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_xgb_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.06,
       gamma=0.01, learning_rate=0.01, max_delta_step=0, max_depth=2,
       min_child_weight=8, missing=None, n_estimators=10000, nthread=4,
       objective=&#39;multi:softprob&#39;, reg_alpha=1e-05, reg_lambda=1,
       scale_pos_weight=1, seed=27, silent=True, subsample=0.09)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Best Model&#51032; MAE &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Model&#51032;-MAE-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[357]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_xgb_model</span> <span class="o">=</span> <span class="n">best_xgb_result</span>
<span class="n">best_xgb_model</span> <span class="o">=</span> <span class="n">best_xgb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X_train</span><span class="p">,</span> <span class="n">train_Y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">train_Y_val</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.54814814815
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[266]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predict_proba 결과 중 앞부분 6개에 대해서만 확인한다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측 확률:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]))</span>

<span class="c1"># 행 방향으로 확률을 더하면 모두 1이 된다.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>예측 확률:
[[ 0.04597149  0.04575544  0.04738645  0.13210092  0.13366631  0.23773444
   0.09812886  0.11085046  0.05152455  0.04585176  0.05102929]
 [ 0.04475919  0.04454884  0.04613684  0.12861733  0.13014142  0.25783595
   0.09554113  0.10792726  0.05016581  0.04464261  0.04968361]
 [ 0.04911323  0.04888242  0.05062489  0.14112884  0.14280121  0.18564042
   0.1048351   0.11842611  0.0550458   0.04898531  0.05451669]
 [ 0.04324971  0.04304646  0.0445809   0.12427977  0.12545304  0.2831645
   0.09231906  0.10428747  0.04847399  0.04313706  0.04800806]
 [ 0.04243613  0.0422367   0.04374228  0.12194193  0.12338693  0.29635522
   0.09058244  0.1023257   0.04756214  0.0423256   0.04710497]
 [ 0.04450689  0.04429772  0.04587676  0.12789232  0.12940782  0.26201952
   0.09500258  0.10731888  0.04988303  0.04439097  0.04940355]]
합: [ 1.  1.  1.  1.  1.  1.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">predict_proba&#51032; &#44208;&#44284;&#50640; argmax &#54632;&#49688;&#47484; &#51201;&#50857;&#54644;&#49436; &#50696;&#52769;&#51012; &#51116;&#50672;&#54624; &#49688; &#51080;&#45796;.<a class="anchor-link" href="#predict_proba&#51032;-&#44208;&#44284;&#50640;-argmax-&#54632;&#49688;&#47484;-&#51201;&#50857;&#54644;&#49436;-&#50696;&#52769;&#51012;-&#51116;&#50672;&#54624;-&#49688;-&#51080;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[267]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;가장 큰 예측 확률의 인덱스:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;예측:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>가장 큰 예측 확률의 인덱스:
[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5 5 5 4 5 5 4 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 4 5 5 5 5 5 5 5 5 5]
예측:
[ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.  5.  5.  4.  5.
  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[269]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;훈련 데이터에 있는 클래스 종류: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;실제 Validation set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_Y_val</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Set의 정확도: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_X_val</span><span class="p">,</span> <span class="n">train_Y_val</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
Validation set의 예측: [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
실제 Validation set: [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
Validation Set의 정확도: 0.33
Test set의 예측: [ 4.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[454]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set의 전체 예측: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_xgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set의 예측: [ 4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  4.  5.  5.  5.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  4.  5.  5.  5.  5.  5.  5.  5.  5.
  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.8-SoftMax">2.8 SoftMax<a class="anchor-link" href="#2.8-SoftMax">&#182;</a></h2><p>Manual for <code>Soft Max</code>: <a href="http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/">click</a></p>
<p>SoftMax 모델을 통해 X와 Y variable들을 One Hot Encoding 해주고 최적 Accuracy를 찾아낸다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[270]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">777</span><span class="p">)</span>  <span class="c1"># for reproducibility</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[271]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Predicting animal type based on various features</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;new_data.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="n">xy</span><span class="p">[:,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[272]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(899, 15) (899, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Y-&#44050;&#51032;-&#53364;&#47000;&#49828;&#44032;-11&#44060;&#51060;&#48064;&#47196;-nb_classes&#47484;-11&#44060;&#47196;-&#51105;&#45716;&#45796;.">Y &#44050;&#51032; &#53364;&#47000;&#49828;&#44032; 11&#44060;&#51060;&#48064;&#47196; nb_classes&#47484; 11&#44060;&#47196; &#51105;&#45716;&#45796;.<a class="anchor-link" href="#Y-&#44050;&#51032;-&#53364;&#47000;&#49828;&#44032;-11&#44060;&#51060;&#48064;&#47196;-nb_classes&#47484;-11&#44060;&#47196;-&#51105;&#45716;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[273]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nb_classes</span> <span class="o">=</span> <span class="mi">11</span>  <span class="c1"># 0 ~ 10</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[274]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># 0 ~ 10</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[275]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Y_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">nb_classes</span><span class="p">)</span>  <span class="c1"># one hot</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;one_hot&quot;</span><span class="p">,</span> <span class="n">Y_one_hot</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>one_hot Tensor(&#34;one_hot:0&#34;, shape=(?, 1, 11), dtype=float32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[276]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Y_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Y_one_hot</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_classes</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reshape&quot;</span><span class="p">,</span> <span class="n">Y_one_hot</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>reshape Tensor(&#34;Reshape:0&#34;, shape=(?, 11), dtype=float32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[277]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">15</span><span class="p">,</span> <span class="n">nb_classes</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">nb_classes</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;bias&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[278]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># tf.nn.softmax computes softmax activations</span>
<span class="c1"># softmax = exp(logits) / reduce_sum(exp(logits), dim)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
<span class="n">hypothesis</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[279]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Cross entropy cost/loss</span>
<span class="n">cost_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
                                                 <span class="n">labels</span><span class="o">=</span><span class="n">Y_one_hot</span><span class="p">)</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">cost_i</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_one_hot</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[304]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Launch graph</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    <span class="n">result8</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50000</span><span class="p">):</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">y_data</span><span class="p">})</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                                 <span class="n">X</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">y_data</span><span class="p">})</span>
            <span class="n">result8</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step: </span><span class="si">{:5}</span><span class="se">\t</span><span class="s2">Loss: </span><span class="si">{:.3f}</span><span class="se">\t</span><span class="s2">Acc: </span><span class="si">{:.2%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

    <span class="c1"># Let&#39;s see if we can predict</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">x_data</span><span class="p">})</span>
    <span class="c1"># y_data: (N,1) = flatten =&gt; (N, ) matches pred.shape</span>
    <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y_data</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">{}</span><span class="s2">] Prediction: </span><span class="si">{}</span><span class="s2"> True Y: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span> <span class="o">==</span> <span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">p</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Step:     0	Loss: 12.367	Acc: 8.34%
Step:   100	Loss: 2.730	Acc: 23.58%
Step:   200	Loss: 2.395	Acc: 23.69%
Step:   300	Loss: 2.233	Acc: 27.03%
Step:   400	Loss: 2.133	Acc: 29.48%
Step:   500	Loss: 2.063	Acc: 30.70%
Step:   600	Loss: 2.014	Acc: 30.81%
Step:   700	Loss: 1.977	Acc: 31.92%
Step:   800	Loss: 1.948	Acc: 32.70%
Step:   900	Loss: 1.926	Acc: 32.93%
Step:  1000	Loss: 1.909	Acc: 34.15%
Step:  1100	Loss: 1.895	Acc: 34.48%
Step:  1200	Loss: 1.884	Acc: 34.93%
Step:  1300	Loss: 1.875	Acc: 35.04%
Step:  1400	Loss: 1.868	Acc: 35.26%
Step:  1500	Loss: 1.862	Acc: 35.48%
Step:  1600	Loss: 1.857	Acc: 35.71%
Step:  1700	Loss: 1.852	Acc: 35.82%
Step:  1800	Loss: 1.848	Acc: 35.71%
Step:  1900	Loss: 1.845	Acc: 35.71%
Step:  2000	Loss: 1.842	Acc: 35.60%
Step:  2100	Loss: 1.840	Acc: 35.93%
Step:  2200	Loss: 1.837	Acc: 36.04%
Step:  2300	Loss: 1.835	Acc: 36.26%
Step:  2400	Loss: 1.834	Acc: 36.15%
Step:  2500	Loss: 1.832	Acc: 36.26%
Step:  2600	Loss: 1.830	Acc: 36.48%
Step:  2700	Loss: 1.829	Acc: 36.48%
Step:  2800	Loss: 1.828	Acc: 36.48%
Step:  2900	Loss: 1.827	Acc: 36.60%
Step:  3000	Loss: 1.826	Acc: 36.60%
Step:  3100	Loss: 1.825	Acc: 36.48%
Step:  3200	Loss: 1.824	Acc: 36.48%
Step:  3300	Loss: 1.823	Acc: 36.48%
Step:  3400	Loss: 1.822	Acc: 36.48%
Step:  3500	Loss: 1.822	Acc: 36.48%
Step:  3600	Loss: 1.821	Acc: 36.48%
Step:  3700	Loss: 1.821	Acc: 36.37%
Step:  3800	Loss: 1.820	Acc: 36.48%
Step:  3900	Loss: 1.819	Acc: 36.37%
Step:  4000	Loss: 1.819	Acc: 36.26%
Step:  4100	Loss: 1.818	Acc: 36.37%
Step:  4200	Loss: 1.818	Acc: 36.15%
Step:  4300	Loss: 1.818	Acc: 36.37%
Step:  4400	Loss: 1.817	Acc: 36.37%
Step:  4500	Loss: 1.817	Acc: 36.37%
Step:  4600	Loss: 1.816	Acc: 36.48%
Step:  4700	Loss: 1.816	Acc: 36.48%
Step:  4800	Loss: 1.816	Acc: 36.60%
Step:  4900	Loss: 1.815	Acc: 36.60%
Step:  5000	Loss: 1.815	Acc: 36.60%
Step:  5100	Loss: 1.815	Acc: 36.60%
Step:  5200	Loss: 1.815	Acc: 36.48%
Step:  5300	Loss: 1.814	Acc: 36.37%
Step:  5400	Loss: 1.814	Acc: 36.26%
Step:  5500	Loss: 1.814	Acc: 36.26%
Step:  5600	Loss: 1.814	Acc: 36.26%
Step:  5700	Loss: 1.813	Acc: 36.15%
Step:  5800	Loss: 1.813	Acc: 36.15%
Step:  5900	Loss: 1.813	Acc: 36.15%
Step:  6000	Loss: 1.813	Acc: 36.15%
Step:  6100	Loss: 1.812	Acc: 36.26%
Step:  6200	Loss: 1.812	Acc: 36.37%
Step:  6300	Loss: 1.812	Acc: 36.37%
Step:  6400	Loss: 1.812	Acc: 36.37%
Step:  6500	Loss: 1.812	Acc: 36.37%
Step:  6600	Loss: 1.812	Acc: 36.37%
Step:  6700	Loss: 1.811	Acc: 36.48%
Step:  6800	Loss: 1.811	Acc: 36.48%
Step:  6900	Loss: 1.811	Acc: 36.48%
Step:  7000	Loss: 1.811	Acc: 36.48%
Step:  7100	Loss: 1.811	Acc: 36.48%
Step:  7200	Loss: 1.811	Acc: 36.48%
Step:  7300	Loss: 1.810	Acc: 36.48%
Step:  7400	Loss: 1.810	Acc: 36.48%
Step:  7500	Loss: 1.810	Acc: 36.37%
Step:  7600	Loss: 1.810	Acc: 36.37%
Step:  7700	Loss: 1.810	Acc: 36.37%
Step:  7800	Loss: 1.810	Acc: 36.26%
Step:  7900	Loss: 1.810	Acc: 36.26%
Step:  8000	Loss: 1.810	Acc: 36.26%
Step:  8100	Loss: 1.809	Acc: 36.26%
Step:  8200	Loss: 1.809	Acc: 36.37%
Step:  8300	Loss: 1.809	Acc: 36.37%
Step:  8400	Loss: 1.809	Acc: 36.37%
Step:  8500	Loss: 1.809	Acc: 36.37%
Step:  8600	Loss: 1.809	Acc: 36.37%
Step:  8700	Loss: 1.809	Acc: 36.37%
Step:  8800	Loss: 1.809	Acc: 36.37%
Step:  8900	Loss: 1.809	Acc: 36.37%
Step:  9000	Loss: 1.809	Acc: 36.37%
Step:  9100	Loss: 1.808	Acc: 36.37%
Step:  9200	Loss: 1.808	Acc: 36.48%
Step:  9300	Loss: 1.808	Acc: 36.48%
Step:  9400	Loss: 1.808	Acc: 36.60%
Step:  9500	Loss: 1.808	Acc: 36.48%
Step:  9600	Loss: 1.808	Acc: 36.48%
Step:  9700	Loss: 1.808	Acc: 36.48%
Step:  9800	Loss: 1.808	Acc: 36.48%
Step:  9900	Loss: 1.808	Acc: 36.48%
Step: 10000	Loss: 1.808	Acc: 36.48%
Step: 10100	Loss: 1.808	Acc: 36.48%
Step: 10200	Loss: 1.808	Acc: 36.48%
Step: 10300	Loss: 1.808	Acc: 36.48%
Step: 10400	Loss: 1.807	Acc: 36.48%
Step: 10500	Loss: 1.807	Acc: 36.48%
Step: 10600	Loss: 1.807	Acc: 36.48%
Step: 10700	Loss: 1.807	Acc: 36.48%
Step: 10800	Loss: 1.807	Acc: 36.48%
Step: 10900	Loss: 1.807	Acc: 36.48%
Step: 11000	Loss: 1.807	Acc: 36.48%
Step: 11100	Loss: 1.807	Acc: 36.48%
Step: 11200	Loss: 1.807	Acc: 36.48%
Step: 11300	Loss: 1.807	Acc: 36.48%
Step: 11400	Loss: 1.807	Acc: 36.37%
Step: 11500	Loss: 1.807	Acc: 36.48%
Step: 11600	Loss: 1.807	Acc: 36.48%
Step: 11700	Loss: 1.807	Acc: 36.48%
Step: 11800	Loss: 1.807	Acc: 36.48%
Step: 11900	Loss: 1.807	Acc: 36.48%
Step: 12000	Loss: 1.807	Acc: 36.48%
Step: 12100	Loss: 1.807	Acc: 36.48%
Step: 12200	Loss: 1.806	Acc: 36.48%
Step: 12300	Loss: 1.806	Acc: 36.48%
Step: 12400	Loss: 1.806	Acc: 36.48%
Step: 12500	Loss: 1.806	Acc: 36.48%
Step: 12600	Loss: 1.806	Acc: 36.71%
Step: 12700	Loss: 1.806	Acc: 36.71%
Step: 12800	Loss: 1.806	Acc: 36.71%
Step: 12900	Loss: 1.806	Acc: 36.82%
Step: 13000	Loss: 1.806	Acc: 36.71%
Step: 13100	Loss: 1.806	Acc: 36.71%
Step: 13200	Loss: 1.806	Acc: 36.71%
Step: 13300	Loss: 1.806	Acc: 36.71%
Step: 13400	Loss: 1.806	Acc: 36.71%
Step: 13500	Loss: 1.806	Acc: 36.71%
Step: 13600	Loss: 1.806	Acc: 36.71%
Step: 13700	Loss: 1.806	Acc: 36.71%
Step: 13800	Loss: 1.806	Acc: 36.71%
Step: 13900	Loss: 1.806	Acc: 36.71%
Step: 14000	Loss: 1.806	Acc: 36.71%
Step: 14100	Loss: 1.806	Acc: 36.71%
Step: 14200	Loss: 1.806	Acc: 36.71%
Step: 14300	Loss: 1.806	Acc: 36.71%
Step: 14400	Loss: 1.806	Acc: 36.71%
Step: 14500	Loss: 1.806	Acc: 36.71%
Step: 14600	Loss: 1.806	Acc: 36.71%
Step: 14700	Loss: 1.806	Acc: 36.71%
Step: 14800	Loss: 1.805	Acc: 36.71%
Step: 14900	Loss: 1.805	Acc: 36.71%
Step: 15000	Loss: 1.805	Acc: 36.82%
Step: 15100	Loss: 1.805	Acc: 36.82%
Step: 15200	Loss: 1.805	Acc: 36.82%
Step: 15300	Loss: 1.805	Acc: 36.82%
Step: 15400	Loss: 1.805	Acc: 36.82%
Step: 15500	Loss: 1.805	Acc: 36.82%
Step: 15600	Loss: 1.805	Acc: 36.93%
Step: 15700	Loss: 1.805	Acc: 36.93%
Step: 15800	Loss: 1.805	Acc: 36.93%
Step: 15900	Loss: 1.805	Acc: 37.04%
Step: 16000	Loss: 1.805	Acc: 37.04%
Step: 16100	Loss: 1.805	Acc: 37.04%
Step: 16200	Loss: 1.805	Acc: 37.04%
Step: 16300	Loss: 1.805	Acc: 37.04%
Step: 16400	Loss: 1.805	Acc: 36.93%
Step: 16500	Loss: 1.805	Acc: 36.93%
Step: 16600	Loss: 1.805	Acc: 36.93%
Step: 16700	Loss: 1.805	Acc: 36.93%
Step: 16800	Loss: 1.805	Acc: 37.04%
Step: 16900	Loss: 1.805	Acc: 37.04%
Step: 17000	Loss: 1.805	Acc: 37.04%
Step: 17100	Loss: 1.805	Acc: 37.04%
Step: 17200	Loss: 1.805	Acc: 37.04%
Step: 17300	Loss: 1.805	Acc: 37.04%
Step: 17400	Loss: 1.805	Acc: 37.04%
Step: 17500	Loss: 1.805	Acc: 37.04%
Step: 17600	Loss: 1.805	Acc: 37.04%
Step: 17700	Loss: 1.805	Acc: 37.04%
Step: 17800	Loss: 1.805	Acc: 37.04%
Step: 17900	Loss: 1.805	Acc: 36.93%
Step: 18000	Loss: 1.805	Acc: 37.04%
Step: 18100	Loss: 1.805	Acc: 37.04%
Step: 18200	Loss: 1.805	Acc: 37.04%
Step: 18300	Loss: 1.805	Acc: 37.04%
Step: 18400	Loss: 1.805	Acc: 37.04%
Step: 18500	Loss: 1.805	Acc: 37.04%
Step: 18600	Loss: 1.805	Acc: 37.04%
Step: 18700	Loss: 1.805	Acc: 37.04%
Step: 18800	Loss: 1.805	Acc: 37.04%
Step: 18900	Loss: 1.805	Acc: 37.04%
Step: 19000	Loss: 1.805	Acc: 37.04%
Step: 19100	Loss: 1.805	Acc: 36.93%
Step: 19200	Loss: 1.805	Acc: 36.93%
Step: 19300	Loss: 1.805	Acc: 36.93%
Step: 19400	Loss: 1.805	Acc: 36.93%
Step: 19500	Loss: 1.804	Acc: 36.93%
Step: 19600	Loss: 1.804	Acc: 36.93%
Step: 19700	Loss: 1.804	Acc: 36.93%
Step: 19800	Loss: 1.804	Acc: 36.93%
Step: 19900	Loss: 1.804	Acc: 36.93%
Step: 20000	Loss: 1.804	Acc: 36.93%
Step: 20100	Loss: 1.804	Acc: 36.93%
Step: 20200	Loss: 1.804	Acc: 36.93%
Step: 20300	Loss: 1.804	Acc: 36.93%
Step: 20400	Loss: 1.804	Acc: 36.93%
Step: 20500	Loss: 1.804	Acc: 36.93%
Step: 20600	Loss: 1.804	Acc: 36.93%
Step: 20700	Loss: 1.804	Acc: 36.93%
Step: 20800	Loss: 1.804	Acc: 36.93%
Step: 20900	Loss: 1.804	Acc: 36.93%
Step: 21000	Loss: 1.804	Acc: 36.93%
Step: 21100	Loss: 1.804	Acc: 36.93%
Step: 21200	Loss: 1.804	Acc: 36.93%
Step: 21300	Loss: 1.804	Acc: 36.93%
Step: 21400	Loss: 1.804	Acc: 36.93%
Step: 21500	Loss: 1.804	Acc: 36.93%
Step: 21600	Loss: 1.804	Acc: 36.93%
Step: 21700	Loss: 1.804	Acc: 36.93%
Step: 21800	Loss: 1.804	Acc: 36.93%
Step: 21900	Loss: 1.804	Acc: 36.93%
Step: 22000	Loss: 1.804	Acc: 36.93%
Step: 22100	Loss: 1.804	Acc: 36.93%
Step: 22200	Loss: 1.804	Acc: 36.93%
Step: 22300	Loss: 1.804	Acc: 36.93%
Step: 22400	Loss: 1.804	Acc: 36.93%
Step: 22500	Loss: 1.804	Acc: 36.93%
Step: 22600	Loss: 1.804	Acc: 36.93%
Step: 22700	Loss: 1.804	Acc: 36.93%
Step: 22800	Loss: 1.804	Acc: 36.93%
Step: 22900	Loss: 1.804	Acc: 36.93%
Step: 23000	Loss: 1.804	Acc: 36.93%
Step: 23100	Loss: 1.804	Acc: 36.93%
Step: 23200	Loss: 1.804	Acc: 36.93%
Step: 23300	Loss: 1.804	Acc: 36.93%
Step: 23400	Loss: 1.804	Acc: 36.93%
Step: 23500	Loss: 1.804	Acc: 36.93%
Step: 23600	Loss: 1.804	Acc: 36.93%
Step: 23700	Loss: 1.804	Acc: 36.93%
Step: 23800	Loss: 1.804	Acc: 36.93%
Step: 23900	Loss: 1.804	Acc: 36.93%
Step: 24000	Loss: 1.804	Acc: 36.93%
Step: 24100	Loss: 1.804	Acc: 36.93%
Step: 24200	Loss: 1.804	Acc: 36.93%
Step: 24300	Loss: 1.804	Acc: 36.93%
Step: 24400	Loss: 1.804	Acc: 36.93%
Step: 24500	Loss: 1.804	Acc: 36.93%
Step: 24600	Loss: 1.804	Acc: 36.93%
Step: 24700	Loss: 1.804	Acc: 36.93%
Step: 24800	Loss: 1.804	Acc: 36.93%
Step: 24900	Loss: 1.804	Acc: 36.93%
Step: 25000	Loss: 1.804	Acc: 36.93%
Step: 25100	Loss: 1.804	Acc: 36.93%
Step: 25200	Loss: 1.804	Acc: 36.93%
Step: 25300	Loss: 1.804	Acc: 36.93%
Step: 25400	Loss: 1.804	Acc: 36.82%
Step: 25500	Loss: 1.804	Acc: 36.82%
Step: 25600	Loss: 1.804	Acc: 36.82%
Step: 25700	Loss: 1.804	Acc: 36.82%
Step: 25800	Loss: 1.804	Acc: 36.93%
Step: 25900	Loss: 1.804	Acc: 36.93%
Step: 26000	Loss: 1.804	Acc: 36.93%
Step: 26100	Loss: 1.804	Acc: 36.93%
Step: 26200	Loss: 1.804	Acc: 36.93%
Step: 26300	Loss: 1.804	Acc: 36.93%
Step: 26400	Loss: 1.804	Acc: 36.93%
Step: 26500	Loss: 1.804	Acc: 36.93%
Step: 26600	Loss: 1.804	Acc: 36.93%
Step: 26700	Loss: 1.804	Acc: 36.93%
Step: 26800	Loss: 1.804	Acc: 36.93%
Step: 26900	Loss: 1.804	Acc: 36.93%
Step: 27000	Loss: 1.804	Acc: 36.93%
Step: 27100	Loss: 1.804	Acc: 36.93%
Step: 27200	Loss: 1.804	Acc: 36.93%
Step: 27300	Loss: 1.804	Acc: 36.93%
Step: 27400	Loss: 1.804	Acc: 36.93%
Step: 27500	Loss: 1.804	Acc: 36.93%
Step: 27600	Loss: 1.804	Acc: 36.93%
Step: 27700	Loss: 1.804	Acc: 36.93%
Step: 27800	Loss: 1.804	Acc: 36.93%
Step: 27900	Loss: 1.804	Acc: 36.93%
Step: 28000	Loss: 1.804	Acc: 36.93%
Step: 28100	Loss: 1.804	Acc: 36.93%
Step: 28200	Loss: 1.804	Acc: 36.82%
Step: 28300	Loss: 1.804	Acc: 36.82%
Step: 28400	Loss: 1.804	Acc: 36.82%
Step: 28500	Loss: 1.804	Acc: 36.82%
Step: 28600	Loss: 1.804	Acc: 36.82%
Step: 28700	Loss: 1.804	Acc: 36.82%
Step: 28800	Loss: 1.804	Acc: 36.82%
Step: 28900	Loss: 1.804	Acc: 36.93%
Step: 29000	Loss: 1.804	Acc: 36.93%
Step: 29100	Loss: 1.804	Acc: 36.93%
Step: 29200	Loss: 1.804	Acc: 36.93%
Step: 29300	Loss: 1.804	Acc: 36.93%
Step: 29400	Loss: 1.804	Acc: 36.93%
Step: 29500	Loss: 1.804	Acc: 36.93%
Step: 29600	Loss: 1.804	Acc: 36.93%
Step: 29700	Loss: 1.804	Acc: 36.82%
Step: 29800	Loss: 1.804	Acc: 36.82%
Step: 29900	Loss: 1.804	Acc: 36.82%
Step: 30000	Loss: 1.804	Acc: 36.82%
Step: 30100	Loss: 1.804	Acc: 36.82%
Step: 30200	Loss: 1.804	Acc: 36.71%
Step: 30300	Loss: 1.804	Acc: 36.71%
Step: 30400	Loss: 1.804	Acc: 36.71%
Step: 30500	Loss: 1.804	Acc: 36.71%
Step: 30600	Loss: 1.804	Acc: 36.71%
Step: 30700	Loss: 1.804	Acc: 36.71%
Step: 30800	Loss: 1.804	Acc: 36.71%
Step: 30900	Loss: 1.804	Acc: 36.71%
Step: 31000	Loss: 1.804	Acc: 36.71%
Step: 31100	Loss: 1.804	Acc: 36.71%
Step: 31200	Loss: 1.804	Acc: 36.71%
Step: 31300	Loss: 1.803	Acc: 36.71%
Step: 31400	Loss: 1.803	Acc: 36.71%
Step: 31500	Loss: 1.803	Acc: 36.71%
Step: 31600	Loss: 1.803	Acc: 36.71%
Step: 31700	Loss: 1.803	Acc: 36.71%
Step: 31800	Loss: 1.803	Acc: 36.71%
Step: 31900	Loss: 1.803	Acc: 36.71%
Step: 32000	Loss: 1.803	Acc: 36.71%
Step: 32100	Loss: 1.803	Acc: 36.71%
Step: 32200	Loss: 1.803	Acc: 36.71%
Step: 32300	Loss: 1.803	Acc: 36.71%
Step: 32400	Loss: 1.803	Acc: 36.71%
Step: 32500	Loss: 1.803	Acc: 36.71%
Step: 32600	Loss: 1.803	Acc: 36.71%
Step: 32700	Loss: 1.803	Acc: 36.71%
Step: 32800	Loss: 1.803	Acc: 36.71%
Step: 32900	Loss: 1.803	Acc: 36.71%
Step: 33000	Loss: 1.803	Acc: 36.71%
Step: 33100	Loss: 1.803	Acc: 36.71%
Step: 33200	Loss: 1.803	Acc: 36.71%
Step: 33300	Loss: 1.803	Acc: 36.71%
Step: 33400	Loss: 1.803	Acc: 36.71%
Step: 33500	Loss: 1.803	Acc: 36.71%
Step: 33600	Loss: 1.803	Acc: 36.71%
Step: 33700	Loss: 1.803	Acc: 36.71%
Step: 33800	Loss: 1.803	Acc: 36.71%
Step: 33900	Loss: 1.803	Acc: 36.71%
Step: 34000	Loss: 1.803	Acc: 36.71%
Step: 34100	Loss: 1.803	Acc: 36.71%
Step: 34200	Loss: 1.803	Acc: 36.71%
Step: 34300	Loss: 1.803	Acc: 36.71%
Step: 34400	Loss: 1.803	Acc: 36.71%
Step: 34500	Loss: 1.803	Acc: 36.71%
Step: 34600	Loss: 1.803	Acc: 36.71%
Step: 34700	Loss: 1.803	Acc: 36.71%
Step: 34800	Loss: 1.803	Acc: 36.71%
Step: 34900	Loss: 1.803	Acc: 36.71%
Step: 35000	Loss: 1.803	Acc: 36.82%
Step: 35100	Loss: 1.803	Acc: 36.82%
Step: 35200	Loss: 1.803	Acc: 36.82%
Step: 35300	Loss: 1.803	Acc: 36.82%
Step: 35400	Loss: 1.803	Acc: 36.82%
Step: 35500	Loss: 1.803	Acc: 36.82%
Step: 35600	Loss: 1.803	Acc: 36.82%
Step: 35700	Loss: 1.803	Acc: 36.82%
Step: 35800	Loss: 1.803	Acc: 36.82%
Step: 35900	Loss: 1.803	Acc: 36.82%
Step: 36000	Loss: 1.803	Acc: 36.82%
Step: 36100	Loss: 1.803	Acc: 36.82%
Step: 36200	Loss: 1.803	Acc: 36.82%
Step: 36300	Loss: 1.803	Acc: 36.82%
Step: 36400	Loss: 1.803	Acc: 36.82%
Step: 36500	Loss: 1.803	Acc: 36.82%
Step: 36600	Loss: 1.803	Acc: 36.71%
Step: 36700	Loss: 1.803	Acc: 36.71%
Step: 36800	Loss: 1.803	Acc: 36.71%
Step: 36900	Loss: 1.803	Acc: 36.71%
Step: 37000	Loss: 1.803	Acc: 36.71%
Step: 37100	Loss: 1.803	Acc: 36.71%
Step: 37200	Loss: 1.803	Acc: 36.71%
Step: 37300	Loss: 1.803	Acc: 36.71%
Step: 37400	Loss: 1.803	Acc: 36.71%
Step: 37500	Loss: 1.803	Acc: 36.71%
Step: 37600	Loss: 1.803	Acc: 36.71%
Step: 37700	Loss: 1.803	Acc: 36.71%
Step: 37800	Loss: 1.803	Acc: 36.71%
Step: 37900	Loss: 1.803	Acc: 36.71%
Step: 38000	Loss: 1.803	Acc: 36.71%
Step: 38100	Loss: 1.803	Acc: 36.71%
Step: 38200	Loss: 1.803	Acc: 36.71%
Step: 38300	Loss: 1.803	Acc: 36.71%
Step: 38400	Loss: 1.803	Acc: 36.71%
Step: 38500	Loss: 1.803	Acc: 36.71%
Step: 38600	Loss: 1.803	Acc: 36.71%
Step: 38700	Loss: 1.803	Acc: 36.71%
Step: 38800	Loss: 1.803	Acc: 36.71%
Step: 38900	Loss: 1.803	Acc: 36.71%
Step: 39000	Loss: 1.803	Acc: 36.71%
Step: 39100	Loss: 1.803	Acc: 36.71%
Step: 39200	Loss: 1.803	Acc: 36.71%
Step: 39300	Loss: 1.803	Acc: 36.71%
Step: 39400	Loss: 1.803	Acc: 36.71%
Step: 39500	Loss: 1.803	Acc: 36.71%
Step: 39600	Loss: 1.803	Acc: 36.71%
Step: 39700	Loss: 1.803	Acc: 36.71%
Step: 39800	Loss: 1.803	Acc: 36.71%
Step: 39900	Loss: 1.803	Acc: 36.71%
Step: 40000	Loss: 1.803	Acc: 36.71%
Step: 40100	Loss: 1.803	Acc: 36.71%
Step: 40200	Loss: 1.803	Acc: 36.71%
Step: 40300	Loss: 1.803	Acc: 36.71%
Step: 40400	Loss: 1.803	Acc: 36.71%
Step: 40500	Loss: 1.803	Acc: 36.71%
Step: 40600	Loss: 1.803	Acc: 36.71%
Step: 40700	Loss: 1.803	Acc: 36.71%
Step: 40800	Loss: 1.803	Acc: 36.71%
Step: 40900	Loss: 1.803	Acc: 36.71%
Step: 41000	Loss: 1.803	Acc: 36.71%
Step: 41100	Loss: 1.803	Acc: 36.71%
Step: 41200	Loss: 1.803	Acc: 36.71%
Step: 41300	Loss: 1.803	Acc: 36.71%
Step: 41400	Loss: 1.803	Acc: 36.71%
Step: 41500	Loss: 1.803	Acc: 36.71%
Step: 41600	Loss: 1.803	Acc: 36.71%
Step: 41700	Loss: 1.803	Acc: 36.71%
Step: 41800	Loss: 1.803	Acc: 36.71%
Step: 41900	Loss: 1.803	Acc: 36.71%
Step: 42000	Loss: 1.803	Acc: 36.71%
Step: 42100	Loss: 1.803	Acc: 36.71%
Step: 42200	Loss: 1.803	Acc: 36.71%
Step: 42300	Loss: 1.803	Acc: 36.71%
Step: 42400	Loss: 1.803	Acc: 36.71%
Step: 42500	Loss: 1.803	Acc: 36.71%
Step: 42600	Loss: 1.803	Acc: 36.71%
Step: 42700	Loss: 1.803	Acc: 36.71%
Step: 42800	Loss: 1.803	Acc: 36.71%
Step: 42900	Loss: 1.803	Acc: 36.71%
Step: 43000	Loss: 1.803	Acc: 36.71%
Step: 43100	Loss: 1.803	Acc: 36.71%
Step: 43200	Loss: 1.803	Acc: 36.71%
Step: 43300	Loss: 1.803	Acc: 36.71%
Step: 43400	Loss: 1.803	Acc: 36.71%
Step: 43500	Loss: 1.803	Acc: 36.71%
Step: 43600	Loss: 1.803	Acc: 36.71%
Step: 43700	Loss: 1.803	Acc: 36.71%
Step: 43800	Loss: 1.803	Acc: 36.71%
Step: 43900	Loss: 1.803	Acc: 36.71%
Step: 44000	Loss: 1.803	Acc: 36.71%
Step: 44100	Loss: 1.803	Acc: 36.71%
Step: 44200	Loss: 1.803	Acc: 36.71%
Step: 44300	Loss: 1.803	Acc: 36.71%
Step: 44400	Loss: 1.803	Acc: 36.71%
Step: 44500	Loss: 1.803	Acc: 36.71%
Step: 44600	Loss: 1.803	Acc: 36.71%
Step: 44700	Loss: 1.803	Acc: 36.71%
Step: 44800	Loss: 1.803	Acc: 36.71%
Step: 44900	Loss: 1.803	Acc: 36.71%
Step: 45000	Loss: 1.803	Acc: 36.71%
Step: 45100	Loss: 1.803	Acc: 36.71%
Step: 45200	Loss: 1.803	Acc: 36.71%
Step: 45300	Loss: 1.803	Acc: 36.71%
Step: 45400	Loss: 1.803	Acc: 36.71%
Step: 45500	Loss: 1.803	Acc: 36.71%
Step: 45600	Loss: 1.803	Acc: 36.71%
Step: 45700	Loss: 1.803	Acc: 36.71%
Step: 45800	Loss: 1.803	Acc: 36.71%
Step: 45900	Loss: 1.803	Acc: 36.71%
Step: 46000	Loss: 1.803	Acc: 36.71%
Step: 46100	Loss: 1.803	Acc: 36.71%
Step: 46200	Loss: 1.803	Acc: 36.71%
Step: 46300	Loss: 1.803	Acc: 36.71%
Step: 46400	Loss: 1.803	Acc: 36.71%
Step: 46500	Loss: 1.803	Acc: 36.71%
Step: 46600	Loss: 1.803	Acc: 36.71%
Step: 46700	Loss: 1.803	Acc: 36.71%
Step: 46800	Loss: 1.803	Acc: 36.71%
Step: 46900	Loss: 1.803	Acc: 36.71%
Step: 47000	Loss: 1.803	Acc: 36.71%
Step: 47100	Loss: 1.803	Acc: 36.71%
Step: 47200	Loss: 1.803	Acc: 36.71%
Step: 47300	Loss: 1.803	Acc: 36.71%
Step: 47400	Loss: 1.803	Acc: 36.71%
Step: 47500	Loss: 1.803	Acc: 36.71%
Step: 47600	Loss: 1.803	Acc: 36.71%
Step: 47700	Loss: 1.803	Acc: 36.71%
Step: 47800	Loss: 1.803	Acc: 36.71%
Step: 47900	Loss: 1.803	Acc: 36.71%
Step: 48000	Loss: 1.803	Acc: 36.71%
Step: 48100	Loss: 1.803	Acc: 36.71%
Step: 48200	Loss: 1.803	Acc: 36.71%
Step: 48300	Loss: 1.803	Acc: 36.71%
Step: 48400	Loss: 1.803	Acc: 36.71%
Step: 48500	Loss: 1.803	Acc: 36.71%
Step: 48600	Loss: 1.803	Acc: 36.71%
Step: 48700	Loss: 1.803	Acc: 36.71%
Step: 48800	Loss: 1.803	Acc: 36.71%
Step: 48900	Loss: 1.803	Acc: 36.71%
Step: 49000	Loss: 1.803	Acc: 36.71%
Step: 49100	Loss: 1.803	Acc: 36.71%
Step: 49200	Loss: 1.803	Acc: 36.71%
Step: 49300	Loss: 1.803	Acc: 36.71%
Step: 49400	Loss: 1.803	Acc: 36.71%
Step: 49500	Loss: 1.803	Acc: 36.71%
Step: 49600	Loss: 1.803	Acc: 36.71%
Step: 49700	Loss: 1.803	Acc: 36.71%
Step: 49800	Loss: 1.803	Acc: 36.71%
Step: 49900	Loss: 1.803	Acc: 36.71%
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 10
[False] Prediction: 6 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 9 True Y: 8
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 4
[True] Prediction: 3 True Y: 3
[False] Prediction: 3 True Y: 4
[False] Prediction: 5 True Y: 9
[False] Prediction: 5 True Y: 4
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 8 True Y: 7
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 3
[False] Prediction: 8 True Y: 3
[False] Prediction: 8 True Y: 9
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 10 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 1 True Y: 0
[False] Prediction: 7 True Y: 2
[False] Prediction: 5 True Y: 3
[False] Prediction: 3 True Y: 2
[True] Prediction: 2 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 6
[True] Prediction: 2 True Y: 2
[False] Prediction: 10 True Y: 5
[True] Prediction: 6 True Y: 6
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 1
[True] Prediction: 8 True Y: 8
[False] Prediction: 7 True Y: 0
[False] Prediction: 3 True Y: 4
[False] Prediction: 4 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 2 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 8 True Y: 6
[False] Prediction: 5 True Y: 6
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 0
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 3 True Y: 2
[False] Prediction: 3 True Y: 8
[False] Prediction: 5 True Y: 4
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 0
[True] Prediction: 5 True Y: 5
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 8 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 3
[False] Prediction: 3 True Y: 4
[False] Prediction: 10 True Y: 7
[True] Prediction: 6 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 10 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 3
[False] Prediction: 6 True Y: 7
[False] Prediction: 8 True Y: 6
[True] Prediction: 10 True Y: 10
[False] Prediction: 6 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 6
[False] Prediction: 10 True Y: 6
[False] Prediction: 3 True Y: 0
[False] Prediction: 6 True Y: 4
[False] Prediction: 5 True Y: 3
[True] Prediction: 10 True Y: 10
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 1
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 4
[False] Prediction: 7 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 6
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 5 True Y: 2
[True] Prediction: 3 True Y: 3
[False] Prediction: 3 True Y: 4
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 10
[False] Prediction: 3 True Y: 8
[False] Prediction: 10 True Y: 7
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 4
[False] Prediction: 7 True Y: 8
[False] Prediction: 6 True Y: 10
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 10 True Y: 10
[False] Prediction: 5 True Y: 7
[False] Prediction: 2 True Y: 5
[False] Prediction: 10 True Y: 4
[False] Prediction: 9 True Y: 8
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 8
[True] Prediction: 7 True Y: 7
[False] Prediction: 10 True Y: 7
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 0
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[False] Prediction: 0 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 7 True Y: 5
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 4 True Y: 2
[False] Prediction: 7 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 8 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 7
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 3 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 6
[False] Prediction: 6 True Y: 0
[False] Prediction: 3 True Y: 1
[False] Prediction: 6 True Y: 8
[False] Prediction: 5 True Y: 4
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[True] Prediction: 6 True Y: 6
[False] Prediction: 7 True Y: 4
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 1
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 6
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 4 True Y: 4
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 10
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 7
[False] Prediction: 10 True Y: 9
[False] Prediction: 5 True Y: 6
[False] Prediction: 10 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 7
[False] Prediction: 5 True Y: 0
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 4 True Y: 1
[False] Prediction: 8 True Y: 10
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 8
[False] Prediction: 8 True Y: 7
[False] Prediction: 5 True Y: 3
[False] Prediction: 8 True Y: 4
[False] Prediction: 5 True Y: 3
[False] Prediction: 8 True Y: 7
[True] Prediction: 8 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 7 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 4 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 7 True Y: 7
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 8
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 8
[False] Prediction: 3 True Y: 4
[False] Prediction: 8 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 0
[False] Prediction: 3 True Y: 6
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 7
[False] Prediction: 2 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 7
[False] Prediction: 5 True Y: 4
[False] Prediction: 10 True Y: 8
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 8 True Y: 10
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 7
[False] Prediction: 3 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 10
[False] Prediction: 6 True Y: 9
[False] Prediction: 8 True Y: 9
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 6 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 5
[False] Prediction: 6 True Y: 9
[True] Prediction: 7 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 6
[False] Prediction: 3 True Y: 4
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 4 True Y: 3
[False] Prediction: 3 True Y: 4
[False] Prediction: 7 True Y: 6
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 1
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 7
[False] Prediction: 5 True Y: 3
[True] Prediction: 3 True Y: 3
[False] Prediction: 3 True Y: 4
[False] Prediction: 5 True Y: 4
[False] Prediction: 3 True Y: 8
[False] Prediction: 5 True Y: 4
[False] Prediction: 8 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 9
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 4
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 2
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 4
[True] Prediction: 6 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 3
[False] Prediction: 8 True Y: 7
[True] Prediction: 7 True Y: 7
[False] Prediction: 3 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 7
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 0
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 0
[False] Prediction: 3 True Y: 2
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 7
[False] Prediction: 6 True Y: 1
[False] Prediction: 5 True Y: 10
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 1
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 0
[False] Prediction: 5 True Y: 1
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 8 True Y: 8
[False] Prediction: 3 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 9
[False] Prediction: 6 True Y: 2
[False] Prediction: 3 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[False] Prediction: 7 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 7 True Y: 6
[False] Prediction: 8 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 3 True Y: 4
[True] Prediction: 9 True Y: 9
[False] Prediction: 3 True Y: 2
[False] Prediction: 5 True Y: 10
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 7
[True] Prediction: 10 True Y: 10
[False] Prediction: 8 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 10 True Y: 8
[True] Prediction: 3 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 3 True Y: 3
[True] Prediction: 3 True Y: 3
[False] Prediction: 8 True Y: 7
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 6
[False] Prediction: 3 True Y: 2
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 8
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 8 True Y: 8
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 8 True Y: 8
[False] Prediction: 3 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 7 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 3 True Y: 8
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 6
[False] Prediction: 4 True Y: 6
[False] Prediction: 5 True Y: 6
[False] Prediction: 8 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 4
[False] Prediction: 7 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 10 True Y: 8
[False] Prediction: 8 True Y: 7
[True] Prediction: 8 True Y: 8
[False] Prediction: 10 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 2 True Y: 4
[False] Prediction: 8 True Y: 9
[True] Prediction: 7 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 0 True Y: 0
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 3 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 7 True Y: 7
[False] Prediction: 4 True Y: 5
[True] Prediction: 8 True Y: 8
[True] Prediction: 4 True Y: 4
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 10
[False] Prediction: 4 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[False] Prediction: 7 True Y: 9
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 6 True Y: 2
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 8
[False] Prediction: 3 True Y: 10
[True] Prediction: 5 True Y: 5
[True] Prediction: 6 True Y: 6
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 8 True Y: 5
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 0
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 10
[True] Prediction: 5 True Y: 5
[True] Prediction: 0 True Y: 0
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 10
[False] Prediction: 6 True Y: 4
[False] Prediction: 5 True Y: 9
[False] Prediction: 10 True Y: 6
[False] Prediction: 10 True Y: 8
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 7
[False] Prediction: 8 True Y: 4
[False] Prediction: 4 True Y: 3
[False] Prediction: 5 True Y: 4
[True] Prediction: 6 True Y: 6
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 8 True Y: 8
[False] Prediction: 8 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 2
[False] Prediction: 8 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 4
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 1
[False] Prediction: 7 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 8
[False] Prediction: 6 True Y: 8
[True] Prediction: 4 True Y: 4
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 4
[False] Prediction: 4 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 8 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[False] Prediction: 7 True Y: 10
[True] Prediction: 8 True Y: 8
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 6 True Y: 6
[True] Prediction: 4 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 9
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 3 True Y: 2
[False] Prediction: 3 True Y: 4
[False] Prediction: 6 True Y: 9
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[False] Prediction: 6 True Y: 8
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 3
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 2 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 9 True Y: 9
[False] Prediction: 5 True Y: 4
[True] Prediction: 3 True Y: 3
[False] Prediction: 10 True Y: 9
[False] Prediction: 10 True Y: 4
[False] Prediction: 5 True Y: 4
[True] Prediction: 8 True Y: 8
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 3
[False] Prediction: 7 True Y: 10
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 1
[False] Prediction: 5 True Y: 7
[False] Prediction: 7 True Y: 1
[False] Prediction: 8 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 3 True Y: 7
[False] Prediction: 5 True Y: 7
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 2 True Y: 3
[False] Prediction: 5 True Y: 7
[False] Prediction: 6 True Y: 5
[False] Prediction: 3 True Y: 2
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 3
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 8
[True] Prediction: 3 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 7
[False] Prediction: 10 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 6 True Y: 7
[False] Prediction: 5 True Y: 1
[False] Prediction: 10 True Y: 8
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 10
[False] Prediction: 7 True Y: 8
[False] Prediction: 5 True Y: 0
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 9
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 3
[False] Prediction: 9 True Y: 7
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[False] Prediction: 3 True Y: 1
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 0
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 2
[False] Prediction: 6 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[False] Prediction: 6 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 6 True Y: 6
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 4
[False] Prediction: 8 True Y: 10
[False] Prediction: 3 True Y: 4
[False] Prediction: 7 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 9
[False] Prediction: 9 True Y: 4
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 1
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 10 True Y: 10
[True] Prediction: 5 True Y: 5
[True] Prediction: 10 True Y: 10
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 9
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 3
[False] Prediction: 3 True Y: 2
[False] Prediction: 3 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 3
[False] Prediction: 3 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 4
[False] Prediction: 6 True Y: 4
[False] Prediction: 8 True Y: 6
[False] Prediction: 5 True Y: 4
[False] Prediction: 8 True Y: 7
[False] Prediction: 4 True Y: 3
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 3 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 6
[False] Prediction: 6 True Y: 9
[False] Prediction: 5 True Y: 7
[False] Prediction: 4 True Y: 0
[False] Prediction: 3 True Y: 7
[False] Prediction: 3 True Y: 4
[False] Prediction: 5 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 7 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 7 True Y: 8
[False] Prediction: 3 True Y: 4
[True] Prediction: 8 True Y: 8
[False] Prediction: 8 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 2 True Y: 3
[True] Prediction: 3 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 8
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 7 True Y: 4
[True] Prediction: 2 True Y: 2
[False] Prediction: 5 True Y: 10
[True] Prediction: 3 True Y: 3
[True] Prediction: 10 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 4
[False] Prediction: 4 True Y: 8
[True] Prediction: 10 True Y: 10
[False] Prediction: 10 True Y: 8
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 2
[False] Prediction: 6 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 3 True Y: 6
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 2
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 4 True Y: 0
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[False] Prediction: 5 True Y: 7
[False] Prediction: 8 True Y: 6
[False] Prediction: 7 True Y: 6
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 10
[False] Prediction: 5 True Y: 0
[False] Prediction: 3 True Y: 4
[False] Prediction: 8 True Y: 6
[False] Prediction: 8 True Y: 10
[False] Prediction: 3 True Y: 2
[True] Prediction: 5 True Y: 5
[True] Prediction: 8 True Y: 8
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 4
[True] Prediction: 3 True Y: 3
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 10
[False] Prediction: 5 True Y: 8
[False] Prediction: 5 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 10 True Y: 6
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 1
[False] Prediction: 8 True Y: 3
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 5 True Y: 5
[True] Prediction: 10 True Y: 10
[True] Prediction: 5 True Y: 5
[False] Prediction: 8 True Y: 5
[True] Prediction: 9 True Y: 9
[True] Prediction: 3 True Y: 3
[False] Prediction: 5 True Y: 7
[True] Prediction: 5 True Y: 5
[True] Prediction: 7 True Y: 7
[False] Prediction: 5 True Y: 4
[False] Prediction: 5 True Y: 10
[True] Prediction: 7 True Y: 7
[True] Prediction: 5 True Y: 5
[False] Prediction: 5 True Y: 3
[False] Prediction: 5 True Y: 2
[False] Prediction: 5 True Y: 4
[True] Prediction: 5 True Y: 5
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[305]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sm_result</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">result8</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[306]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sm_result</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[306]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[[&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15900,
  1.8051865,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16000,
  1.8051617,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16100,
  1.805137,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16200,
  1.8051133,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16300,
  1.8050896,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16800,
  1.8049773,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16900,
  1.8049555,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17000,
  1.8049343,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17100,
  1.804913,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17200,
  1.8048927,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17300,
  1.8048718,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17400,
  1.8048519,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17500,
  1.8048327,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17600,
  1.8048126,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17700,
  1.8047936,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17800,
  1.8047748,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18000,
  1.8047376,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18100,
  1.8047196,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18200,
  1.8047014,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18300,
  1.8046844,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18400,
  1.8046664,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18500,
  1.8046496,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18600,
  1.8046327,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18700,
  1.8046159,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18800,
  1.8045993,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  18900,
  1.8045828,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19000,
  1.8045673,
  0.37041157],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15600,
  1.8052626,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15700,
  1.8052367,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15800,
  1.8052115,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16400,
  1.8050665,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16500,
  1.805043,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16600,
  1.8050207,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  16700,
  1.8049988,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  17900,
  1.8047563,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19100,
  1.8045511,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19200,
  1.8045357,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19300,
  1.8045202,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19400,
  1.8045052,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19500,
  1.8044901,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19600,
  1.8044753,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19700,
  1.8044605,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19800,
  1.8044466,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  19900,
  1.8044319,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20000,
  1.8044181,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20100,
  1.804404,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20200,
  1.8043904,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20300,
  1.8043766,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20400,
  1.8043634,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20500,
  1.80435,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20600,
  1.804337,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20700,
  1.8043243,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20800,
  1.8043118,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  20900,
  1.8042991,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21000,
  1.8042864,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21100,
  1.8042736,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21200,
  1.8042625,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21300,
  1.80425,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21400,
  1.8042377,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21500,
  1.8042263,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21600,
  1.8042147,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21700,
  1.8042033,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21800,
  1.8041921,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  21900,
  1.8041809,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22000,
  1.8041698,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22100,
  1.8041592,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22200,
  1.8041476,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22300,
  1.8041375,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22400,
  1.8041266,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22500,
  1.8041162,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22600,
  1.8041056,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22700,
  1.8040957,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22800,
  1.8040853,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  22900,
  1.8040755,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23000,
  1.8040653,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23100,
  1.8040558,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23200,
  1.8040463,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23300,
  1.8040365,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23400,
  1.8040267,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23500,
  1.8040173,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23600,
  1.8040081,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23700,
  1.8039993,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23800,
  1.8039902,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  23900,
  1.8039813,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24000,
  1.8039719,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24100,
  1.8039631,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24200,
  1.8039542,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24300,
  1.8039455,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24400,
  1.8039373,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24500,
  1.8039286,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24600,
  1.8039206,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24700,
  1.8039122,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24800,
  1.8039042,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  24900,
  1.8038956,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25000,
  1.8038877,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25100,
  1.8038796,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25200,
  1.8038719,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25300,
  1.803864,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25800,
  1.8038256,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25900,
  1.803818,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26000,
  1.8038108,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26100,
  1.8038036,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26200,
  1.8037963,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26300,
  1.8037894,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26400,
  1.8037823,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26500,
  1.8037754,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26600,
  1.8037685,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26700,
  1.8037615,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26800,
  1.8037547,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  26900,
  1.803748,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27000,
  1.803741,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27100,
  1.8037345,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27200,
  1.8037277,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27300,
  1.8037213,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27400,
  1.803715,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27500,
  1.8037084,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27600,
  1.8037024,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27700,
  1.803696,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27800,
  1.8036891,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  27900,
  1.803683,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28000,
  1.803677,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28100,
  1.8036711,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28900,
  1.8036242,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29000,
  1.803618,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29100,
  1.8036127,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29200,
  1.8036072,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29300,
  1.8036013,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29400,
  1.8035958,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29500,
  1.8035908,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29600,
  1.8035848,
  0.36929923],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12900,
  1.8061516,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15000,
  1.8054268,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15100,
  1.8053983,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15200,
  1.8053705,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15300,
  1.8053427,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15400,
  1.8053159,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  15500,
  1.805289,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25400,
  1.8038559,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25500,
  1.8038484,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25600,
  1.8038408,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  25700,
  1.8038332,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28200,
  1.8036652,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28300,
  1.8036588,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28400,
  1.8036532,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28500,
  1.8036468,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28600,
  1.8036414,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28700,
  1.8036355,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  28800,
  1.8036296,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29700,
  1.8035797,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29800,
  1.8035744,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  29900,
  1.8035697,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30000,
  1.8035641,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30100,
  1.8035587,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35000,
  1.8033437,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35100,
  1.8033401,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35200,
  1.803336,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35300,
  1.8033328,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35400,
  1.8033289,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35500,
  1.8033254,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35600,
  1.8033214,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35700,
  1.803318,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35800,
  1.8033147,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  35900,
  1.8033106,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36000,
  1.8033077,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36100,
  1.8033044,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36200,
  1.8033007,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36300,
  1.803297,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36400,
  1.8032937,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36500,
  1.8032907,
  0.36818686],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12600,
  1.8062782,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12700,
  1.8062357,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12800,
  1.8061932,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13000,
  1.8061105,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13100,
  1.8060704,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13200,
  1.8060309,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13300,
  1.8059926,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13400,
  1.8059542,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13500,
  1.805917,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13600,
  1.8058803,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13700,
  1.8058443,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13800,
  1.8058089,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  13900,
  1.8057736,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14000,
  1.8057395,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14100,
  1.805706,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14200,
  1.8056728,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14300,
  1.8056407,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14400,
  1.8056083,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14500,
  1.8055766,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14600,
  1.8055457,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14700,
  1.8055154,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14800,
  1.8054856,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  14900,
  1.8054562,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30200,
  1.8035533,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30300,
  1.8035487,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30400,
  1.8035432,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30500,
  1.8035383,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30600,
  1.8035333,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30700,
  1.8035282,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30800,
  1.8035232,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  30900,
  1.8035184,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31000,
  1.8035133,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31100,
  1.8035082,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31200,
  1.8035038,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31300,
  1.8034989,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31400,
  1.8034943,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31500,
  1.8034894,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31600,
  1.8034848,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31700,
  1.8034803,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31800,
  1.8034759,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  31900,
  1.803471,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32000,
  1.8034668,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32100,
  1.8034623,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32200,
  1.8034576,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32300,
  1.803453,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32400,
  1.8034488,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32500,
  1.8034441,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32600,
  1.8034402,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32700,
  1.8034354,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32800,
  1.8034313,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  32900,
  1.8034271,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33000,
  1.8034228,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33100,
  1.8034183,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33200,
  1.8034141,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33300,
  1.8034105,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33400,
  1.8034064,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33500,
  1.8034021,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33600,
  1.8033981,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33700,
  1.8033938,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33800,
  1.8033903,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  33900,
  1.803386,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34000,
  1.8033822,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34100,
  1.8033776,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34200,
  1.8033742,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34300,
  1.8033704,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34400,
  1.8033662,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34500,
  1.8033624,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34600,
  1.8033586,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34700,
  1.8033547,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34800,
  1.8033509,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  34900,
  1.8033475,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36600,
  1.8032868,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36700,
  1.8032835,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36800,
  1.8032802,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  36900,
  1.8032764,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37000,
  1.8032737,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37100,
  1.8032701,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37200,
  1.8032669,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37300,
  1.8032637,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37400,
  1.8032603,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37500,
  1.8032572,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37600,
  1.8032542,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37700,
  1.8032507,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37800,
  1.8032475,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  37900,
  1.8032445,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38000,
  1.8032416,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38100,
  1.803238,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38200,
  1.8032351,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38300,
  1.8032318,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38400,
  1.8032292,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38500,
  1.8032258,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38600,
  1.803223,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38700,
  1.8032199,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38800,
  1.8032167,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  38900,
  1.8032138,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39000,
  1.8032112,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39100,
  1.8032079,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39200,
  1.8032053,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39300,
  1.8032024,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39400,
  1.8031994,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39500,
  1.8031964,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39600,
  1.8031936,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39700,
  1.8031906,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39800,
  1.8031877,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  39900,
  1.803185,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40000,
  1.8031819,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40100,
  1.8031793,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40200,
  1.8031766,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40300,
  1.8031738,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40400,
  1.803171,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40500,
  1.8031685,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40600,
  1.8031657,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40700,
  1.8031627,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40800,
  1.8031603,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  40900,
  1.8031573,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41000,
  1.8031549,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41100,
  1.8031522,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41200,
  1.8031498,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41300,
  1.8031472,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41400,
  1.8031443,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41500,
  1.8031417,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41600,
  1.8031391,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41700,
  1.8031365,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41800,
  1.8031341,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  41900,
  1.8031316,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42000,
  1.803129,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42100,
  1.8031267,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42200,
  1.803124,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42300,
  1.8031213,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42400,
  1.8031191,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42500,
  1.8031163,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42600,
  1.8031141,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42700,
  1.8031113,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42800,
  1.8031092,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  42900,
  1.8031065,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43000,
  1.8031045,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43100,
  1.8031021,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43200,
  1.8030996,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43300,
  1.803097,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43400,
  1.8030946,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43500,
  1.8030926,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43600,
  1.8030897,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43700,
  1.8030876,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43800,
  1.8030853,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  43900,
  1.8030832,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44000,
  1.8030812,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44100,
  1.8030784,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44200,
  1.8030764,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44300,
  1.8030744,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44400,
  1.8030719,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44500,
  1.8030692,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44600,
  1.8030674,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44700,
  1.8030654,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44800,
  1.8030628,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  44900,
  1.8030604,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45000,
  1.8030585,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45100,
  1.8030562,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45200,
  1.8030541,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45300,
  1.8030517,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45400,
  1.8030496,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45500,
  1.8030478,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45600,
  1.8030455,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45700,
  1.8030432,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45800,
  1.8030413,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  45900,
  1.8030392,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46000,
  1.803037,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46100,
  1.8030351,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46200,
  1.8030329,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46300,
  1.8030305,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46400,
  1.8030283,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46500,
  1.8030264,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46600,
  1.8030246,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46700,
  1.8030225,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46800,
  1.8030202,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  46900,
  1.8030187,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47000,
  1.8030164,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47100,
  1.8030149,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47200,
  1.8030124,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47300,
  1.8030105,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47400,
  1.8030086,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47500,
  1.8030065,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47600,
  1.8030045,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47700,
  1.8030027,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47800,
  1.8030007,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  47900,
  1.8029987,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48000,
  1.8029968,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48100,
  1.8029951,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48200,
  1.8029931,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48300,
  1.802991,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48400,
  1.8029896,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48500,
  1.8029871,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48600,
  1.8029854,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48700,
  1.8029833,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48800,
  1.8029816,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  48900,
  1.8029792,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49000,
  1.8029778,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49100,
  1.802976,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49200,
  1.8029742,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49300,
  1.802973,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49400,
  1.8029709,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49500,
  1.8029687,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49600,
  1.8029671,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49700,
  1.8029655,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49800,
  1.8029639,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  49900,
  1.8029618,
  0.36707452],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2900,
  1.8268178,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3000,
  1.8258014,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4800,
  1.8157166,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4900,
  1.8153985,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5000,
  1.8150945,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5100,
  1.8148028,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9400,
  1.8082112,
  0.36596218],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2600,
  1.8304677,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2700,
  1.8291373,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2800,
  1.8279259,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3100,
  1.8248651,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3200,
  1.8240004,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3300,
  1.8231993,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3400,
  1.8224547,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3500,
  1.8217615,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3600,
  1.8211145,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3800,
  1.8199404,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4600,
  1.8163984,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4700,
  1.8160495,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5200,
  1.8145232,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6700,
  1.8113564,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6800,
  1.8111956,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6900,
  1.8110391,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7000,
  1.8108873,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7100,
  1.81074,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7200,
  1.8105963,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7300,
  1.8104563,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7400,
  1.8103205,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9200,
  1.8083805,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9300,
  1.8082949,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9500,
  1.8081297,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9600,
  1.8080494,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9700,
  1.8079716,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9800,
  1.8078952,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9900,
  1.8078196,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10000,
  1.8077466,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10100,
  1.8076748,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10200,
  1.8076044,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10300,
  1.8075355,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10400,
  1.8074678,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10500,
  1.8074018,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10600,
  1.8073375,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10700,
  1.8072742,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10800,
  1.8072119,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  10900,
  1.807151,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11000,
  1.8070909,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11100,
  1.8070326,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11200,
  1.8069754,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11300,
  1.8069191,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11500,
  1.8068101,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11600,
  1.8067567,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11700,
  1.8067048,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11800,
  1.8066541,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11900,
  1.8066036,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12000,
  1.8065548,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12100,
  1.806506,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12200,
  1.8064588,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12300,
  1.8064131,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12400,
  1.806367,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  12500,
  1.8063223,
  0.36484984],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3700,
  1.8205087,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  3900,
  1.8194056,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4100,
  1.818427,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4300,
  1.8175521,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4400,
  1.8171475,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4500,
  1.8167636,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5300,
  1.8142545,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6200,
  1.8122395,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6300,
  1.8120517,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6400,
  1.8118694,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6500,
  1.8116933,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6600,
  1.8115225,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7500,
  1.8101885,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7600,
  1.8100597,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7700,
  1.8099337,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8200,
  1.8093526,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8300,
  1.8092445,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8400,
  1.8091393,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8500,
  1.8090361,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8600,
  1.8089364,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8700,
  1.8088379,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8800,
  1.8087419,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8900,
  1.8086487,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9000,
  1.8085573,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  9100,
  1.8084677,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  11400,
  1.8068641,
  0.36373749],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2300,
  1.8353591,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2500,
  1.831933,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4000,
  1.8189021,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5400,
  1.8139961,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5500,
  1.8137479,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5600,
  1.8135087,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6100,
  1.812433,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7800,
  1.8098117,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  7900,
  1.8096925,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8000,
  1.8095759,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  8100,
  1.8094628,
  0.36262515],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2400,
  1.8335556,
  0.36151278],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  4200,
  1.8179777,
  0.36151278],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5700,
  1.813278,
  0.36151278],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5800,
  1.8130562,
  0.36151278],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  5900,
  1.8128414,
  0.36151278],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  6000,
  1.8126338,
  0.36151278],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2200,
  1.8373749,
  0.36040044],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2100,
  1.8396388,
  0.3592881],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1700,
  1.8522638,
  0.35817575],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1600,
  1.8567168,
  0.35706341],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1800,
  1.8484299,
  0.35706341],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1900,
  1.8451034,
  0.35706341],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  2000,
  1.8421959,
  0.35595107],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1500,
  1.8619319,
  0.3548387],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1400,
  1.8680986,
  0.35261402],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1300,
  1.8754704,
  0.35038933],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1200,
  1.884406,
  0.34927696],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1100,
  1.895407,
  0.34482759],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  1000,
  1.9091349,
  0.34149054],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  900,
  1.9264174,
  0.32925472],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  800,
  1.9483397,
  0.32703003],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  700,
  1.9765173,
  0.31924361],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  600,
  2.0135338,
  0.30812013],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  500,
  2.0634892,
  0.30700779],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  400,
  2.1328132,
  0.29477197],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  300,
  2.2333074,
  0.27030033],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  200,
  2.3950171,
  0.23692992],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  100,
  2.7298045,
  0.23581758],
 [&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;,
  0,
  12.36657,
  0.083426028]]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">Best Result&#50640; &#45824;&#54644; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Best-Result&#50640;-&#45824;&#54644;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[315]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_sm_result</span> <span class="o">=</span> <span class="n">sm_result</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_sm_result</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[&lt;tf.Tensor &#39;Softmax:0&#39; shape=(?, 11) dtype=float32&gt;, 15900, 1.8051865, 0.37041157]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[325]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[325]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(155, 63)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test-set&#51032;-&#50696;&#52769;&#54620;-Y-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">Test set&#51032; &#50696;&#52769;&#54620; Y &#44050;&#51012; &#48372;&#50668;&#51456;&#45796;.<a class="anchor-link" href="#Test-set&#51032;-&#50696;&#52769;&#54620;-Y-&#44050;&#51012;-&#48372;&#50668;&#51456;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[343]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;test_X.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Launch graph</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Let&#39;s see if we can predict</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">test_X</span><span class="p">})</span>
    <span class="c1"># y_data: (N,1) = flatten =&gt; (N, ) matches pred.shape</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction: </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Prediction: 3 
Prediction: 3 
Prediction: 4 
Prediction: 4 
Prediction: 4 
Prediction: 4 
Prediction: 3 
Prediction: 4 
Prediction: 4 
Prediction: 3 
Prediction: 4 
Prediction: 4 
Prediction: 3 
Prediction: 3 
Prediction: 4 
Prediction: 4 
Prediction: 3 
Prediction: 4 
Prediction: 3 
Prediction: 3 
Prediction: 4 
Prediction: 3 
Prediction: 4 
Prediction: 3 
Prediction: 3 
Prediction: 3 
Prediction: 4 
Prediction: 1 
Prediction: 1 
Prediction: 3 
Prediction: 4 
Prediction: 1 
Prediction: 1 
Prediction: 3 
Prediction: 3 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 4 
Prediction: 4 
Prediction: 4 
Prediction: 4 
Prediction: 1 
Prediction: 4 
Prediction: 4 
Prediction: 1 
Prediction: 4 
Prediction: 1 
Prediction: 4 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 4 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 4 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 4 
Prediction: 4 
Prediction: 3 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 4 
Prediction: 4 
Prediction: 4 
Prediction: 3 
Prediction: 1 
Prediction: 3 
Prediction: 1 
Prediction: 1 
Prediction: 3 
Prediction: 3 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 3 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
Prediction: 1 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.9-Keras-+-Relu-+-SoftMax">2.9 Keras + Relu + SoftMax<a class="anchor-link" href="#2.9-Keras-+-Relu-+-SoftMax">&#182;</a></h2><p>Description for <code>Keras + Relu + SoftMax</code>: 
<a href="https://keras.io/">click</a>
<a href="https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions">click</a>
<a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/">click</a></p>
<p>Keras를 통해 고속 구현을 하고  Relu Activation Function을 통해 hidden layer에서 값을 찾아내 RNN을 구현한 후 SoftMax로 결과값을 처리해준 것이다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[344]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.wrappers.scikit_learn</span> <span class="k">import</span> <span class="n">KerasClassifier</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">EarlyStopping</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[345]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fix random seed for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="mi">1</span>
<span class="mi">2</span>
<span class="mi">3</span>
<span class="c1"># fix random seed for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[346]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># load dataset</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;new_data.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">values</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">15</span><span class="p">]</span>
<span class="n">dataframe2</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;test_X.csv&quot;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataframe2</span><span class="o">.</span><span class="n">values</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">dataset2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[347]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># encode class values as integers</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">encoded_Y</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="c1"># convert integers to dummy variables (i.e. one hot encoded)</span>
<span class="n">dummy_y</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">encoded_Y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[348]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define baseline model</span>
<span class="k">def</span> <span class="nf">baseline_model</span><span class="p">():</span>
    <span class="c1"># create model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="c1"># Compile model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[349]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">estimator</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_fn</span><span class="o">=</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[350]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[351]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dummy_y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Baseline: </span><span class="si">%.2f%%</span><span class="s2"> (</span><span class="si">%.2f%%</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Baseline: 31.60% (4.97%)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[352]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[353]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">dummy_y</span><span class="p">,</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/1000
899/899 [==============================] - 0s - loss: 2.3226 - acc: 0.2581     
Epoch 2/1000
899/899 [==============================] - 0s - loss: 2.0894 - acc: 0.3103     
Epoch 3/1000
899/899 [==============================] - 0s - loss: 2.0464 - acc: 0.3148     
Epoch 4/1000
899/899 [==============================] - 0s - loss: 2.0059 - acc: 0.3159     
Epoch 5/1000
899/899 [==============================] - 0s - loss: 1.9787 - acc: 0.3270     
Epoch 6/1000
899/899 [==============================] - 0s - loss: 1.9583 - acc: 0.3370     
Epoch 7/1000
899/899 [==============================] - 0s - loss: 1.9408 - acc: 0.3248     
Epoch 8/1000
899/899 [==============================] - 0s - loss: 1.9209 - acc: 0.3370     
Epoch 9/1000
899/899 [==============================] - 0s - loss: 1.8985 - acc: 0.3404     
Epoch 10/1000
899/899 [==============================] - 0s - loss: 1.8864 - acc: 0.3426     
Epoch 11/1000
899/899 [==============================] - 0s - loss: 1.8758 - acc: 0.3482     
Epoch 12/1000
899/899 [==============================] - 0s - loss: 1.8605 - acc: 0.3571     
Epoch 13/1000
899/899 [==============================] - 0s - loss: 1.8519 - acc: 0.3604     
Epoch 14/1000
899/899 [==============================] - 0s - loss: 1.8632 - acc: 0.3693     
Epoch 15/1000
899/899 [==============================] - 0s - loss: 1.8453 - acc: 0.3526     
Epoch 16/1000
899/899 [==============================] - 0s - loss: 1.8394 - acc: 0.3648     
Epoch 17/1000
899/899 [==============================] - 0s - loss: 1.8388 - acc: 0.3615     
Epoch 18/1000
899/899 [==============================] - 0s - loss: 1.8318 - acc: 0.3626     
Epoch 19/1000
899/899 [==============================] - 0s - loss: 1.8226 - acc: 0.3715     
Epoch 20/1000
899/899 [==============================] - 0s - loss: 1.8168 - acc: 0.3682     
Epoch 21/1000
899/899 [==============================] - 0s - loss: 1.8076 - acc: 0.3782     
Epoch 22/1000
899/899 [==============================] - 0s - loss: 1.8019 - acc: 0.3760     
Epoch 23/1000
899/899 [==============================] - 0s - loss: 1.8054 - acc: 0.3660     
Epoch 24/1000
899/899 [==============================] - 0s - loss: 1.8016 - acc: 0.3726     
Epoch 25/1000
899/899 [==============================] - 0s - loss: 1.8009 - acc: 0.3637     
Epoch 26/1000
899/899 [==============================] - 0s - loss: 1.7883 - acc: 0.3737     
Epoch 27/1000
899/899 [==============================] - 0s - loss: 1.7977 - acc: 0.3793     
Epoch 28/1000
899/899 [==============================] - 0s - loss: 1.7855 - acc: 0.3726     
Epoch 29/1000
899/899 [==============================] - 0s - loss: 1.7830 - acc: 0.3726     
Epoch 30/1000
899/899 [==============================] - 0s - loss: 1.7784 - acc: 0.3737     
Epoch 31/1000
899/899 [==============================] - 0s - loss: 1.7831 - acc: 0.3660     
Epoch 32/1000
899/899 [==============================] - 0s - loss: 1.7674 - acc: 0.3826     
Epoch 33/1000
899/899 [==============================] - 0s - loss: 1.7659 - acc: 0.3749     
Epoch 34/1000
899/899 [==============================] - 0s - loss: 1.7638 - acc: 0.3793     
Epoch 35/1000
899/899 [==============================] - 0s - loss: 1.7732 - acc: 0.3838     
Epoch 36/1000
899/899 [==============================] - 0s - loss: 1.7570 - acc: 0.3882     
Epoch 37/1000
899/899 [==============================] - 0s - loss: 1.7515 - acc: 0.3815     
Epoch 38/1000
899/899 [==============================] - 0s - loss: 1.7531 - acc: 0.3860     
Epoch 39/1000
899/899 [==============================] - 0s - loss: 1.7527 - acc: 0.3927     
Epoch 40/1000
899/899 [==============================] - 0s - loss: 1.7500 - acc: 0.3982     
Epoch 41/1000
899/899 [==============================] - 0s - loss: 1.7538 - acc: 0.3860     
Epoch 42/1000
899/899 [==============================] - 0s - loss: 1.7511 - acc: 0.3904     
Epoch 43/1000
899/899 [==============================] - 0s - loss: 1.7366 - acc: 0.3982     
Epoch 44/1000
899/899 [==============================] - 0s - loss: 1.7331 - acc: 0.3915     
Epoch 45/1000
899/899 [==============================] - 0s - loss: 1.7366 - acc: 0.3893     
Epoch 46/1000
899/899 [==============================] - 0s - loss: 1.7266 - acc: 0.3971     
Epoch 47/1000
899/899 [==============================] - 0s - loss: 1.7217 - acc: 0.3971     
Epoch 48/1000
899/899 [==============================] - 0s - loss: 1.7238 - acc: 0.3982     
Epoch 49/1000
899/899 [==============================] - 0s - loss: 1.7204 - acc: 0.3882     
Epoch 50/1000
899/899 [==============================] - 0s - loss: 1.7183 - acc: 0.3971     
Epoch 51/1000
899/899 [==============================] - 0s - loss: 1.7162 - acc: 0.3915     
Epoch 52/1000
899/899 [==============================] - 0s - loss: 1.7120 - acc: 0.3904     
Epoch 53/1000
899/899 [==============================] - 0s - loss: 1.7150 - acc: 0.3971     
Epoch 54/1000
899/899 [==============================] - 0s - loss: 1.7049 - acc: 0.3938     
Epoch 55/1000
899/899 [==============================] - 0s - loss: 1.7034 - acc: 0.3971     
Epoch 56/1000
899/899 [==============================] - 0s - loss: 1.7017 - acc: 0.4060     
Epoch 57/1000
899/899 [==============================] - 0s - loss: 1.7070 - acc: 0.3904     
Epoch 58/1000
899/899 [==============================] - 0s - loss: 1.7004 - acc: 0.4060     
Epoch 59/1000
899/899 [==============================] - 0s - loss: 1.6964 - acc: 0.3993     
Epoch 60/1000
899/899 [==============================] - 0s - loss: 1.6913 - acc: 0.4060     
Epoch 61/1000
899/899 [==============================] - 0s - loss: 1.6911 - acc: 0.4049     
Epoch 62/1000
899/899 [==============================] - 0s - loss: 1.6932 - acc: 0.3904     
Epoch 63/1000
899/899 [==============================] - 0s - loss: 1.6819 - acc: 0.4116     
Epoch 64/1000
899/899 [==============================] - 0s - loss: 1.6775 - acc: 0.4105     
Epoch 65/1000
899/899 [==============================] - 0s - loss: 1.6767 - acc: 0.4127     
Epoch 66/1000
899/899 [==============================] - 0s - loss: 1.6759 - acc: 0.4016     
Epoch 67/1000
899/899 [==============================] - 0s - loss: 1.6697 - acc: 0.4171     
Epoch 68/1000
899/899 [==============================] - 0s - loss: 1.6735 - acc: 0.3993     
Epoch 69/1000
899/899 [==============================] - 0s - loss: 1.6686 - acc: 0.4305     
Epoch 70/1000
899/899 [==============================] - 0s - loss: 1.6634 - acc: 0.4227     
Epoch 71/1000
899/899 [==============================] - 0s - loss: 1.6719 - acc: 0.4160     
Epoch 72/1000
899/899 [==============================] - 0s - loss: 1.6542 - acc: 0.4294     
Epoch 73/1000
899/899 [==============================] - 0s - loss: 1.6622 - acc: 0.4271     
Epoch 74/1000
899/899 [==============================] - 0s - loss: 1.6616 - acc: 0.4127     
Epoch 75/1000
899/899 [==============================] - 0s - loss: 1.6624 - acc: 0.4071     
Epoch 76/1000
899/899 [==============================] - 0s - loss: 1.6527 - acc: 0.4249     
Epoch 77/1000
899/899 [==============================] - 0s - loss: 1.6509 - acc: 0.4294     
Epoch 78/1000
899/899 [==============================] - 0s - loss: 1.6508 - acc: 0.4249     
Epoch 79/1000
899/899 [==============================] - 0s - loss: 1.6417 - acc: 0.4238     
Epoch 80/1000
899/899 [==============================] - 0s - loss: 1.6436 - acc: 0.4216     
Epoch 81/1000
899/899 [==============================] - 0s - loss: 1.6394 - acc: 0.4327     
Epoch 82/1000
899/899 [==============================] - 0s - loss: 1.6365 - acc: 0.4349     
Epoch 83/1000
899/899 [==============================] - 0s - loss: 1.6376 - acc: 0.4127     
Epoch 84/1000
899/899 [==============================] - 0s - loss: 1.6305 - acc: 0.4205     
Epoch 85/1000
899/899 [==============================] - 0s - loss: 1.6409 - acc: 0.4194     
Epoch 86/1000
899/899 [==============================] - 0s - loss: 1.6351 - acc: 0.4205     
Epoch 87/1000
899/899 [==============================] - 0s - loss: 1.6341 - acc: 0.4283     
Epoch 88/1000
899/899 [==============================] - 0s - loss: 1.6273 - acc: 0.4394     
Epoch 89/1000
899/899 [==============================] - 0s - loss: 1.6238 - acc: 0.4394     
Epoch 90/1000
899/899 [==============================] - 0s - loss: 1.6175 - acc: 0.4238     
Epoch 91/1000
899/899 [==============================] - 0s - loss: 1.6192 - acc: 0.4427     
Epoch 92/1000
899/899 [==============================] - 0s - loss: 1.6139 - acc: 0.4416     
Epoch 93/1000
899/899 [==============================] - 0s - loss: 1.6142 - acc: 0.4405     
Epoch 94/1000
899/899 [==============================] - 0s - loss: 1.6089 - acc: 0.4449     
Epoch 95/1000
899/899 [==============================] - 0s - loss: 1.6082 - acc: 0.4405     
Epoch 96/1000
899/899 [==============================] - 0s - loss: 1.6100 - acc: 0.4549     
Epoch 97/1000
899/899 [==============================] - 0s - loss: 1.6097 - acc: 0.4483     
Epoch 98/1000
899/899 [==============================] - 0s - loss: 1.6019 - acc: 0.4449     
Epoch 99/1000
899/899 [==============================] - 0s - loss: 1.5976 - acc: 0.4316     
Epoch 100/1000
899/899 [==============================] - 0s - loss: 1.5935 - acc: 0.4483     
Epoch 101/1000
899/899 [==============================] - 0s - loss: 1.5948 - acc: 0.4416     
Epoch 102/1000
899/899 [==============================] - 0s - loss: 1.5840 - acc: 0.4461     
Epoch 103/1000
899/899 [==============================] - 0s - loss: 1.5826 - acc: 0.4472     
Epoch 104/1000
899/899 [==============================] - 0s - loss: 1.5773 - acc: 0.4505     
Epoch 105/1000
899/899 [==============================] - 0s - loss: 1.5849 - acc: 0.4394     
Epoch 106/1000
899/899 [==============================] - 0s - loss: 1.5877 - acc: 0.4472     
Epoch 107/1000
899/899 [==============================] - 0s - loss: 1.5822 - acc: 0.4327     
Epoch 108/1000
899/899 [==============================] - 0s - loss: 1.5756 - acc: 0.4461     
Epoch 109/1000
899/899 [==============================] - 0s - loss: 1.5751 - acc: 0.4438     
Epoch 110/1000
899/899 [==============================] - 0s - loss: 1.5756 - acc: 0.4427     
Epoch 111/1000
899/899 [==============================] - 0s - loss: 1.5698 - acc: 0.4449     
Epoch 112/1000
899/899 [==============================] - 0s - loss: 1.5670 - acc: 0.4483     
Epoch 113/1000
899/899 [==============================] - 0s - loss: 1.5696 - acc: 0.4461     
Epoch 114/1000
899/899 [==============================] - 0s - loss: 1.5619 - acc: 0.4583     
Epoch 115/1000
899/899 [==============================] - 0s - loss: 1.5578 - acc: 0.4516     
Epoch 116/1000
899/899 [==============================] - 0s - loss: 1.5637 - acc: 0.4516     
Epoch 117/1000
899/899 [==============================] - 0s - loss: 1.5539 - acc: 0.4583     
Epoch 118/1000
899/899 [==============================] - 0s - loss: 1.5514 - acc: 0.4494     
Epoch 119/1000
899/899 [==============================] - 0s - loss: 1.5530 - acc: 0.4538     
Epoch 120/1000
899/899 [==============================] - 0s - loss: 1.5495 - acc: 0.4505     
Epoch 121/1000
899/899 [==============================] - 0s - loss: 1.5506 - acc: 0.4494     
Epoch 122/1000
899/899 [==============================] - 0s - loss: 1.5471 - acc: 0.4705     
Epoch 123/1000
899/899 [==============================] - 0s - loss: 1.5472 - acc: 0.4527     
Epoch 124/1000
899/899 [==============================] - 0s - loss: 1.5441 - acc: 0.4561     
Epoch 125/1000
899/899 [==============================] - 0s - loss: 1.5410 - acc: 0.4672     
Epoch 126/1000
899/899 [==============================] - 0s - loss: 1.5304 - acc: 0.4705     
Epoch 127/1000
899/899 [==============================] - 0s - loss: 1.5375 - acc: 0.4516     
Epoch 128/1000
899/899 [==============================] - 0s - loss: 1.5316 - acc: 0.4549     
Epoch 129/1000
899/899 [==============================] - 0s - loss: 1.5331 - acc: 0.4616     
Epoch 130/1000
899/899 [==============================] - 0s - loss: 1.5275 - acc: 0.4650     
Epoch 131/1000
899/899 [==============================] - 0s - loss: 1.5309 - acc: 0.4427     
Epoch 132/1000
899/899 [==============================] - 0s - loss: 1.5181 - acc: 0.4627     
Epoch 133/1000
899/899 [==============================] - 0s - loss: 1.5211 - acc: 0.4739     
Epoch 134/1000
899/899 [==============================] - 0s - loss: 1.5146 - acc: 0.4783     
Epoch 135/1000
899/899 [==============================] - 0s - loss: 1.5118 - acc: 0.4694     
Epoch 136/1000
899/899 [==============================] - 0s - loss: 1.5120 - acc: 0.4705     
Epoch 137/1000
899/899 [==============================] - 0s - loss: 1.5095 - acc: 0.4716     
Epoch 138/1000
899/899 [==============================] - 0s - loss: 1.5127 - acc: 0.4694     
Epoch 139/1000
899/899 [==============================] - 0s - loss: 1.5190 - acc: 0.4594     
Epoch 140/1000
899/899 [==============================] - 0s - loss: 1.5138 - acc: 0.4750     
Epoch 141/1000
899/899 [==============================] - 0s - loss: 1.5031 - acc: 0.4661     
Epoch 142/1000
899/899 [==============================] - 0s - loss: 1.5074 - acc: 0.4794     
Epoch 143/1000
899/899 [==============================] - 0s - loss: 1.4968 - acc: 0.4716     
Epoch 144/1000
899/899 [==============================] - 0s - loss: 1.4951 - acc: 0.4705     
Epoch 145/1000
899/899 [==============================] - 0s - loss: 1.4986 - acc: 0.4727     
Epoch 146/1000
899/899 [==============================] - 0s - loss: 1.4897 - acc: 0.4794     
Epoch 147/1000
899/899 [==============================] - 0s - loss: 1.4992 - acc: 0.4739     
Epoch 148/1000
899/899 [==============================] - 0s - loss: 1.4832 - acc: 0.4805     
Epoch 149/1000
899/899 [==============================] - 0s - loss: 1.4851 - acc: 0.4705     
Epoch 150/1000
899/899 [==============================] - 0s - loss: 1.4804 - acc: 0.4816     
Epoch 151/1000
899/899 [==============================] - 0s - loss: 1.4816 - acc: 0.4772     
Epoch 152/1000
899/899 [==============================] - 0s - loss: 1.4742 - acc: 0.4794     
Epoch 153/1000
899/899 [==============================] - 0s - loss: 1.4780 - acc: 0.4661     
Epoch 154/1000
899/899 [==============================] - 0s - loss: 1.4737 - acc: 0.4772     
Epoch 155/1000
899/899 [==============================] - 0s - loss: 1.4774 - acc: 0.4739     
Epoch 156/1000
899/899 [==============================] - 0s - loss: 1.4685 - acc: 0.4805     
Epoch 157/1000
899/899 [==============================] - 0s - loss: 1.4669 - acc: 0.4905     
Epoch 158/1000
899/899 [==============================] - 0s - loss: 1.4649 - acc: 0.4872     
Epoch 159/1000
899/899 [==============================] - 0s - loss: 1.4642 - acc: 0.4861     
Epoch 160/1000
899/899 [==============================] - 0s - loss: 1.4621 - acc: 0.4816     
Epoch 161/1000
899/899 [==============================] - 0s - loss: 1.4635 - acc: 0.4805     
Epoch 162/1000
899/899 [==============================] - 0s - loss: 1.4655 - acc: 0.4928     
Epoch 163/1000
899/899 [==============================] - 0s - loss: 1.4565 - acc: 0.4850     
Epoch 164/1000
899/899 [==============================] - 0s - loss: 1.4595 - acc: 0.4761     
Epoch 165/1000
899/899 [==============================] - 0s - loss: 1.4473 - acc: 0.4839     
Epoch 166/1000
899/899 [==============================] - 0s - loss: 1.4661 - acc: 0.4672     
Epoch 167/1000
899/899 [==============================] - 0s - loss: 1.4492 - acc: 0.4861     
Epoch 168/1000
899/899 [==============================] - 0s - loss: 1.4481 - acc: 0.4850     
Epoch 169/1000
899/899 [==============================] - 0s - loss: 1.4511 - acc: 0.4805     
Epoch 170/1000
899/899 [==============================] - 0s - loss: 1.4451 - acc: 0.4750     
Epoch 171/1000
899/899 [==============================] - 0s - loss: 1.4472 - acc: 0.4861     
Epoch 172/1000
899/899 [==============================] - 0s - loss: 1.4413 - acc: 0.4805     
Epoch 173/1000
899/899 [==============================] - 0s - loss: 1.4298 - acc: 0.4950     
Epoch 174/1000
899/899 [==============================] - 0s - loss: 1.4298 - acc: 0.4961     
Epoch 175/1000
899/899 [==============================] - 0s - loss: 1.4263 - acc: 0.5072     
Epoch 176/1000
899/899 [==============================] - 0s - loss: 1.4291 - acc: 0.5028     
Epoch 177/1000
899/899 [==============================] - 0s - loss: 1.4300 - acc: 0.4950     
Epoch 178/1000
899/899 [==============================] - 0s - loss: 1.4251 - acc: 0.4939     
Epoch 179/1000
899/899 [==============================] - 0s - loss: 1.4297 - acc: 0.4950     
Epoch 180/1000
899/899 [==============================] - 0s - loss: 1.4213 - acc: 0.4894     
Epoch 181/1000
899/899 [==============================] - 0s - loss: 1.4384 - acc: 0.4805     
Epoch 182/1000
899/899 [==============================] - 0s - loss: 1.4225 - acc: 0.4905     
Epoch 183/1000
899/899 [==============================] - 0s - loss: 1.4185 - acc: 0.4928     
Epoch 184/1000
899/899 [==============================] - 0s - loss: 1.4151 - acc: 0.4950     
Epoch 185/1000
899/899 [==============================] - 0s - loss: 1.4124 - acc: 0.4905     
Epoch 186/1000
899/899 [==============================] - 0s - loss: 1.4121 - acc: 0.5006     
Epoch 187/1000
899/899 [==============================] - 0s - loss: 1.4093 - acc: 0.5006     
Epoch 188/1000
899/899 [==============================] - ETA: 0s - loss: 1.5463 - acc: 0.375 - 0s - loss: 1.3990 - acc: 0.5161     
Epoch 189/1000
899/899 [==============================] - 0s - loss: 1.4030 - acc: 0.4972     
Epoch 190/1000
899/899 [==============================] - 0s - loss: 1.3988 - acc: 0.5006     
Epoch 191/1000
899/899 [==============================] - 0s - loss: 1.3983 - acc: 0.5083     
Epoch 192/1000
899/899 [==============================] - 0s - loss: 1.3982 - acc: 0.4972     
Epoch 193/1000
899/899 [==============================] - 0s - loss: 1.4049 - acc: 0.5195     
Epoch 194/1000
899/899 [==============================] - 0s - loss: 1.3995 - acc: 0.5117     
Epoch 195/1000
899/899 [==============================] - 0s - loss: 1.3976 - acc: 0.5039     
Epoch 196/1000
899/899 [==============================] - 0s - loss: 1.3989 - acc: 0.5028     
Epoch 197/1000
899/899 [==============================] - 0s - loss: 1.3979 - acc: 0.4961     
Epoch 198/1000
899/899 [==============================] - 0s - loss: 1.4107 - acc: 0.5006     
Epoch 199/1000
899/899 [==============================] - 0s - loss: 1.3925 - acc: 0.5017     
Epoch 200/1000
899/899 [==============================] - 0s - loss: 1.3856 - acc: 0.5039     
Epoch 201/1000
899/899 [==============================] - 0s - loss: 1.3859 - acc: 0.5061     
Epoch 202/1000
899/899 [==============================] - 0s - loss: 1.3927 - acc: 0.5072     
Epoch 203/1000
899/899 [==============================] - 0s - loss: 1.3854 - acc: 0.5106     
Epoch 204/1000
899/899 [==============================] - 0s - loss: 1.3789 - acc: 0.5206     
Epoch 205/1000
899/899 [==============================] - 0s - loss: 1.3767 - acc: 0.5117     
Epoch 206/1000
899/899 [==============================] - 0s - loss: 1.3804 - acc: 0.5117     
Epoch 207/1000
899/899 [==============================] - 0s - loss: 1.3894 - acc: 0.5017     
Epoch 208/1000
899/899 [==============================] - 0s - loss: 1.3769 - acc: 0.4994     
Epoch 209/1000
899/899 [==============================] - 0s - loss: 1.3674 - acc: 0.5128     
Epoch 210/1000
899/899 [==============================] - 0s - loss: 1.3701 - acc: 0.5206     
Epoch 211/1000
899/899 [==============================] - 0s - loss: 1.3694 - acc: 0.5150     
Epoch 212/1000
899/899 [==============================] - 0s - loss: 1.3693 - acc: 0.5006     
Epoch 213/1000
899/899 [==============================] - 0s - loss: 1.3711 - acc: 0.5072     
Epoch 214/1000
899/899 [==============================] - 0s - loss: 1.3661 - acc: 0.5039     
Epoch 215/1000
899/899 [==============================] - 0s - loss: 1.3565 - acc: 0.5217     
Epoch 216/1000
899/899 [==============================] - 0s - loss: 1.3702 - acc: 0.5172     
Epoch 217/1000
899/899 [==============================] - 0s - loss: 1.3565 - acc: 0.5050     
Epoch 218/1000
899/899 [==============================] - 0s - loss: 1.3641 - acc: 0.5139     
Epoch 219/1000
899/899 [==============================] - 0s - loss: 1.3562 - acc: 0.5161     
Epoch 220/1000
899/899 [==============================] - 0s - loss: 1.3547 - acc: 0.5195     
Epoch 221/1000
899/899 [==============================] - 0s - loss: 1.3563 - acc: 0.5172     
Epoch 222/1000
899/899 [==============================] - 0s - loss: 1.3608 - acc: 0.5228     
Epoch 223/1000
899/899 [==============================] - 0s - loss: 1.3511 - acc: 0.5206     
Epoch 224/1000
899/899 [==============================] - 0s - loss: 1.3471 - acc: 0.5128     
Epoch 225/1000
899/899 [==============================] - 0s - loss: 1.3486 - acc: 0.5273     
Epoch 226/1000
899/899 [==============================] - 0s - loss: 1.3427 - acc: 0.5184     
Epoch 227/1000
899/899 [==============================] - 0s - loss: 1.3419 - acc: 0.5095     
Epoch 228/1000
899/899 [==============================] - 0s - loss: 1.3458 - acc: 0.5317     
Epoch 229/1000
899/899 [==============================] - 0s - loss: 1.3529 - acc: 0.5195     
Epoch 230/1000
899/899 [==============================] - 0s - loss: 1.3397 - acc: 0.5384     
Epoch 231/1000
899/899 [==============================] - 0s - loss: 1.3394 - acc: 0.5161     
Epoch 232/1000
899/899 [==============================] - 0s - loss: 1.3435 - acc: 0.5083     
Epoch 233/1000
899/899 [==============================] - 0s - loss: 1.3329 - acc: 0.5317     
Epoch 234/1000
899/899 [==============================] - 0s - loss: 1.3446 - acc: 0.5128     
Epoch 235/1000
899/899 [==============================] - 0s - loss: 1.3313 - acc: 0.5428     
Epoch 236/1000
899/899 [==============================] - 0s - loss: 1.3262 - acc: 0.5295     
Epoch 237/1000
899/899 [==============================] - 0s - loss: 1.3278 - acc: 0.5339     
Epoch 238/1000
899/899 [==============================] - 0s - loss: 1.3327 - acc: 0.5295     
Epoch 239/1000
899/899 [==============================] - 0s - loss: 1.3203 - acc: 0.5339     
Epoch 240/1000
899/899 [==============================] - 0s - loss: 1.3281 - acc: 0.5228     
Epoch 241/1000
899/899 [==============================] - 0s - loss: 1.3284 - acc: 0.5406     
Epoch 242/1000
899/899 [==============================] - 0s - loss: 1.3259 - acc: 0.5284     
Epoch 243/1000
899/899 [==============================] - 0s - loss: 1.3178 - acc: 0.5384     
Epoch 244/1000
899/899 [==============================] - 0s - loss: 1.3220 - acc: 0.5328     
Epoch 245/1000
899/899 [==============================] - 0s - loss: 1.3275 - acc: 0.5217     
Epoch 246/1000
899/899 [==============================] - 0s - loss: 1.3154 - acc: 0.5384     
Epoch 247/1000
899/899 [==============================] - 0s - loss: 1.3200 - acc: 0.5228     
Epoch 248/1000
899/899 [==============================] - 0s - loss: 1.3082 - acc: 0.5373     
Epoch 249/1000
899/899 [==============================] - 0s - loss: 1.3249 - acc: 0.5328     
Epoch 250/1000
899/899 [==============================] - 0s - loss: 1.3266 - acc: 0.5395     
Epoch 251/1000
899/899 [==============================] - 0s - loss: 1.3090 - acc: 0.5306     
Epoch 252/1000
899/899 [==============================] - 0s - loss: 1.3081 - acc: 0.5406     
Epoch 253/1000
899/899 [==============================] - 0s - loss: 1.3204 - acc: 0.5150     
Epoch 254/1000
899/899 [==============================] - 0s - loss: 1.3004 - acc: 0.5306     
Epoch 255/1000
899/899 [==============================] - 0s - loss: 1.2997 - acc: 0.5406     
Epoch 256/1000
899/899 [==============================] - 0s - loss: 1.2964 - acc: 0.5328     
Epoch 257/1000
899/899 [==============================] - 0s - loss: 1.2991 - acc: 0.5428     
Epoch 258/1000
899/899 [==============================] - 0s - loss: 1.2920 - acc: 0.5551     
Epoch 259/1000
899/899 [==============================] - 0s - loss: 1.2974 - acc: 0.5417     
Epoch 260/1000
899/899 [==============================] - 0s - loss: 1.2961 - acc: 0.5528     
Epoch 261/1000
899/899 [==============================] - 0s - loss: 1.2950 - acc: 0.5428     
Epoch 262/1000
899/899 [==============================] - 0s - loss: 1.2926 - acc: 0.5462     
Epoch 263/1000
899/899 [==============================] - 0s - loss: 1.2945 - acc: 0.5373     
Epoch 264/1000
899/899 [==============================] - 0s - loss: 1.2912 - acc: 0.5439     
Epoch 265/1000
899/899 [==============================] - 0s - loss: 1.2982 - acc: 0.5362     
Epoch 266/1000
899/899 [==============================] - 0s - loss: 1.2861 - acc: 0.5473     
Epoch 267/1000
899/899 [==============================] - 0s - loss: 1.2861 - acc: 0.5451     
Epoch 268/1000
899/899 [==============================] - 0s - loss: 1.2854 - acc: 0.5395     
Epoch 269/1000
899/899 [==============================] - 0s - loss: 1.2801 - acc: 0.5573     
Epoch 270/1000
899/899 [==============================] - 0s - loss: 1.2817 - acc: 0.5462     
Epoch 271/1000
899/899 [==============================] - 0s - loss: 1.2880 - acc: 0.5473     
Epoch 272/1000
899/899 [==============================] - 0s - loss: 1.2887 - acc: 0.5506     
Epoch 273/1000
899/899 [==============================] - 0s - loss: 1.2771 - acc: 0.5484     
Epoch 274/1000
899/899 [==============================] - 0s - loss: 1.2875 - acc: 0.5384     
Epoch 275/1000
899/899 [==============================] - 0s - loss: 1.2792 - acc: 0.5517     
Epoch 276/1000
899/899 [==============================] - 0s - loss: 1.2755 - acc: 0.5517     
Epoch 277/1000
899/899 [==============================] - 0s - loss: 1.2781 - acc: 0.5462     
Epoch 278/1000
899/899 [==============================] - 0s - loss: 1.2717 - acc: 0.5551     
Epoch 279/1000
899/899 [==============================] - 0s - loss: 1.2668 - acc: 0.5606     
Epoch 280/1000
899/899 [==============================] - 0s - loss: 1.2701 - acc: 0.5684     
Epoch 281/1000
899/899 [==============================] - 0s - loss: 1.2739 - acc: 0.5517     
Epoch 282/1000
899/899 [==============================] - 0s - loss: 1.2644 - acc: 0.5528     
Epoch 283/1000
899/899 [==============================] - 0s - loss: 1.2660 - acc: 0.5595     
Epoch 284/1000
899/899 [==============================] - 0s - loss: 1.2691 - acc: 0.5551     
Epoch 285/1000
899/899 [==============================] - 0s - loss: 1.2703 - acc: 0.5617     
Epoch 286/1000
899/899 [==============================] - 0s - loss: 1.2660 - acc: 0.5473     
Epoch 287/1000
899/899 [==============================] - 0s - loss: 1.2673 - acc: 0.5439     
Epoch 288/1000
899/899 [==============================] - 0s - loss: 1.2592 - acc: 0.5562     
Epoch 289/1000
899/899 [==============================] - 0s - loss: 1.2575 - acc: 0.5495     
Epoch 290/1000
899/899 [==============================] - 0s - loss: 1.2568 - acc: 0.5584     
Epoch 291/1000
899/899 [==============================] - 0s - loss: 1.2479 - acc: 0.5684     
Epoch 292/1000
899/899 [==============================] - 0s - loss: 1.2489 - acc: 0.5617     
Epoch 293/1000
899/899 [==============================] - 0s - loss: 1.2529 - acc: 0.5539     
Epoch 294/1000
899/899 [==============================] - 0s - loss: 1.2529 - acc: 0.5495     
Epoch 295/1000
899/899 [==============================] - 0s - loss: 1.2573 - acc: 0.5406     
Epoch 296/1000
899/899 [==============================] - 0s - loss: 1.2489 - acc: 0.5706     
Epoch 297/1000
899/899 [==============================] - 0s - loss: 1.2686 - acc: 0.5573     
Epoch 298/1000
899/899 [==============================] - 0s - loss: 1.2444 - acc: 0.5573     
Epoch 299/1000
899/899 [==============================] - 0s - loss: 1.2388 - acc: 0.5717     
Epoch 300/1000
899/899 [==============================] - 0s - loss: 1.2482 - acc: 0.5628     
Epoch 301/1000
899/899 [==============================] - 0s - loss: 1.2391 - acc: 0.5684     
Epoch 302/1000
899/899 [==============================] - 0s - loss: 1.2429 - acc: 0.5640     
Epoch 303/1000
899/899 [==============================] - 0s - loss: 1.2359 - acc: 0.5606     
Epoch 304/1000
899/899 [==============================] - 0s - loss: 1.2393 - acc: 0.5506     
Epoch 305/1000
899/899 [==============================] - 0s - loss: 1.2417 - acc: 0.5684     
Epoch 306/1000
899/899 [==============================] - 0s - loss: 1.2372 - acc: 0.5573     
Epoch 307/1000
899/899 [==============================] - 0s - loss: 1.2295 - acc: 0.5706     
Epoch 308/1000
899/899 [==============================] - 0s - loss: 1.2328 - acc: 0.5695     
Epoch 309/1000
899/899 [==============================] - 0s - loss: 1.2358 - acc: 0.5673     
Epoch 310/1000
899/899 [==============================] - 0s - loss: 1.2391 - acc: 0.5673     
Epoch 311/1000
899/899 [==============================] - 0s - loss: 1.2326 - acc: 0.5617     
Epoch 312/1000
899/899 [==============================] - 0s - loss: 1.2252 - acc: 0.5662     
Epoch 313/1000
899/899 [==============================] - 0s - loss: 1.2217 - acc: 0.5717     
Epoch 314/1000
899/899 [==============================] - 0s - loss: 1.2278 - acc: 0.5695     
Epoch 315/1000
899/899 [==============================] - 0s - loss: 1.2397 - acc: 0.5551     
Epoch 316/1000
899/899 [==============================] - 0s - loss: 1.2138 - acc: 0.5684     
Epoch 317/1000
899/899 [==============================] - 0s - loss: 1.2203 - acc: 0.5684     
Epoch 318/1000
899/899 [==============================] - 0s - loss: 1.2146 - acc: 0.5684     
Epoch 319/1000
899/899 [==============================] - 0s - loss: 1.2127 - acc: 0.5673     
Epoch 320/1000
899/899 [==============================] - 0s - loss: 1.2138 - acc: 0.5695     
Epoch 321/1000
899/899 [==============================] - 0s - loss: 1.2183 - acc: 0.5684     
Epoch 322/1000
899/899 [==============================] - 0s - loss: 1.2161 - acc: 0.5706     
Epoch 323/1000
899/899 [==============================] - 0s - loss: 1.2135 - acc: 0.5806     
Epoch 324/1000
899/899 [==============================] - 0s - loss: 1.2154 - acc: 0.5717     
Epoch 325/1000
899/899 [==============================] - 0s - loss: 1.2024 - acc: 0.5806     
Epoch 326/1000
899/899 [==============================] - 0s - loss: 1.2063 - acc: 0.5773     
Epoch 327/1000
899/899 [==============================] - 0s - loss: 1.2118 - acc: 0.5773     
Epoch 328/1000
899/899 [==============================] - 0s - loss: 1.2023 - acc: 0.5806     
Epoch 329/1000
899/899 [==============================] - 0s - loss: 1.2110 - acc: 0.5662     
Epoch 330/1000
899/899 [==============================] - 0s - loss: 1.2010 - acc: 0.5829     
Epoch 331/1000
899/899 [==============================] - 0s - loss: 1.2095 - acc: 0.5662     
Epoch 332/1000
899/899 [==============================] - 0s - loss: 1.1992 - acc: 0.5907     
Epoch 333/1000
899/899 [==============================] - 0s - loss: 1.2151 - acc: 0.5784     
Epoch 334/1000
899/899 [==============================] - 0s - loss: 1.1999 - acc: 0.5762     
Epoch 335/1000
899/899 [==============================] - 0s - loss: 1.1981 - acc: 0.5806     
Epoch 336/1000
899/899 [==============================] - 0s - loss: 1.2014 - acc: 0.5806     
Epoch 337/1000
899/899 [==============================] - 0s - loss: 1.1897 - acc: 0.5918     
Epoch 338/1000
899/899 [==============================] - 0s - loss: 1.1986 - acc: 0.5751     
Epoch 339/1000
899/899 [==============================] - 0s - loss: 1.2025 - acc: 0.5806     
Epoch 340/1000
899/899 [==============================] - 0s - loss: 1.1837 - acc: 0.5873     
Epoch 341/1000
899/899 [==============================] - 0s - loss: 1.1920 - acc: 0.5729     
Epoch 342/1000
899/899 [==============================] - 0s - loss: 1.1913 - acc: 0.5873     
Epoch 343/1000
899/899 [==============================] - 0s - loss: 1.1933 - acc: 0.5829     
Epoch 344/1000
899/899 [==============================] - 0s - loss: 1.1884 - acc: 0.5873     
Epoch 345/1000
899/899 [==============================] - 0s - loss: 1.1861 - acc: 0.5773     
Epoch 346/1000
899/899 [==============================] - 0s - loss: 1.1847 - acc: 0.5840     
Epoch 347/1000
899/899 [==============================] - 0s - loss: 1.1775 - acc: 0.5907     
Epoch 348/1000
899/899 [==============================] - 0s - loss: 1.1813 - acc: 0.5840     
Epoch 349/1000
899/899 [==============================] - 0s - loss: 1.1872 - acc: 0.5884     
Epoch 350/1000
899/899 [==============================] - 0s - loss: 1.1794 - acc: 0.5829     
Epoch 351/1000
899/899 [==============================] - 0s - loss: 1.1783 - acc: 0.5862     
Epoch 352/1000
899/899 [==============================] - 0s - loss: 1.1803 - acc: 0.5751     
Epoch 353/1000
899/899 [==============================] - 0s - loss: 1.1791 - acc: 0.5818     
Epoch 354/1000
899/899 [==============================] - 0s - loss: 1.1728 - acc: 0.6007     
Epoch 355/1000
899/899 [==============================] - 0s - loss: 1.1755 - acc: 0.5929     
Epoch 356/1000
899/899 [==============================] - 0s - loss: 1.1722 - acc: 0.5951     
Epoch 357/1000
899/899 [==============================] - 0s - loss: 1.1728 - acc: 0.5829     
Epoch 358/1000
899/899 [==============================] - 0s - loss: 1.1721 - acc: 0.5996     
Epoch 359/1000
899/899 [==============================] - 0s - loss: 1.1779 - acc: 0.5751     
Epoch 360/1000
899/899 [==============================] - 0s - loss: 1.1791 - acc: 0.5829     
Epoch 361/1000
899/899 [==============================] - 0s - loss: 1.1654 - acc: 0.5873     
Epoch 362/1000
899/899 [==============================] - 0s - loss: 1.1759 - acc: 0.5940     
Epoch 363/1000
899/899 [==============================] - 0s - loss: 1.1749 - acc: 0.5929     
Epoch 364/1000
899/899 [==============================] - 0s - loss: 1.1668 - acc: 0.5862     
Epoch 365/1000
899/899 [==============================] - 0s - loss: 1.1612 - acc: 0.5895     
Epoch 366/1000
899/899 [==============================] - 0s - loss: 1.1585 - acc: 0.5962     
Epoch 367/1000
899/899 [==============================] - 0s - loss: 1.1714 - acc: 0.5851     
Epoch 368/1000
899/899 [==============================] - 0s - loss: 1.1710 - acc: 0.5840     
Epoch 369/1000
899/899 [==============================] - 0s - loss: 1.1571 - acc: 0.5996     
Epoch 370/1000
899/899 [==============================] - 0s - loss: 1.1659 - acc: 0.5873     
Epoch 371/1000
899/899 [==============================] - 0s - loss: 1.1499 - acc: 0.6051     
Epoch 372/1000
899/899 [==============================] - 0s - loss: 1.1590 - acc: 0.5895     
Epoch 373/1000
899/899 [==============================] - 0s - loss: 1.1498 - acc: 0.5984     
Epoch 374/1000
899/899 [==============================] - 0s - loss: 1.1532 - acc: 0.6073     
Epoch 375/1000
899/899 [==============================] - 0s - loss: 1.1582 - acc: 0.5951     
Epoch 376/1000
899/899 [==============================] - 0s - loss: 1.1523 - acc: 0.6040     
Epoch 377/1000
899/899 [==============================] - 0s - loss: 1.1473 - acc: 0.6029     
Epoch 378/1000
899/899 [==============================] - 0s - loss: 1.1458 - acc: 0.6062     
Epoch 379/1000
899/899 [==============================] - 0s - loss: 1.1728 - acc: 0.5862     
Epoch 380/1000
899/899 [==============================] - 0s - loss: 1.1496 - acc: 0.6029     
Epoch 381/1000
899/899 [==============================] - 0s - loss: 1.1442 - acc: 0.5996     
Epoch 382/1000
899/899 [==============================] - 0s - loss: 1.1440 - acc: 0.6007     
Epoch 383/1000
899/899 [==============================] - 0s - loss: 1.1430 - acc: 0.5951     
Epoch 384/1000
899/899 [==============================] - 0s - loss: 1.1402 - acc: 0.6051     
Epoch 385/1000
899/899 [==============================] - 0s - loss: 1.1463 - acc: 0.5996     
Epoch 386/1000
899/899 [==============================] - 0s - loss: 1.1362 - acc: 0.6062     
Epoch 387/1000
899/899 [==============================] - 0s - loss: 1.1401 - acc: 0.6085     
Epoch 388/1000
899/899 [==============================] - 0s - loss: 1.1418 - acc: 0.5984     
Epoch 389/1000
899/899 [==============================] - 0s - loss: 1.1274 - acc: 0.6107     
Epoch 390/1000
899/899 [==============================] - 0s - loss: 1.1372 - acc: 0.6096     
Epoch 391/1000
899/899 [==============================] - 0s - loss: 1.1338 - acc: 0.5984     
Epoch 392/1000
899/899 [==============================] - 0s - loss: 1.1347 - acc: 0.6029     
Epoch 393/1000
899/899 [==============================] - 0s - loss: 1.1248 - acc: 0.5984     
Epoch 394/1000
899/899 [==============================] - 0s - loss: 1.1384 - acc: 0.6029     
Epoch 395/1000
899/899 [==============================] - 0s - loss: 1.1378 - acc: 0.5884     
Epoch 396/1000
899/899 [==============================] - 0s - loss: 1.1224 - acc: 0.6040     
Epoch 397/1000
899/899 [==============================] - 0s - loss: 1.1292 - acc: 0.6073     
Epoch 398/1000
899/899 [==============================] - 0s - loss: 1.1253 - acc: 0.5884     
Epoch 399/1000
899/899 [==============================] - 0s - loss: 1.1283 - acc: 0.6040     
Epoch 400/1000
899/899 [==============================] - 0s - loss: 1.1258 - acc: 0.6029     
Epoch 401/1000
899/899 [==============================] - 0s - loss: 1.1301 - acc: 0.5951     
Epoch 402/1000
899/899 [==============================] - 0s - loss: 1.1253 - acc: 0.6118     
Epoch 403/1000
899/899 [==============================] - 0s - loss: 1.1228 - acc: 0.6040     
Epoch 404/1000
899/899 [==============================] - 0s - loss: 1.1213 - acc: 0.6118     
Epoch 405/1000
899/899 [==============================] - 0s - loss: 1.1136 - acc: 0.6218     
Epoch 406/1000
899/899 [==============================] - 0s - loss: 1.1271 - acc: 0.6018     
Epoch 407/1000
899/899 [==============================] - 0s - loss: 1.1144 - acc: 0.6118     
Epoch 408/1000
899/899 [==============================] - 0s - loss: 1.1225 - acc: 0.6107     
Epoch 409/1000
899/899 [==============================] - 0s - loss: 1.1162 - acc: 0.6129     
Epoch 410/1000
899/899 [==============================] - 0s - loss: 1.1138 - acc: 0.6073     
Epoch 411/1000
899/899 [==============================] - 0s - loss: 1.1177 - acc: 0.6218     
Epoch 412/1000
899/899 [==============================] - 0s - loss: 1.1158 - acc: 0.6107     
Epoch 413/1000
899/899 [==============================] - 0s - loss: 1.1133 - acc: 0.6085     
Epoch 414/1000
899/899 [==============================] - 0s - loss: 1.1047 - acc: 0.6140     
Epoch 415/1000
899/899 [==============================] - 0s - loss: 1.1060 - acc: 0.6140     
Epoch 416/1000
899/899 [==============================] - 0s - loss: 1.1104 - acc: 0.6140     
Epoch 417/1000
899/899 [==============================] - 0s - loss: 1.1080 - acc: 0.6029     
Epoch 418/1000
899/899 [==============================] - 0s - loss: 1.1056 - acc: 0.6162     
Epoch 419/1000
899/899 [==============================] - 0s - loss: 1.1063 - acc: 0.6107     
Epoch 420/1000
899/899 [==============================] - 0s - loss: 1.1126 - acc: 0.6029     
Epoch 421/1000
899/899 [==============================] - 0s - loss: 1.1069 - acc: 0.5973     
Epoch 422/1000
899/899 [==============================] - 0s - loss: 1.1022 - acc: 0.6207     
Epoch 423/1000
899/899 [==============================] - 0s - loss: 1.1052 - acc: 0.6162     
Epoch 424/1000
899/899 [==============================] - 0s - loss: 1.1065 - acc: 0.6129     
Epoch 425/1000
899/899 [==============================] - 0s - loss: 1.0949 - acc: 0.6218     
Epoch 426/1000
899/899 [==============================] - 0s - loss: 1.0987 - acc: 0.6129     
Epoch 427/1000
899/899 [==============================] - 0s - loss: 1.1110 - acc: 0.6151     
Epoch 428/1000
899/899 [==============================] - 0s - loss: 1.1002 - acc: 0.6251     
Epoch 429/1000
899/899 [==============================] - 0s - loss: 1.0997 - acc: 0.6162     
Epoch 430/1000
899/899 [==============================] - 0s - loss: 1.0910 - acc: 0.6151     
Epoch 431/1000
899/899 [==============================] - 0s - loss: 1.0958 - acc: 0.6029     
Epoch 432/1000
899/899 [==============================] - 0s - loss: 1.0897 - acc: 0.6174     
Epoch 433/1000
899/899 [==============================] - 0s - loss: 1.1135 - acc: 0.6029     
Epoch 434/1000
899/899 [==============================] - 0s - loss: 1.1004 - acc: 0.6162     
Epoch 435/1000
899/899 [==============================] - 0s - loss: 1.0951 - acc: 0.6073     
Epoch 436/1000
899/899 [==============================] - 0s - loss: 1.0909 - acc: 0.6251     
Epoch 437/1000
899/899 [==============================] - 0s - loss: 1.0986 - acc: 0.6162     
Epoch 438/1000
899/899 [==============================] - 0s - loss: 1.1015 - acc: 0.6096     
Epoch 439/1000
899/899 [==============================] - 0s - loss: 1.0878 - acc: 0.6251     
Epoch 440/1000
899/899 [==============================] - 0s - loss: 1.0838 - acc: 0.6229     
Epoch 441/1000
899/899 [==============================] - 0s - loss: 1.0795 - acc: 0.6229     
Epoch 442/1000
899/899 [==============================] - 0s - loss: 1.0823 - acc: 0.6207     
Epoch 443/1000
899/899 [==============================] - 0s - loss: 1.0874 - acc: 0.6151     
Epoch 444/1000
899/899 [==============================] - 0s - loss: 1.0760 - acc: 0.6440     
Epoch 445/1000
899/899 [==============================] - 0s - loss: 1.0803 - acc: 0.6218     
Epoch 446/1000
899/899 [==============================] - 0s - loss: 1.0765 - acc: 0.6296     
Epoch 447/1000
899/899 [==============================] - 0s - loss: 1.0922 - acc: 0.6140     
Epoch 448/1000
899/899 [==============================] - 0s - loss: 1.0764 - acc: 0.6274     
Epoch 449/1000
899/899 [==============================] - 0s - loss: 1.0758 - acc: 0.6307     
Epoch 450/1000
899/899 [==============================] - 0s - loss: 1.0835 - acc: 0.6196     
Epoch 451/1000
899/899 [==============================] - 0s - loss: 1.0709 - acc: 0.6285     
Epoch 452/1000
899/899 [==============================] - 0s - loss: 1.0758 - acc: 0.6274     
Epoch 453/1000
899/899 [==============================] - 0s - loss: 1.0724 - acc: 0.6352     
Epoch 454/1000
899/899 [==============================] - 0s - loss: 1.0687 - acc: 0.6251     
Epoch 455/1000
899/899 [==============================] - 0s - loss: 1.0670 - acc: 0.6363     
Epoch 456/1000
899/899 [==============================] - 0s - loss: 1.0752 - acc: 0.6263     
Epoch 457/1000
899/899 [==============================] - 0s - loss: 1.0665 - acc: 0.6274     
Epoch 458/1000
899/899 [==============================] - 0s - loss: 1.0814 - acc: 0.6174     
Epoch 459/1000
899/899 [==============================] - 0s - loss: 1.0707 - acc: 0.6296     
Epoch 460/1000
899/899 [==============================] - 0s - loss: 1.0894 - acc: 0.6196     
Epoch 461/1000
899/899 [==============================] - 0s - loss: 1.0579 - acc: 0.6285     
Epoch 462/1000
899/899 [==============================] - 0s - loss: 1.0628 - acc: 0.6240     
Epoch 463/1000
899/899 [==============================] - 0s - loss: 1.0867 - acc: 0.6085     
Epoch 464/1000
899/899 [==============================] - 0s - loss: 1.0661 - acc: 0.6140     
Epoch 465/1000
899/899 [==============================] - 0s - loss: 1.0619 - acc: 0.6285     
Epoch 466/1000
899/899 [==============================] - 0s - loss: 1.0749 - acc: 0.6251     
Epoch 467/1000
899/899 [==============================] - 0s - loss: 1.0523 - acc: 0.6229     
Epoch 468/1000
899/899 [==============================] - 0s - loss: 1.0620 - acc: 0.6352     
Epoch 469/1000
899/899 [==============================] - 0s - loss: 1.0538 - acc: 0.6374     
Epoch 470/1000
899/899 [==============================] - 0s - loss: 1.0565 - acc: 0.6329     
Epoch 471/1000
899/899 [==============================] - 0s - loss: 1.0555 - acc: 0.6307     
Epoch 472/1000
899/899 [==============================] - 0s - loss: 1.0542 - acc: 0.6318     
Epoch 473/1000
899/899 [==============================] - 0s - loss: 1.0541 - acc: 0.6240     
Epoch 474/1000
899/899 [==============================] - 0s - loss: 1.0581 - acc: 0.6285     
Epoch 475/1000
899/899 [==============================] - 0s - loss: 1.0516 - acc: 0.6229     
Epoch 476/1000
899/899 [==============================] - 0s - loss: 1.0540 - acc: 0.6352     
Epoch 477/1000
899/899 [==============================] - 0s - loss: 1.0598 - acc: 0.6307     
Epoch 478/1000
899/899 [==============================] - 0s - loss: 1.0607 - acc: 0.6196     
Epoch 479/1000
899/899 [==============================] - 0s - loss: 1.0471 - acc: 0.6396     
Epoch 480/1000
899/899 [==============================] - 0s - loss: 1.0438 - acc: 0.6407     
Epoch 481/1000
899/899 [==============================] - 0s - loss: 1.0415 - acc: 0.6318     
Epoch 482/1000
899/899 [==============================] - ETA: 0s - loss: 1.2645 - acc: 0.500 - 0s - loss: 1.0418 - acc: 0.6307     
Epoch 483/1000
899/899 [==============================] - 0s - loss: 1.0452 - acc: 0.6363     
Epoch 484/1000
899/899 [==============================] - 0s - loss: 1.0492 - acc: 0.6218     
Epoch 485/1000
899/899 [==============================] - 0s - loss: 1.0527 - acc: 0.6329     
Epoch 486/1000
899/899 [==============================] - 0s - loss: 1.0610 - acc: 0.6207     
Epoch 487/1000
899/899 [==============================] - 0s - loss: 1.0545 - acc: 0.6363     
Epoch 488/1000
899/899 [==============================] - 0s - loss: 1.0324 - acc: 0.6485     
Epoch 489/1000
899/899 [==============================] - 0s - loss: 1.0445 - acc: 0.6307     
Epoch 490/1000
899/899 [==============================] - 0s - loss: 1.0369 - acc: 0.6440     
Epoch 491/1000
899/899 [==============================] - 0s - loss: 1.0314 - acc: 0.6452     
Epoch 492/1000
899/899 [==============================] - 0s - loss: 1.0442 - acc: 0.6340     
Epoch 493/1000
899/899 [==============================] - 0s - loss: 1.0403 - acc: 0.6318     
Epoch 494/1000
899/899 [==============================] - 0s - loss: 1.0427 - acc: 0.6340     
Epoch 495/1000
899/899 [==============================] - 0s - loss: 1.0330 - acc: 0.6307     
Epoch 496/1000
899/899 [==============================] - 0s - loss: 1.0227 - acc: 0.6385     
Epoch 497/1000
899/899 [==============================] - 0s - loss: 1.0414 - acc: 0.6318     
Epoch 498/1000
899/899 [==============================] - 0s - loss: 1.0238 - acc: 0.6407     
Epoch 499/1000
899/899 [==============================] - 0s - loss: 1.0294 - acc: 0.6374     
Epoch 500/1000
899/899 [==============================] - 0s - loss: 1.0201 - acc: 0.6440     
Epoch 501/1000
899/899 [==============================] - 0s - loss: 1.0175 - acc: 0.6385     
Epoch 502/1000
899/899 [==============================] - 0s - loss: 1.0248 - acc: 0.6474     
Epoch 503/1000
899/899 [==============================] - 0s - loss: 1.0266 - acc: 0.6318     
Epoch 504/1000
899/899 [==============================] - 0s - loss: 1.0254 - acc: 0.6274     
Epoch 505/1000
899/899 [==============================] - 0s - loss: 1.0211 - acc: 0.6429     
Epoch 506/1000
899/899 [==============================] - 0s - loss: 1.0240 - acc: 0.6496     
Epoch 507/1000
899/899 [==============================] - 0s - loss: 1.0192 - acc: 0.6407     
Epoch 508/1000
899/899 [==============================] - 0s - loss: 1.0213 - acc: 0.6352     
Epoch 509/1000
899/899 [==============================] - 0s - loss: 1.0134 - acc: 0.6496     
Epoch 510/1000
899/899 [==============================] - 0s - loss: 1.0182 - acc: 0.6418     
Epoch 511/1000
899/899 [==============================] - 0s - loss: 1.0110 - acc: 0.6529     
Epoch 512/1000
899/899 [==============================] - 0s - loss: 1.0243 - acc: 0.6385     
Epoch 513/1000
899/899 [==============================] - 0s - loss: 1.0101 - acc: 0.6607     
Epoch 514/1000
899/899 [==============================] - 0s - loss: 1.0086 - acc: 0.6552     
Epoch 515/1000
899/899 [==============================] - 0s - loss: 1.0142 - acc: 0.6507     
Epoch 516/1000
899/899 [==============================] - 0s - loss: 1.0234 - acc: 0.6307     
Epoch 517/1000
899/899 [==============================] - 0s - loss: 1.0085 - acc: 0.6474     
Epoch 518/1000
899/899 [==============================] - 0s - loss: 1.0101 - acc: 0.6507     
Epoch 519/1000
899/899 [==============================] - 0s - loss: 1.0032 - acc: 0.6407     
Epoch 520/1000
899/899 [==============================] - 0s - loss: 1.0223 - acc: 0.6418     
Epoch 521/1000
899/899 [==============================] - 0s - loss: 1.0157 - acc: 0.6418     
Epoch 522/1000
899/899 [==============================] - 0s - loss: 1.0091 - acc: 0.6385     
Epoch 523/1000
899/899 [==============================] - 0s - loss: 1.0217 - acc: 0.6440     
Epoch 524/1000
899/899 [==============================] - 0s - loss: 1.0123 - acc: 0.6374     
Epoch 525/1000
899/899 [==============================] - 0s - loss: 0.9953 - acc: 0.6440     
Epoch 526/1000
899/899 [==============================] - 0s - loss: 0.9993 - acc: 0.6496     
Epoch 527/1000
899/899 [==============================] - 0s - loss: 1.0067 - acc: 0.6352     
Epoch 528/1000
899/899 [==============================] - 0s - loss: 1.0120 - acc: 0.6396     
Epoch 529/1000
899/899 [==============================] - 0s - loss: 1.0076 - acc: 0.6463     
Epoch 530/1000
899/899 [==============================] - 0s - loss: 0.9988 - acc: 0.6607     
Epoch 531/1000
899/899 [==============================] - 0s - loss: 0.9957 - acc: 0.6607     
Epoch 532/1000
899/899 [==============================] - 0s - loss: 0.9950 - acc: 0.6563     
Epoch 533/1000
899/899 [==============================] - 0s - loss: 1.0000 - acc: 0.6463     
Epoch 534/1000
899/899 [==============================] - 0s - loss: 0.9966 - acc: 0.6596     
Epoch 535/1000
899/899 [==============================] - 0s - loss: 0.9960 - acc: 0.6563     
Epoch 536/1000
899/899 [==============================] - 0s - loss: 0.9903 - acc: 0.6563     
Epoch 537/1000
899/899 [==============================] - 0s - loss: 1.0033 - acc: 0.6440     
Epoch 538/1000
899/899 [==============================] - 0s - loss: 0.9874 - acc: 0.6552     
Epoch 539/1000
899/899 [==============================] - 0s - loss: 1.0042 - acc: 0.6429     
Epoch 540/1000
899/899 [==============================] - 0s - loss: 0.9942 - acc: 0.6618     
Epoch 541/1000
899/899 [==============================] - 0s - loss: 0.9893 - acc: 0.6463     
Epoch 542/1000
899/899 [==============================] - 0s - loss: 0.9821 - acc: 0.6618     
Epoch 543/1000
899/899 [==============================] - 0s - loss: 0.9971 - acc: 0.6440     
Epoch 544/1000
899/899 [==============================] - 0s - loss: 1.0023 - acc: 0.6463     
Epoch 545/1000
899/899 [==============================] - 0s - loss: 0.9975 - acc: 0.6407     
Epoch 546/1000
899/899 [==============================] - 0s - loss: 0.9847 - acc: 0.6685     
Epoch 547/1000
899/899 [==============================] - 0s - loss: 0.9857 - acc: 0.6630     
Epoch 548/1000
899/899 [==============================] - 0s - loss: 0.9944 - acc: 0.6485     
Epoch 549/1000
899/899 [==============================] - 0s - loss: 0.9857 - acc: 0.6529     
Epoch 550/1000
899/899 [==============================] - 0s - loss: 0.9803 - acc: 0.6630     
Epoch 551/1000
899/899 [==============================] - 0s - loss: 0.9774 - acc: 0.6652     
Epoch 552/1000
899/899 [==============================] - 0s - loss: 0.9766 - acc: 0.6663     
Epoch 553/1000
899/899 [==============================] - 0s - loss: 0.9764 - acc: 0.6696     
Epoch 554/1000
899/899 [==============================] - 0s - loss: 0.9812 - acc: 0.6774     
Epoch 555/1000
899/899 [==============================] - 0s - loss: 0.9846 - acc: 0.6452     
Epoch 556/1000
899/899 [==============================] - 0s - loss: 0.9858 - acc: 0.6440     
Epoch 557/1000
899/899 [==============================] - 0s - loss: 0.9748 - acc: 0.6596     
Epoch 558/1000
899/899 [==============================] - 0s - loss: 0.9832 - acc: 0.6429     
Epoch 559/1000
899/899 [==============================] - 0s - loss: 0.9675 - acc: 0.6785     
Epoch 560/1000
899/899 [==============================] - 0s - loss: 0.9903 - acc: 0.6529     
Epoch 561/1000
899/899 [==============================] - 0s - loss: 0.9686 - acc: 0.6741     
Epoch 562/1000
899/899 [==============================] - 0s - loss: 0.9780 - acc: 0.6541     
Epoch 563/1000
899/899 [==============================] - 0s - loss: 0.9685 - acc: 0.6685     
Epoch 564/1000
899/899 [==============================] - 0s - loss: 0.9675 - acc: 0.6641     
Epoch 565/1000
899/899 [==============================] - 0s - loss: 0.9686 - acc: 0.6641     
Epoch 566/1000
899/899 [==============================] - 0s - loss: 0.9702 - acc: 0.6641     
Epoch 567/1000
899/899 [==============================] - 0s - loss: 0.9656 - acc: 0.6641     
Epoch 568/1000
899/899 [==============================] - 0s - loss: 0.9659 - acc: 0.6585     
Epoch 569/1000
899/899 [==============================] - 0s - loss: 0.9720 - acc: 0.6641     
Epoch 570/1000
899/899 [==============================] - 0s - loss: 0.9773 - acc: 0.6529     
Epoch 571/1000
899/899 [==============================] - 0s - loss: 0.9707 - acc: 0.6696     
Epoch 572/1000
899/899 [==============================] - ETA: 0s - loss: 1.0208 - acc: 0.656 - 0s - loss: 0.9575 - acc: 0.6607     
Epoch 573/1000
899/899 [==============================] - 0s - loss: 0.9669 - acc: 0.6630     
Epoch 574/1000
899/899 [==============================] - 0s - loss: 0.9581 - acc: 0.6607     
Epoch 575/1000
899/899 [==============================] - 0s - loss: 0.9558 - acc: 0.6596     
Epoch 576/1000
899/899 [==============================] - 0s - loss: 0.9580 - acc: 0.6607     
Epoch 577/1000
899/899 [==============================] - 0s - loss: 0.9573 - acc: 0.6663     
Epoch 578/1000
899/899 [==============================] - 0s - loss: 0.9731 - acc: 0.6518     
Epoch 579/1000
899/899 [==============================] - 0s - loss: 0.9628 - acc: 0.6674     
Epoch 580/1000
899/899 [==============================] - 0s - loss: 0.9568 - acc: 0.6641     
Epoch 581/1000
899/899 [==============================] - 0s - loss: 0.9572 - acc: 0.6719     
Epoch 582/1000
899/899 [==============================] - 0s - loss: 0.9587 - acc: 0.6474     
Epoch 583/1000
899/899 [==============================] - 0s - loss: 0.9533 - acc: 0.6630     
Epoch 584/1000
899/899 [==============================] - 0s - loss: 0.9462 - acc: 0.6763     
Epoch 585/1000
899/899 [==============================] - 0s - loss: 0.9615 - acc: 0.6641     
Epoch 586/1000
899/899 [==============================] - 0s - loss: 0.9524 - acc: 0.6719     
Epoch 587/1000
899/899 [==============================] - 0s - loss: 0.9594 - acc: 0.6730     
Epoch 588/1000
899/899 [==============================] - 0s - loss: 0.9567 - acc: 0.6674     
Epoch 589/1000
899/899 [==============================] - 0s - loss: 0.9572 - acc: 0.6696     
Epoch 590/1000
899/899 [==============================] - 0s - loss: 0.9485 - acc: 0.6785     
Epoch 591/1000
899/899 [==============================] - 0s - loss: 0.9412 - acc: 0.6841     
Epoch 592/1000
899/899 [==============================] - 0s - loss: 0.9451 - acc: 0.6552     
Epoch 593/1000
899/899 [==============================] - 0s - loss: 0.9528 - acc: 0.6730     
Epoch 594/1000
899/899 [==============================] - 0s - loss: 0.9463 - acc: 0.6752     
Epoch 595/1000
899/899 [==============================] - 0s - loss: 0.9516 - acc: 0.6641     
Epoch 596/1000
899/899 [==============================] - 0s - loss: 0.9456 - acc: 0.6841     
Epoch 597/1000
899/899 [==============================] - 0s - loss: 0.9428 - acc: 0.6808     
Epoch 598/1000
899/899 [==============================] - 0s - loss: 0.9488 - acc: 0.6652     
Epoch 599/1000
899/899 [==============================] - 0s - loss: 0.9398 - acc: 0.6785     
Epoch 600/1000
899/899 [==============================] - 0s - loss: 0.9390 - acc: 0.6908     
Epoch 601/1000
899/899 [==============================] - 0s - loss: 0.9405 - acc: 0.6796     
Epoch 602/1000
899/899 [==============================] - 0s - loss: 0.9355 - acc: 0.6841     
Epoch 603/1000
899/899 [==============================] - 0s - loss: 0.9339 - acc: 0.6852     
Epoch 604/1000
899/899 [==============================] - 0s - loss: 0.9305 - acc: 0.6852     
Epoch 605/1000
899/899 [==============================] - 0s - loss: 0.9509 - acc: 0.6785     
Epoch 606/1000
899/899 [==============================] - 0s - loss: 0.9302 - acc: 0.6785     
Epoch 607/1000
899/899 [==============================] - 0s - loss: 0.9298 - acc: 0.6841     
Epoch 608/1000
899/899 [==============================] - 0s - loss: 0.9447 - acc: 0.6763     
Epoch 609/1000
899/899 [==============================] - 0s - loss: 0.9398 - acc: 0.6774     
Epoch 610/1000
899/899 [==============================] - 0s - loss: 0.9441 - acc: 0.6897     
Epoch 611/1000
899/899 [==============================] - 0s - loss: 0.9299 - acc: 0.6863     
Epoch 612/1000
899/899 [==============================] - 0s - loss: 0.9247 - acc: 0.6830     
Epoch 613/1000
899/899 [==============================] - 0s - loss: 0.9389 - acc: 0.6808     
Epoch 614/1000
899/899 [==============================] - 0s - loss: 0.9360 - acc: 0.6830     
Epoch 615/1000
899/899 [==============================] - 0s - loss: 0.9342 - acc: 0.6796     
Epoch 616/1000
899/899 [==============================] - 0s - loss: 0.9247 - acc: 0.6908     
Epoch 617/1000
899/899 [==============================] - 0s - loss: 0.9149 - acc: 0.6863     
Epoch 618/1000
899/899 [==============================] - 0s - loss: 0.9215 - acc: 0.6819     
Epoch 619/1000
899/899 [==============================] - 0s - loss: 0.9354 - acc: 0.6752     
Epoch 620/1000
899/899 [==============================] - 0s - loss: 0.9289 - acc: 0.6819     
Epoch 621/1000
899/899 [==============================] - 0s - loss: 0.9209 - acc: 0.6952     
Epoch 622/1000
899/899 [==============================] - 0s - loss: 0.9131 - acc: 0.7041     
Epoch 623/1000
899/899 [==============================] - 0s - loss: 0.9133 - acc: 0.6874     
Epoch 624/1000
899/899 [==============================] - 0s - loss: 0.9175 - acc: 0.6885     
Epoch 625/1000
899/899 [==============================] - 0s - loss: 0.9201 - acc: 0.6919     
Epoch 626/1000
899/899 [==============================] - 0s - loss: 0.9268 - acc: 0.6908     
Epoch 627/1000
899/899 [==============================] - 0s - loss: 0.9163 - acc: 0.6819     
Epoch 628/1000
899/899 [==============================] - 0s - loss: 0.9166 - acc: 0.6808     
Epoch 629/1000
899/899 [==============================] - 0s - loss: 0.9145 - acc: 0.6908     
Epoch 630/1000
899/899 [==============================] - 0s - loss: 0.9235 - acc: 0.6874     
Epoch 631/1000
899/899 [==============================] - 0s - loss: 0.9140 - acc: 0.6885     
Epoch 632/1000
899/899 [==============================] - 0s - loss: 0.9199 - acc: 0.6785     
Epoch 633/1000
899/899 [==============================] - 0s - loss: 0.9143 - acc: 0.6885     
Epoch 634/1000
899/899 [==============================] - 0s - loss: 0.9116 - acc: 0.6863     
Epoch 635/1000
899/899 [==============================] - 0s - loss: 0.9117 - acc: 0.6852     
Epoch 636/1000
899/899 [==============================] - 0s - loss: 0.9057 - acc: 0.6874     
Epoch 637/1000
899/899 [==============================] - 0s - loss: 0.9066 - acc: 0.6885     
Epoch 638/1000
899/899 [==============================] - 0s - loss: 0.9189 - acc: 0.6897     
Epoch 639/1000
899/899 [==============================] - 0s - loss: 0.9103 - acc: 0.6897     
Epoch 640/1000
899/899 [==============================] - 0s - loss: 0.9067 - acc: 0.6974     
Epoch 641/1000
899/899 [==============================] - 0s - loss: 0.9028 - acc: 0.6808     
Epoch 642/1000
899/899 [==============================] - 0s - loss: 0.9024 - acc: 0.6930     
Epoch 643/1000
899/899 [==============================] - 0s - loss: 0.9172 - acc: 0.6852     
Epoch 644/1000
899/899 [==============================] - 0s - loss: 0.9119 - acc: 0.6830     
Epoch 645/1000
899/899 [==============================] - 0s - loss: 0.9129 - acc: 0.6941     
Epoch 646/1000
899/899 [==============================] - 0s - loss: 0.8988 - acc: 0.7019     
Epoch 647/1000
899/899 [==============================] - 0s - loss: 0.9062 - acc: 0.6941     
Epoch 648/1000
899/899 [==============================] - 0s - loss: 0.8980 - acc: 0.6952     
Epoch 649/1000
899/899 [==============================] - 0s - loss: 0.8937 - acc: 0.6986     
Epoch 650/1000
899/899 [==============================] - 0s - loss: 0.8944 - acc: 0.7008     
Epoch 651/1000
899/899 [==============================] - 0s - loss: 0.9097 - acc: 0.6874     
Epoch 652/1000
899/899 [==============================] - 0s - loss: 0.9075 - acc: 0.6919     
Epoch 653/1000
899/899 [==============================] - 0s - loss: 0.9069 - acc: 0.6819     
Epoch 654/1000
899/899 [==============================] - 0s - loss: 0.8990 - acc: 0.6930     
Epoch 655/1000
899/899 [==============================] - 0s - loss: 0.8919 - acc: 0.7008     
Epoch 656/1000
899/899 [==============================] - 0s - loss: 0.8979 - acc: 0.6919     
Epoch 657/1000
899/899 [==============================] - 0s - loss: 0.8925 - acc: 0.6974     
Epoch 658/1000
899/899 [==============================] - 0s - loss: 0.8893 - acc: 0.6930     
Epoch 659/1000
899/899 [==============================] - 0s - loss: 0.8978 - acc: 0.7008     
Epoch 660/1000
899/899 [==============================] - 0s - loss: 0.8881 - acc: 0.6952     
Epoch 661/1000
899/899 [==============================] - 0s - loss: 0.9006 - acc: 0.6941     
Epoch 662/1000
899/899 [==============================] - 0s - loss: 0.9104 - acc: 0.6774     
Epoch 663/1000
899/899 [==============================] - 0s - loss: 0.8851 - acc: 0.7063     
Epoch 664/1000
899/899 [==============================] - 0s - loss: 0.8793 - acc: 0.7119     
Epoch 665/1000
899/899 [==============================] - 0s - loss: 0.8811 - acc: 0.7030     
Epoch 666/1000
899/899 [==============================] - 0s - loss: 0.8766 - acc: 0.7175     
Epoch 667/1000
899/899 [==============================] - 0s - loss: 0.8866 - acc: 0.7086     
Epoch 668/1000
899/899 [==============================] - 0s - loss: 0.8960 - acc: 0.6808     
Epoch 669/1000
899/899 [==============================] - 0s - loss: 0.8848 - acc: 0.7097     
Epoch 670/1000
899/899 [==============================] - 0s - loss: 0.8882 - acc: 0.6874     
Epoch 671/1000
899/899 [==============================] - 0s - loss: 0.8873 - acc: 0.7008     
Epoch 672/1000
899/899 [==============================] - 0s - loss: 0.8774 - acc: 0.7019     
Epoch 673/1000
899/899 [==============================] - 0s - loss: 0.8769 - acc: 0.7063     
Epoch 674/1000
899/899 [==============================] - 0s - loss: 0.8804 - acc: 0.6986     
Epoch 675/1000
899/899 [==============================] - 0s - loss: 0.8914 - acc: 0.7075     
Epoch 676/1000
899/899 [==============================] - 0s - loss: 0.8775 - acc: 0.7075     
Epoch 677/1000
899/899 [==============================] - 0s - loss: 0.8817 - acc: 0.6986     
Epoch 678/1000
899/899 [==============================] - 0s - loss: 0.8786 - acc: 0.7063     
Epoch 679/1000
899/899 [==============================] - 0s - loss: 0.8820 - acc: 0.7108     
Epoch 680/1000
899/899 [==============================] - 0s - loss: 0.9113 - acc: 0.6852     
Epoch 681/1000
899/899 [==============================] - 0s - loss: 0.8803 - acc: 0.6997     
Epoch 682/1000
899/899 [==============================] - 0s - loss: 0.8896 - acc: 0.6930     
Epoch 683/1000
899/899 [==============================] - 0s - loss: 0.8842 - acc: 0.6963     
Epoch 684/1000
899/899 [==============================] - 0s - loss: 0.8718 - acc: 0.7041     
Epoch 685/1000
899/899 [==============================] - 0s - loss: 0.8741 - acc: 0.6986     
Epoch 686/1000
899/899 [==============================] - 0s - loss: 0.8680 - acc: 0.7075     
Epoch 687/1000
899/899 [==============================] - 0s - loss: 0.8686 - acc: 0.7041     
Epoch 688/1000
899/899 [==============================] - 0s - loss: 0.8661 - acc: 0.7075     
Epoch 689/1000
899/899 [==============================] - 0s - loss: 0.8724 - acc: 0.7019     
Epoch 690/1000
899/899 [==============================] - 0s - loss: 0.8653 - acc: 0.7186     
Epoch 691/1000
899/899 [==============================] - 0s - loss: 0.8659 - acc: 0.7130     
Epoch 692/1000
899/899 [==============================] - 0s - loss: 0.8616 - acc: 0.7219     
Epoch 693/1000
899/899 [==============================] - 0s - loss: 0.8590 - acc: 0.7030     
Epoch 694/1000
899/899 [==============================] - 0s - loss: 0.8672 - acc: 0.6986     
Epoch 695/1000
899/899 [==============================] - 0s - loss: 0.8677 - acc: 0.7175     
Epoch 696/1000
899/899 [==============================] - 0s - loss: 0.8636 - acc: 0.7063     
Epoch 697/1000
899/899 [==============================] - 0s - loss: 0.8631 - acc: 0.7141     
Epoch 698/1000
899/899 [==============================] - 0s - loss: 0.8643 - acc: 0.7130     
Epoch 699/1000
899/899 [==============================] - 0s - loss: 0.8651 - acc: 0.7175     
Epoch 700/1000
899/899 [==============================] - 0s - loss: 0.8661 - acc: 0.7086     
Epoch 701/1000
899/899 [==============================] - 0s - loss: 0.8625 - acc: 0.7152     
Epoch 702/1000
899/899 [==============================] - 0s - loss: 0.8558 - acc: 0.7175     
Epoch 703/1000
899/899 [==============================] - 0s - loss: 0.8646 - acc: 0.7041     
Epoch 704/1000
899/899 [==============================] - 0s - loss: 0.8484 - acc: 0.7208     
Epoch 705/1000
899/899 [==============================] - 0s - loss: 0.8499 - acc: 0.7063     
Epoch 706/1000
899/899 [==============================] - 0s - loss: 0.8650 - acc: 0.7230     
Epoch 707/1000
899/899 [==============================] - 0s - loss: 0.8526 - acc: 0.7152     
Epoch 708/1000
899/899 [==============================] - 0s - loss: 0.8590 - acc: 0.7175     
Epoch 709/1000
899/899 [==============================] - 0s - loss: 0.8532 - acc: 0.7219     
Epoch 710/1000
899/899 [==============================] - 0s - loss: 0.8597 - acc: 0.7052     
Epoch 711/1000
899/899 [==============================] - 0s - loss: 0.8485 - acc: 0.7175     
Epoch 712/1000
899/899 [==============================] - 0s - loss: 0.8452 - acc: 0.7230     
Epoch 713/1000
899/899 [==============================] - 0s - loss: 0.8458 - acc: 0.7152     
Epoch 714/1000
899/899 [==============================] - 0s - loss: 0.8439 - acc: 0.7108     
Epoch 715/1000
899/899 [==============================] - 0s - loss: 0.8550 - acc: 0.7152     
Epoch 716/1000
899/899 [==============================] - 0s - loss: 0.8538 - acc: 0.7186     
Epoch 717/1000
899/899 [==============================] - 0s - loss: 0.8453 - acc: 0.7197     
Epoch 718/1000
899/899 [==============================] - 0s - loss: 0.8554 - acc: 0.6997     
Epoch 719/1000
899/899 [==============================] - 0s - loss: 0.8468 - acc: 0.7275     
Epoch 720/1000
899/899 [==============================] - 0s - loss: 0.8403 - acc: 0.7308     
Epoch 721/1000
899/899 [==============================] - 0s - loss: 0.8401 - acc: 0.7230     
Epoch 722/1000
899/899 [==============================] - 0s - loss: 0.8405 - acc: 0.7275     
Epoch 723/1000
899/899 [==============================] - 0s - loss: 0.8396 - acc: 0.7186     
Epoch 724/1000
899/899 [==============================] - 0s - loss: 0.8457 - acc: 0.7152     
Epoch 725/1000
899/899 [==============================] - 0s - loss: 0.8387 - acc: 0.7175     
Epoch 726/1000
899/899 [==============================] - 0s - loss: 0.8463 - acc: 0.7241     
Epoch 727/1000
899/899 [==============================] - 0s - loss: 0.8348 - acc: 0.7219     
Epoch 728/1000
899/899 [==============================] - 0s - loss: 0.8462 - acc: 0.7164     
Epoch 729/1000
899/899 [==============================] - 0s - loss: 0.8378 - acc: 0.7241     
Epoch 730/1000
899/899 [==============================] - 0s - loss: 0.8406 - acc: 0.7152     
Epoch 731/1000
899/899 [==============================] - 0s - loss: 0.8383 - acc: 0.7208     
Epoch 732/1000
899/899 [==============================] - 0s - loss: 0.8454 - acc: 0.7075     
Epoch 733/1000
899/899 [==============================] - 0s - loss: 0.8680 - acc: 0.7008     
Epoch 734/1000
899/899 [==============================] - 0s - loss: 0.8333 - acc: 0.7375     
Epoch 735/1000
899/899 [==============================] - 0s - loss: 0.8306 - acc: 0.7253     
Epoch 736/1000
899/899 [==============================] - 0s - loss: 0.8311 - acc: 0.7419     
Epoch 737/1000
899/899 [==============================] - 0s - loss: 0.8367 - acc: 0.7330     
Epoch 738/1000
899/899 [==============================] - 0s - loss: 0.8437 - acc: 0.7219     
Epoch 739/1000
899/899 [==============================] - 0s - loss: 0.8340 - acc: 0.7308     
Epoch 740/1000
899/899 [==============================] - 0s - loss: 0.8330 - acc: 0.7353     
Epoch 741/1000
899/899 [==============================] - 0s - loss: 0.8403 - acc: 0.7275     
Epoch 742/1000
899/899 [==============================] - 0s - loss: 0.8325 - acc: 0.7330     
Epoch 743/1000
899/899 [==============================] - 0s - loss: 0.8287 - acc: 0.7297     
Epoch 744/1000
899/899 [==============================] - 0s - loss: 0.8202 - acc: 0.7464     
Epoch 745/1000
899/899 [==============================] - 0s - loss: 0.8272 - acc: 0.7353     
Epoch 746/1000
899/899 [==============================] - 0s - loss: 0.8291 - acc: 0.7375     
Epoch 747/1000
899/899 [==============================] - 0s - loss: 0.8270 - acc: 0.7219     
Epoch 748/1000
899/899 [==============================] - 0s - loss: 0.8287 - acc: 0.7275     
Epoch 749/1000
899/899 [==============================] - 0s - loss: 0.8180 - acc: 0.7341     
Epoch 750/1000
899/899 [==============================] - 0s - loss: 0.8390 - acc: 0.7097     
Epoch 751/1000
899/899 [==============================] - 0s - loss: 0.8224 - acc: 0.7364     
Epoch 752/1000
899/899 [==============================] - 0s - loss: 0.8309 - acc: 0.7308     
Epoch 753/1000
899/899 [==============================] - 0s - loss: 0.8098 - acc: 0.7364     
Epoch 754/1000
899/899 [==============================] - 0s - loss: 0.8196 - acc: 0.7319     
Epoch 755/1000
899/899 [==============================] - 0s - loss: 0.8274 - acc: 0.7308     
Epoch 756/1000
899/899 [==============================] - 0s - loss: 0.8121 - acc: 0.7297     
Epoch 757/1000
899/899 [==============================] - 0s - loss: 0.8109 - acc: 0.7219     
Epoch 758/1000
899/899 [==============================] - 0s - loss: 0.8227 - acc: 0.7308     
Epoch 759/1000
899/899 [==============================] - 0s - loss: 0.8128 - acc: 0.7375     
Epoch 760/1000
899/899 [==============================] - 0s - loss: 0.8228 - acc: 0.7286     
Epoch 761/1000
899/899 [==============================] - 0s - loss: 0.8302 - acc: 0.7319     
Epoch 762/1000
899/899 [==============================] - 0s - loss: 0.8156 - acc: 0.7341     
Epoch 763/1000
899/899 [==============================] - 0s - loss: 0.8187 - acc: 0.7275     
Epoch 764/1000
899/899 [==============================] - 0s - loss: 0.8157 - acc: 0.7264     
Epoch 765/1000
899/899 [==============================] - 0s - loss: 0.8254 - acc: 0.7197     
Epoch 766/1000
899/899 [==============================] - 0s - loss: 0.8324 - acc: 0.7108     
Epoch 767/1000
899/899 [==============================] - 0s - loss: 0.8064 - acc: 0.7397     
Epoch 768/1000
899/899 [==============================] - 0s - loss: 0.8149 - acc: 0.7386     
Epoch 769/1000
899/899 [==============================] - 0s - loss: 0.8153 - acc: 0.7330     
Epoch 770/1000
899/899 [==============================] - 0s - loss: 0.8040 - acc: 0.7364     
Epoch 771/1000
899/899 [==============================] - 0s - loss: 0.8124 - acc: 0.7353     
Epoch 772/1000
899/899 [==============================] - 0s - loss: 0.8059 - acc: 0.7408     
Epoch 773/1000
899/899 [==============================] - 0s - loss: 0.7934 - acc: 0.7508     
Epoch 774/1000
899/899 [==============================] - 0s - loss: 0.7999 - acc: 0.7386     
Epoch 775/1000
899/899 [==============================] - 0s - loss: 0.8041 - acc: 0.7275     
Epoch 776/1000
899/899 [==============================] - 0s - loss: 0.8197 - acc: 0.7197     
Epoch 777/1000
899/899 [==============================] - 0s - loss: 0.8032 - acc: 0.7430     
Epoch 778/1000
899/899 [==============================] - 0s - loss: 0.8017 - acc: 0.7397     
Epoch 779/1000
899/899 [==============================] - 0s - loss: 0.7963 - acc: 0.7519     
Epoch 780/1000
899/899 [==============================] - 0s - loss: 0.8057 - acc: 0.7375     
Epoch 781/1000
899/899 [==============================] - 0s - loss: 0.7959 - acc: 0.7408     
Epoch 782/1000
899/899 [==============================] - 0s - loss: 0.8010 - acc: 0.7486     
Epoch 783/1000
899/899 [==============================] - 0s - loss: 0.7967 - acc: 0.7375     
Epoch 784/1000
899/899 [==============================] - 0s - loss: 0.8066 - acc: 0.7364     
Epoch 785/1000
899/899 [==============================] - 0s - loss: 0.7931 - acc: 0.7486     
Epoch 786/1000
899/899 [==============================] - 0s - loss: 0.8180 - acc: 0.7375     
Epoch 787/1000
899/899 [==============================] - 0s - loss: 0.8282 - acc: 0.7130     
Epoch 788/1000
899/899 [==============================] - 0s - loss: 0.7967 - acc: 0.7408     
Epoch 789/1000
899/899 [==============================] - 0s - loss: 0.8050 - acc: 0.7419     
Epoch 790/1000
899/899 [==============================] - 0s - loss: 0.7926 - acc: 0.7519     
Epoch 791/1000
899/899 [==============================] - 0s - loss: 0.7888 - acc: 0.7408     
Epoch 792/1000
899/899 [==============================] - 0s - loss: 0.7987 - acc: 0.7375     
Epoch 793/1000
899/899 [==============================] - 0s - loss: 0.8020 - acc: 0.7386     
Epoch 794/1000
899/899 [==============================] - 0s - loss: 0.7945 - acc: 0.7397     
Epoch 795/1000
899/899 [==============================] - 0s - loss: 0.7951 - acc: 0.7430     
Epoch 796/1000
899/899 [==============================] - 0s - loss: 0.7823 - acc: 0.7464     
Epoch 797/1000
899/899 [==============================] - 0s - loss: 0.7969 - acc: 0.7475     
Epoch 798/1000
899/899 [==============================] - 0s - loss: 0.7872 - acc: 0.7642     
Epoch 799/1000
899/899 [==============================] - 0s - loss: 0.7829 - acc: 0.7453     
Epoch 800/1000
899/899 [==============================] - 0s - loss: 0.8009 - acc: 0.7508     
Epoch 801/1000
899/899 [==============================] - 0s - loss: 0.7813 - acc: 0.7564     
Epoch 802/1000
899/899 [==============================] - 0s - loss: 0.7807 - acc: 0.7497     
Epoch 803/1000
899/899 [==============================] - 0s - loss: 0.7782 - acc: 0.7597     
Epoch 804/1000
899/899 [==============================] - 0s - loss: 0.7820 - acc: 0.7497     
Epoch 805/1000
899/899 [==============================] - 0s - loss: 0.7878 - acc: 0.7475     
Epoch 806/1000
899/899 [==============================] - 0s - loss: 0.7759 - acc: 0.7653     
Epoch 807/1000
899/899 [==============================] - 0s - loss: 0.7826 - acc: 0.7486     
Epoch 808/1000
899/899 [==============================] - 0s - loss: 0.7823 - acc: 0.7586     
Epoch 809/1000
899/899 [==============================] - 0s - loss: 0.7873 - acc: 0.7453     
Epoch 810/1000
899/899 [==============================] - 0s - loss: 0.7830 - acc: 0.7453     
Epoch 811/1000
899/899 [==============================] - 0s - loss: 0.7864 - acc: 0.7508     
Epoch 812/1000
899/899 [==============================] - 0s - loss: 0.7874 - acc: 0.7419     
Epoch 813/1000
899/899 [==============================] - 0s - loss: 0.7950 - acc: 0.7375     
Epoch 814/1000
899/899 [==============================] - 0s - loss: 0.7879 - acc: 0.7430     
Epoch 815/1000
899/899 [==============================] - 0s - loss: 0.7811 - acc: 0.7453     
Epoch 816/1000
899/899 [==============================] - 0s - loss: 0.7754 - acc: 0.7542     
Epoch 817/1000
899/899 [==============================] - 0s - loss: 0.7748 - acc: 0.7586     
Epoch 818/1000
899/899 [==============================] - 0s - loss: 0.7793 - acc: 0.7542     
Epoch 819/1000
899/899 [==============================] - 0s - loss: 0.7884 - acc: 0.7375     
Epoch 820/1000
899/899 [==============================] - 0s - loss: 0.7704 - acc: 0.7753     
Epoch 821/1000
899/899 [==============================] - 0s - loss: 0.7751 - acc: 0.7531     
Epoch 822/1000
899/899 [==============================] - 0s - loss: 0.7844 - acc: 0.7531     
Epoch 823/1000
899/899 [==============================] - 0s - loss: 0.7764 - acc: 0.7542     
Epoch 824/1000
899/899 [==============================] - 0s - loss: 0.7705 - acc: 0.7497     
Epoch 825/1000
899/899 [==============================] - 0s - loss: 0.7868 - acc: 0.7386     
Epoch 826/1000
899/899 [==============================] - 0s - loss: 0.7923 - acc: 0.7330     
Epoch 827/1000
899/899 [==============================] - 0s - loss: 0.7592 - acc: 0.7597     
Epoch 828/1000
899/899 [==============================] - 0s - loss: 0.7641 - acc: 0.7508     
Epoch 829/1000
899/899 [==============================] - 0s - loss: 0.7641 - acc: 0.7675     
Epoch 830/1000
899/899 [==============================] - 0s - loss: 0.7632 - acc: 0.7453     
Epoch 831/1000
899/899 [==============================] - 0s - loss: 0.7703 - acc: 0.7542     
Epoch 832/1000
899/899 [==============================] - 0s - loss: 0.7796 - acc: 0.7442     
Epoch 833/1000
899/899 [==============================] - 0s - loss: 0.7723 - acc: 0.7575     
Epoch 834/1000
899/899 [==============================] - 0s - loss: 0.7559 - acc: 0.7586     
Epoch 835/1000
899/899 [==============================] - 0s - loss: 0.7627 - acc: 0.7731     
Epoch 836/1000
899/899 [==============================] - 0s - loss: 0.7591 - acc: 0.7686     
Epoch 837/1000
899/899 [==============================] - 0s - loss: 0.7609 - acc: 0.7442     
Epoch 838/1000
899/899 [==============================] - 0s - loss: 0.7670 - acc: 0.7364     
Epoch 839/1000
899/899 [==============================] - 0s - loss: 0.7589 - acc: 0.7486     
Epoch 840/1000
899/899 [==============================] - 0s - loss: 0.7512 - acc: 0.7664     
Epoch 841/1000
899/899 [==============================] - 0s - loss: 0.7678 - acc: 0.7486     
Epoch 842/1000
899/899 [==============================] - 0s - loss: 0.7627 - acc: 0.7653     
Epoch 843/1000
899/899 [==============================] - 0s - loss: 0.7612 - acc: 0.7575     
Epoch 844/1000
899/899 [==============================] - 0s - loss: 0.7627 - acc: 0.7553     
Epoch 845/1000
899/899 [==============================] - 0s - loss: 0.7495 - acc: 0.7597     
Epoch 846/1000
899/899 [==============================] - 0s - loss: 0.7518 - acc: 0.7620     
Epoch 847/1000
899/899 [==============================] - 0s - loss: 0.7617 - acc: 0.7497     
Epoch 848/1000
899/899 [==============================] - 0s - loss: 0.7595 - acc: 0.7653     
Epoch 849/1000
899/899 [==============================] - 0s - loss: 0.7512 - acc: 0.7620     
Epoch 850/1000
899/899 [==============================] - 0s - loss: 0.7584 - acc: 0.7653     
Epoch 851/1000
899/899 [==============================] - 0s - loss: 0.7500 - acc: 0.7631     
Epoch 852/1000
899/899 [==============================] - 0s - loss: 0.7480 - acc: 0.7709     
Epoch 853/1000
899/899 [==============================] - 0s - loss: 0.7717 - acc: 0.7475     
Epoch 854/1000
899/899 [==============================] - 0s - loss: 0.7802 - acc: 0.7475     
Epoch 855/1000
899/899 [==============================] - 0s - loss: 0.7561 - acc: 0.7564     
Epoch 856/1000
899/899 [==============================] - 0s - loss: 0.7446 - acc: 0.7620     
Epoch 857/1000
899/899 [==============================] - 0s - loss: 0.7419 - acc: 0.7764     
Epoch 858/1000
899/899 [==============================] - 0s - loss: 0.7522 - acc: 0.7564     
Epoch 859/1000
899/899 [==============================] - 0s - loss: 0.7624 - acc: 0.7497     
Epoch 860/1000
899/899 [==============================] - 0s - loss: 0.7485 - acc: 0.7631     
Epoch 861/1000
899/899 [==============================] - 0s - loss: 0.7603 - acc: 0.7430     
Epoch 862/1000
899/899 [==============================] - 0s - loss: 0.7462 - acc: 0.7575     
Epoch 863/1000
899/899 [==============================] - 0s - loss: 0.7489 - acc: 0.7608     
Epoch 864/1000
899/899 [==============================] - 0s - loss: 0.7607 - acc: 0.7408     
Epoch 865/1000
899/899 [==============================] - 0s - loss: 0.7465 - acc: 0.7620     
Epoch 866/1000
899/899 [==============================] - 0s - loss: 0.7446 - acc: 0.7675     
Epoch 867/1000
899/899 [==============================] - 0s - loss: 0.7430 - acc: 0.7508     
Epoch 868/1000
899/899 [==============================] - 0s - loss: 0.7395 - acc: 0.7742     
Epoch 869/1000
899/899 [==============================] - 0s - loss: 0.7459 - acc: 0.7675     
Epoch 870/1000
899/899 [==============================] - 0s - loss: 0.7421 - acc: 0.7586     
Epoch 871/1000
899/899 [==============================] - 0s - loss: 0.7462 - acc: 0.7620     
Epoch 872/1000
899/899 [==============================] - 0s - loss: 0.7433 - acc: 0.7564     
Epoch 873/1000
899/899 [==============================] - 0s - loss: 0.7322 - acc: 0.7642     
Epoch 874/1000
899/899 [==============================] - 0s - loss: 0.7333 - acc: 0.7686     
Epoch 875/1000
899/899 [==============================] - 0s - loss: 0.7359 - acc: 0.7731     
Epoch 876/1000
899/899 [==============================] - 0s - loss: 0.7317 - acc: 0.7742     
Epoch 877/1000
899/899 [==============================] - 0s - loss: 0.7368 - acc: 0.7742     
Epoch 878/1000
899/899 [==============================] - 0s - loss: 0.7308 - acc: 0.7831     
Epoch 879/1000
899/899 [==============================] - 0s - loss: 0.7485 - acc: 0.7475     
Epoch 880/1000
899/899 [==============================] - 0s - loss: 0.7423 - acc: 0.7608     
Epoch 881/1000
899/899 [==============================] - 0s - loss: 0.7404 - acc: 0.7642     
Epoch 882/1000
899/899 [==============================] - 0s - loss: 0.7243 - acc: 0.7775     
Epoch 883/1000
899/899 [==============================] - 0s - loss: 0.7516 - acc: 0.7586     
Epoch 884/1000
899/899 [==============================] - 0s - loss: 0.7291 - acc: 0.7675     
Epoch 885/1000
899/899 [==============================] - 0s - loss: 0.7218 - acc: 0.7764     
Epoch 886/1000
899/899 [==============================] - 0s - loss: 0.7203 - acc: 0.7720     
Epoch 887/1000
899/899 [==============================] - 0s - loss: 0.7297 - acc: 0.7709     
Epoch 888/1000
899/899 [==============================] - 0s - loss: 0.7216 - acc: 0.7820     
Epoch 889/1000
899/899 [==============================] - 0s - loss: 0.7191 - acc: 0.7720     
Epoch 890/1000
899/899 [==============================] - 0s - loss: 0.7308 - acc: 0.7631     
Epoch 891/1000
899/899 [==============================] - 0s - loss: 0.7137 - acc: 0.7798     
Epoch 892/1000
899/899 [==============================] - 0s - loss: 0.7308 - acc: 0.7653     
Epoch 893/1000
899/899 [==============================] - 0s - loss: 0.7228 - acc: 0.7697     
Epoch 894/1000
899/899 [==============================] - 0s - loss: 0.7315 - acc: 0.7697     
Epoch 895/1000
899/899 [==============================] - 0s - loss: 0.7196 - acc: 0.7798     
Epoch 896/1000
899/899 [==============================] - 0s - loss: 0.7300 - acc: 0.7709     
Epoch 897/1000
899/899 [==============================] - 0s - loss: 0.7254 - acc: 0.7786     
Epoch 898/1000
899/899 [==============================] - 0s - loss: 0.7198 - acc: 0.7798     
Epoch 899/1000
899/899 [==============================] - 0s - loss: 0.7341 - acc: 0.7586     
Epoch 900/1000
899/899 [==============================] - 0s - loss: 0.7301 - acc: 0.7664     
Epoch 901/1000
899/899 [==============================] - 0s - loss: 0.7147 - acc: 0.7742     
Epoch 902/1000
899/899 [==============================] - 0s - loss: 0.7393 - acc: 0.7508     
Epoch 903/1000
899/899 [==============================] - 0s - loss: 0.7139 - acc: 0.7809     
Epoch 904/1000
899/899 [==============================] - 0s - loss: 0.7184 - acc: 0.7742     
Epoch 905/1000
899/899 [==============================] - 0s - loss: 0.7168 - acc: 0.7709     
Epoch 906/1000
899/899 [==============================] - 0s - loss: 0.7202 - acc: 0.7786     
Epoch 907/1000
899/899 [==============================] - 0s - loss: 0.7147 - acc: 0.7764     
Epoch 908/1000
899/899 [==============================] - 0s - loss: 0.7092 - acc: 0.7809     
Epoch 909/1000
899/899 [==============================] - 0s - loss: 0.7104 - acc: 0.7764     
Epoch 910/1000
899/899 [==============================] - 0s - loss: 0.7087 - acc: 0.7798     
Epoch 911/1000
899/899 [==============================] - 0s - loss: 0.7156 - acc: 0.7720     
Epoch 912/1000
899/899 [==============================] - 0s - loss: 0.7100 - acc: 0.7909     
Epoch 913/1000
899/899 [==============================] - 0s - loss: 0.7144 - acc: 0.7809     
Epoch 914/1000
899/899 [==============================] - 0s - loss: 0.7153 - acc: 0.7664     
Epoch 915/1000
899/899 [==============================] - 0s - loss: 0.7134 - acc: 0.7831     
Epoch 916/1000
899/899 [==============================] - 0s - loss: 0.7107 - acc: 0.7831     
Epoch 917/1000
899/899 [==============================] - 0s - loss: 0.7128 - acc: 0.7664     
Epoch 918/1000
899/899 [==============================] - 0s - loss: 0.7258 - acc: 0.7720     
Epoch 919/1000
899/899 [==============================] - 0s - loss: 0.7313 - acc: 0.7608     
Epoch 920/1000
899/899 [==============================] - 0s - loss: 0.6997 - acc: 0.7842     
Epoch 921/1000
899/899 [==============================] - 0s - loss: 0.7134 - acc: 0.7720     
Epoch 922/1000
899/899 [==============================] - 0s - loss: 0.7230 - acc: 0.7553     
Epoch 923/1000
899/899 [==============================] - 0s - loss: 0.7186 - acc: 0.7620     
Epoch 924/1000
899/899 [==============================] - 0s - loss: 0.7012 - acc: 0.7875     
Epoch 925/1000
899/899 [==============================] - 0s - loss: 0.7009 - acc: 0.7786     
Epoch 926/1000
899/899 [==============================] - 0s - loss: 0.7134 - acc: 0.7697     
Epoch 927/1000
899/899 [==============================] - 0s - loss: 0.7010 - acc: 0.7920     
Epoch 928/1000
899/899 [==============================] - 0s - loss: 0.7073 - acc: 0.7942     
Epoch 929/1000
899/899 [==============================] - 0s - loss: 0.7081 - acc: 0.7753     
Epoch 930/1000
899/899 [==============================] - 0s - loss: 0.6990 - acc: 0.7887     
Epoch 931/1000
899/899 [==============================] - 0s - loss: 0.7012 - acc: 0.7842     
Epoch 932/1000
899/899 [==============================] - 0s - loss: 0.7090 - acc: 0.7697     
Epoch 933/1000
899/899 [==============================] - 0s - loss: 0.7002 - acc: 0.7820     
Epoch 934/1000
899/899 [==============================] - 0s - loss: 0.7090 - acc: 0.7709     
Epoch 935/1000
899/899 [==============================] - 0s - loss: 0.6906 - acc: 0.7953     
Epoch 936/1000
899/899 [==============================] - 0s - loss: 0.6892 - acc: 0.7942     
Epoch 937/1000
899/899 [==============================] - 0s - loss: 0.7072 - acc: 0.7731     
Epoch 938/1000
899/899 [==============================] - 0s - loss: 0.7094 - acc: 0.7686     
Epoch 939/1000
899/899 [==============================] - 0s - loss: 0.6916 - acc: 0.7875     
Epoch 940/1000
899/899 [==============================] - 0s - loss: 0.6980 - acc: 0.7764     
Epoch 941/1000
899/899 [==============================] - 0s - loss: 0.7128 - acc: 0.7664     
Epoch 942/1000
899/899 [==============================] - 0s - loss: 0.6899 - acc: 0.7942     
Epoch 943/1000
899/899 [==============================] - 0s - loss: 0.6902 - acc: 0.7764     
Epoch 944/1000
899/899 [==============================] - 0s - loss: 0.7005 - acc: 0.7820     
Epoch 945/1000
899/899 [==============================] - 0s - loss: 0.7041 - acc: 0.7753     
Epoch 946/1000
899/899 [==============================] - 0s - loss: 0.6979 - acc: 0.7764     
Epoch 947/1000
899/899 [==============================] - 0s - loss: 0.6894 - acc: 0.7920     
Epoch 948/1000
899/899 [==============================] - 0s - loss: 0.6852 - acc: 0.7864     
Epoch 949/1000
899/899 [==============================] - 0s - loss: 0.6849 - acc: 0.7875     
Epoch 950/1000
899/899 [==============================] - 0s - loss: 0.6899 - acc: 0.7864     
Epoch 951/1000
899/899 [==============================] - 0s - loss: 0.6995 - acc: 0.7831     
Epoch 952/1000
899/899 [==============================] - 0s - loss: 0.6825 - acc: 0.7898     
Epoch 953/1000
899/899 [==============================] - 0s - loss: 0.6875 - acc: 0.7753     
Epoch 954/1000
899/899 [==============================] - 0s - loss: 0.7083 - acc: 0.7709     
Epoch 955/1000
899/899 [==============================] - 0s - loss: 0.7018 - acc: 0.7686     
Epoch 956/1000
899/899 [==============================] - 0s - loss: 0.6905 - acc: 0.7786     
Epoch 957/1000
899/899 [==============================] - 0s - loss: 0.7004 - acc: 0.7853     
Epoch 958/1000
899/899 [==============================] - 0s - loss: 0.6948 - acc: 0.7775     
Epoch 959/1000
899/899 [==============================] - 0s - loss: 0.6849 - acc: 0.7920     
Epoch 960/1000
899/899 [==============================] - 0s - loss: 0.6799 - acc: 0.7998     
Epoch 961/1000
899/899 [==============================] - 0s - loss: 0.6909 - acc: 0.7786     
Epoch 962/1000
899/899 [==============================] - 0s - loss: 0.6860 - acc: 0.7898     
Epoch 963/1000
899/899 [==============================] - 0s - loss: 0.6890 - acc: 0.7831     
Epoch 964/1000
899/899 [==============================] - 0s - loss: 0.6780 - acc: 0.7964     
Epoch 965/1000
899/899 [==============================] - 0s - loss: 0.6845 - acc: 0.7875     
Epoch 966/1000
899/899 [==============================] - 0s - loss: 0.6791 - acc: 0.7909     
Epoch 967/1000
899/899 [==============================] - 0s - loss: 0.6830 - acc: 0.7775     
Epoch 968/1000
899/899 [==============================] - 0s - loss: 0.6785 - acc: 0.7898     
Epoch 969/1000
899/899 [==============================] - 0s - loss: 0.6847 - acc: 0.7842     
Epoch 970/1000
899/899 [==============================] - 0s - loss: 0.7068 - acc: 0.7709     
Epoch 971/1000
899/899 [==============================] - 0s - loss: 0.6768 - acc: 0.7820     
Epoch 972/1000
899/899 [==============================] - 0s - loss: 0.6787 - acc: 0.7920     
Epoch 973/1000
899/899 [==============================] - 0s - loss: 0.6767 - acc: 0.7875     
Epoch 974/1000
899/899 [==============================] - 0s - loss: 0.6870 - acc: 0.7887     
Epoch 975/1000
899/899 [==============================] - 0s - loss: 0.6855 - acc: 0.7842     
Epoch 976/1000
899/899 [==============================] - 0s - loss: 0.6704 - acc: 0.7998     
Epoch 977/1000
899/899 [==============================] - 0s - loss: 0.6663 - acc: 0.7920     
Epoch 978/1000
899/899 [==============================] - 0s - loss: 0.6687 - acc: 0.7887     
Epoch 979/1000
899/899 [==============================] - 0s - loss: 0.6685 - acc: 0.7909     
Epoch 980/1000
899/899 [==============================] - 0s - loss: 0.6701 - acc: 0.7731     
Epoch 981/1000
899/899 [==============================] - 0s - loss: 0.6676 - acc: 0.7898     
Epoch 982/1000
899/899 [==============================] - 0s - loss: 0.6618 - acc: 0.7920     
Epoch 983/1000
899/899 [==============================] - 0s - loss: 0.6645 - acc: 0.7964     
Epoch 984/1000
899/899 [==============================] - 0s - loss: 0.6616 - acc: 0.7964     
Epoch 985/1000
899/899 [==============================] - 0s - loss: 0.6788 - acc: 0.7864     
Epoch 986/1000
899/899 [==============================] - 0s - loss: 0.6560 - acc: 0.7953     
Epoch 987/1000
899/899 [==============================] - 0s - loss: 0.6622 - acc: 0.8020     
Epoch 988/1000
899/899 [==============================] - 0s - loss: 0.6761 - acc: 0.7976     
Epoch 989/1000
899/899 [==============================] - 0s - loss: 0.6796 - acc: 0.7898     
Epoch 990/1000
899/899 [==============================] - 0s - loss: 0.6629 - acc: 0.8053     
Epoch 991/1000
899/899 [==============================] - 0s - loss: 0.6677 - acc: 0.7809     
Epoch 992/1000
899/899 [==============================] - 0s - loss: 0.6655 - acc: 0.8009     
Epoch 993/1000
899/899 [==============================] - 0s - loss: 0.6648 - acc: 0.7909     
Epoch 994/1000
899/899 [==============================] - 0s - loss: 0.6692 - acc: 0.7875     
Epoch 995/1000
899/899 [==============================] - 0s - loss: 0.6726 - acc: 0.7831     
Epoch 996/1000
899/899 [==============================] - 0s - loss: 0.6626 - acc: 0.7931     
Epoch 997/1000
899/899 [==============================] - 0s - loss: 0.6639 - acc: 0.7909     
Epoch 998/1000
899/899 [==============================] - 0s - loss: 0.6713 - acc: 0.8053     
Epoch 999/1000
899/899 [==============================] - 0s - loss: 0.6606 - acc: 0.7964     
Epoch 1000/1000
899/899 [==============================] - 0s - loss: 0.6550 - acc: 0.8020     
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-Data&#47484;-&#53664;&#45824;&#47196;-&#44396;&#54620;-Prediction-&#50696;&#52769;-&#44050;&#51060;&#45796;.">Train Data&#47484; &#53664;&#45824;&#47196; &#44396;&#54620; Prediction &#50696;&#52769; &#44050;&#51060;&#45796;.<a class="anchor-link" href="#Train-Data&#47484;-&#53664;&#45824;&#47196;-&#44396;&#54620;-Prediction-&#50696;&#52769;-&#44050;&#51060;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[358]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> 32/899 [&gt;.............................] - ETA: 0s</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[358]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([ 5,  7, 10,  3,  6,  5,  5,  6,  5,  9,  3,  3,  5,  1,  7,  4,  3,
        4,  9,  5,  5,  3,  8,  6,  3,  7,  9,  5,  3,  4,  4,  5,  5,  5,
       10,  5,  0,  2,  5,  5,  6,  0,  2,  7,  2,  2,  5,  4,  6,  2,  4,
        6,  5,  5,  9,  1,  8,  7,  4,  3,  3,  4,  5,  8,  5,  5,  5,  6,
        3,  3,  7,  5,  7,  3,  5,  0,  5,  5,  6,  2,  8,  5,  3,  6,  3,
        5,  4,  0,  5,  5,  6,  8,  5,  3,  6,  5,  6,  0,  4,  7,  6,  6,
        5,  6,  4,  5,  3,  5,  9,  1,  6,  4,  4,  3,  7,  7, 10,  5,  5,
        7,  6,  7,  0,  4,  3, 10,  3,  1,  7,  4,  6,  6,  6,  4,  5,  5,
        5,  5,  7,  1,  5,  3,  4,  6,  5,  4,  5,  3,  7,  6,  5,  5,  5,
        7,  4,  8, 10, 10,  3,  7,  5,  6, 10,  5,  3,  8,  8,  3,  5,  6,
        5,  8,  7,  7,  6,  4,  5,  5,  0,  5,  5,  6,  5,  6,  5,  2,  0,
        2,  6,  3,  5,  2,  6,  5,  3,  2,  6,  5,  5, 10,  5,  1,  7,  5,
        6,  8,  5,  7,  3,  3,  3,  7,  4,  5,  6,  0,  1,  6,  4,  5,  5,
        6,  6,  5,  3,  6,  5,  4,  5,  5,  5,  7,  6,  6,  8,  4,  5,  1,
        7,  5,  5,  7,  3,  5,  4,  4,  6, 10,  5,  6,  5,  7,  5,  7,  5,
        4,  5,  5,  5,  5,  5,  4,  6,  6,  6,  7,  8,  7,  5,  6,  7,  0,
        5,  8,  6,  1, 10,  4,  7,  7,  7,  3,  4,  5,  7,  8,  5,  3,  7,
        6,  3,  6,  7,  3,  5,  5,  5,  8,  2,  8,  0,  6,  5,  3,  6, 10,
        5,  5,  7,  3,  6,  6,  5,  3,  7,  4,  8,  5,  5,  5,  5,  3,  5,
        5,  3,  6,  8,  6,  6,  7,  2,  5,  7,  9,  8,  3,  5,  5,  6,  5,
        7,  9,  7,  7,  3, 10,  7,  4,  4,  5,  5,  7,  3,  4,  6,  4,  5,
        1,  5,  8,  3,  3,  2,  5,  8,  5,  5,  5,  3,  5,  7,  9,  6,  5,
        6,  5,  4,  7,  2,  3,  4,  6, 10,  4,  3,  9,  7,  3,  5, 10,  7,
        5, 10,  7,  5,  5,  5,  5,  3,  6,  5,  5,  5,  5,  4,  0,  2, 10,
        6,  6,  7,  1,  7,  5,  7,  1,  5,  0,  1,  4,  5,  3,  8,  7,  5,
        5,  9,  2,  5,  7,  2,  3,  4,  8,  5,  1,  6,  5,  5,  4,  9,  2,
        3,  8,  7, 10,  5,  5,  5,  4,  7,  7,  5,  5,  5,  6,  3,  3,  7,
        7,  5,  3,  8,  6,  2,  5,  6,  3,  4,  7,  6,  8,  5,  5,  8,  3,
        3,  5,  5,  5,  5,  8,  5,  5,  5, 10,  8,  5,  5,  8,  6,  6,  6,
        6,  5,  5,  5,  5,  5,  8,  7,  5,  0,  5,  5,  5, 10,  5,  5,  4,
        7,  5,  3,  8,  7,  8,  6,  5,  4,  7,  7,  5,  5,  0,  5,  5,  3,
        5,  4,  7,  3,  8,  4,  3,  5,  5,  3,  4,  9,  5,  0,  5,  5,  5,
       10,  2,  5,  5,  8, 10,  5,  6,  3,  5,  5,  5, 10,  8,  7,  5,  8,
        5,  2, 10,  5,  0,  5, 10,  7, 10,  4,  9,  6,  8,  3,  3, 10, 10,
        5,  7,  6,  3,  4,  6,  5,  2,  5,  6,  8, 10,  5,  4,  5,  2,  5,
        5,  3,  5,  8,  6,  3,  1,  7,  5,  3,  8,  4,  5,  7,  3,  3,  5,
        2,  5,  3,  7,  5,  5,  5,  2,  3,  6,  5,  4,  7,  5,  5,  5,  6,
        5,  6,  5,  5,  5,  4,  8,  6,  5, 10,  8,  5,  5,  6,  4,  5,  9,
        5,  3,  2,  2,  5,  5,  2,  8,  0,  4,  3,  3,  5,  3,  5,  9,  5,
        3,  9,  4,  4,  8,  5, 10,  3,  7,  6,  2,  6,  0,  1,  5,  1,  6,
        1,  7,  7,  3,  5,  3,  7,  5,  2,  7,  5,  0,  4,  6,  5,  6,  8,
        3,  5,  5,  5,  7,  5,  4,  5,  7,  1,  8,  3,  4,  5,  8,  8,  0,
        5,  9,  4,  3,  7,  3,  3,  4,  1,  5,  2,  0,  5,  5,  5,  6,  6,
        5,  3, 10,  5,  6,  7,  5,  6,  6,  7,  5,  3,  8,  4,  7,  4,  8,
        5, 10,  4,  8,  3,  1,  5,  5,  5,  7,  5, 10,  5,  5,  9,  5,  3,
        7,  3,  2,  4,  5,  5, 10,  3,  5,  7,  5,  4,  6,  4,  7,  3,  6,
        5,  5,  3,  5,  5,  6,  5,  3,  6,  9,  7,  0,  7,  4,  3,  5,  5,
        5,  8,  5,  4,  8,  4,  8,  8,  5,  5,  7,  2,  3,  7,  8,  8,  7,
        7,  5,  5,  4,  5,  7,  3,  5,  3,  4,  2, 10,  3, 10,  5,  4,  1,
       10,  8,  5,  2,  5,  5,  6,  5,  7,  2,  5,  7,  5,  7,  0,  2,  4,
        6,  7,  5,  8,  7,  4,  5,  0,  4,  6, 10,  2,  5,  8,  3,  3,  5,
        3,  7,  7,  5,  3, 10,  8, 10,  5,  6,  5,  1,  3,  5,  5,  5,  7,
        5,  9,  9,  3,  7,  6,  7,  4, 10,  7,  7,  3,  2,  6,  5], dtype=int64)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[361]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> 32/899 [&gt;.............................] - ETA: 0s</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[361]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[  1.02007186e-06,   1.77738280e-03,   1.46753073e-03, ...,
          2.99268775e-03,   1.65467995e-09,   5.11392672e-03],
       [  4.52406748e-05,   1.39105810e-10,   9.22930710e-09, ...,
          2.89429468e-03,   3.42403859e-04,   1.97233952e-04],
       [  8.11468344e-04,   3.59599881e-07,   5.29041653e-03, ...,
          2.22583640e-06,   1.34378002e-04,   6.09360099e-01],
       ..., 
       [  7.29348892e-09,   3.60597647e-03,   8.33716869e-01, ...,
          1.46212697e-03,   7.49616248e-19,   1.30419963e-07],
       [  1.22919760e-03,   3.06906038e-08,   3.35362131e-07, ...,
          2.18422394e-02,   2.39874911e-03,   1.79638300e-05],
       [  1.64378226e-01,   2.66652738e-17,   1.02656266e-13, ...,
          2.37487452e-08,   7.84304664e-02,   2.83786212e-04]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test-set&#51032;-&#50696;&#52769;&#44050;&#51060;&#45796;.">Test set&#51032; &#50696;&#52769;&#44050;&#51060;&#45796;.<a class="anchor-link" href="#Test-set&#51032;-&#50696;&#52769;&#44050;&#51060;&#45796;.">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[360]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> 32/155 [=====&gt;........................] - ETA: 0s</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[355]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[355]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([10,  5,  1,  8,  5,  7,  7,  5,  5,  6,  5,  6,  6,  9,  5,  6, 10,
        6,  7,  6,  1,  7,  7,  7,  7,  1,  3,  5,  5,  6,  5, 10,  4,  5,
        5,  7,  6,  5,  3,  3,  5,  6,  5,  5,  5,  3,  7,  7,  6, 10,  8,
       10,  7,  3,  7,  5,  5,  4,  8,  5,  8,  5,  5,  6,  3,  5,  6,  2,
        5,  5,  5, 10,  5,  5,  5,  5,  5,  5,  4,  3,  5,  3,  4,  5,  6,
        5,  5,  2,  3,  6,  5,  6,  5,  5,  5,  4,  5,  5,  5,  6,  0,  7,
        7,  7,  0,  3,  5,  5,  3,  7,  5,  3,  3,  4,  0,  5,  5,  5,  4,
        5,  4,  0,  5,  4,  4,  5,  6,  5,  5,  7,  4,  5,  4,  6,  6,  6,
        3,  5,  5,  7,  3,  9,  5,  3,  5,  5,  5,  5,  6,  5,  5,  5,  0,
        0,  4], dtype=int64)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="3.-Conclusion">3. Conclusion<a class="anchor-link" href="#3.-Conclusion">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="--Data-&#51204;&#52376;&#47532;-&#44284;&#51221;">- Data &#51204;&#52376;&#47532; &#44284;&#51221;<a class="anchor-link" href="#--Data-&#51204;&#52376;&#47532;-&#44284;&#51221;">&#182;</a></h2><h3 id="Data-set&#51032;-&#47784;&#46304;-&#48320;&#49688;&#44032;-categorical-number&#51060;&#44592;-&#46412;&#47928;&#50640;-One-Hot-Encoding&#51012;-&#53685;&#54644;-numerical-&#51032;&#48120;&#47484;-&#44057;&#45716;-dummy-&#48320;&#49688;&#47196;-&#48148;&#45012;&#51452;&#50612;&#50556;-&#54664;&#45796;.">Data set&#51032; &#47784;&#46304; &#48320;&#49688;&#44032; categorical number&#51060;&#44592; &#46412;&#47928;&#50640; One Hot Encoding&#51012; &#53685;&#54644; numerical &#51032;&#48120;&#47484; &#44057;&#45716; dummy &#48320;&#49688;&#47196; &#48148;&#45012;&#51452;&#50612;&#50556; &#54664;&#45796;.<a class="anchor-link" href="#Data-set&#51032;-&#47784;&#46304;-&#48320;&#49688;&#44032;-categorical-number&#51060;&#44592;-&#46412;&#47928;&#50640;-One-Hot-Encoding&#51012;-&#53685;&#54644;-numerical-&#51032;&#48120;&#47484;-&#44057;&#45716;-dummy-&#48320;&#49688;&#47196;-&#48148;&#45012;&#51452;&#50612;&#50556;-&#54664;&#45796;.">&#182;</a></h3><h3 id="K2-~-K14&#44620;&#51648;&#51032;-&#51656;&#47928;&#46308;&#50640;-Missing-Value&#46308;&#51008;-MICE-&#47784;&#45944;&#51012;-&#53685;&#54644;-Imputation-&#54644;&#51452;&#50632;&#45796;.-SoftImpute&#44284;-KNN-&#48169;&#48277;&#51012;-&#50024;-&#46041;&#51068;&#54620;-&#47784;&#45944;&#51012;-&#46028;&#47140;&#48372;&#50520;&#51004;&#45208;-&#49457;&#45733;-&#52264;&#51060;&#44032;-&#53356;&#44172;-&#45208;&#51648;-&#50506;&#50500;-MICE-Imputation&#51012;-&#50044;&#45796;.">K2 ~ K14&#44620;&#51648;&#51032; &#51656;&#47928;&#46308;&#50640; Missing Value&#46308;&#51008; MICE &#47784;&#45944;&#51012; &#53685;&#54644; Imputation &#54644;&#51452;&#50632;&#45796;. SoftImpute&#44284; KNN &#48169;&#48277;&#51012; &#50024; &#46041;&#51068;&#54620; &#47784;&#45944;&#51012; &#46028;&#47140;&#48372;&#50520;&#51004;&#45208; &#49457;&#45733; &#52264;&#51060;&#44032; &#53356;&#44172; &#45208;&#51648; &#50506;&#50500; MICE Imputation&#51012; &#50044;&#45796;.<a class="anchor-link" href="#K2-~-K14&#44620;&#51648;&#51032;-&#51656;&#47928;&#46308;&#50640;-Missing-Value&#46308;&#51008;-MICE-&#47784;&#45944;&#51012;-&#53685;&#54644;-Imputation-&#54644;&#51452;&#50632;&#45796;.-SoftImpute&#44284;-KNN-&#48169;&#48277;&#51012;-&#50024;-&#46041;&#51068;&#54620;-&#47784;&#45944;&#51012;-&#46028;&#47140;&#48372;&#50520;&#51004;&#45208;-&#49457;&#45733;-&#52264;&#51060;&#44032;-&#53356;&#44172;-&#45208;&#51648;-&#50506;&#50500;-MICE-Imputation&#51012;-&#50044;&#45796;.">&#182;</a></h3><h3 id="Ideo_self-column&#51032;-Missing-Value-&#50976;&#47924;&#50640;-&#46384;&#46972;-Train-set&#44284;-Test-set&#51004;&#47196;-&#45208;&#45600;&#51452;&#50632;&#45796;.">Ideo_self column&#51032; Missing Value &#50976;&#47924;&#50640; &#46384;&#46972; Train set&#44284; Test set&#51004;&#47196; &#45208;&#45600;&#51452;&#50632;&#45796;.<a class="anchor-link" href="#Ideo_self-column&#51032;-Missing-Value-&#50976;&#47924;&#50640;-&#46384;&#46972;-Train-set&#44284;-Test-set&#51004;&#47196;-&#45208;&#45600;&#51452;&#50632;&#45796;.">&#182;</a></h3><h2 id="--Data-Modeling-&#44284;&#51221;">- Data Modeling &#44284;&#51221;<a class="anchor-link" href="#--Data-Modeling-&#44284;&#51221;">&#182;</a></h2><h3 id="Train-set&#51012;-&#53664;&#45824;&#47196;-&#50948;&#51032;-9&#44060;&#51032;-&#47784;&#45944;&#46308;&#51032;-&#49457;&#45733;&#51012;-&#54217;&#44032;&#54644;-&#52572;&#51201;-&#47784;&#45944;&#51032;-&#51221;&#54869;&#46020;&#50752;-AUC-&#44050;&#51008;-&#45796;&#51020;&#44284;-&#44057;&#45796;.">Train set&#51012; &#53664;&#45824;&#47196; &#50948;&#51032; 9&#44060;&#51032; &#47784;&#45944;&#46308;&#51032; &#49457;&#45733;&#51012; &#54217;&#44032;&#54644; &#52572;&#51201; &#47784;&#45944;&#51032; &#51221;&#54869;&#46020;&#50752; AUC &#44050;&#51008; &#45796;&#51020;&#44284; &#44057;&#45796;.<a class="anchor-link" href="#Train-set&#51012;-&#53664;&#45824;&#47196;-&#50948;&#51032;-9&#44060;&#51032;-&#47784;&#45944;&#46308;&#51032;-&#49457;&#45733;&#51012;-&#54217;&#44032;&#54644;-&#52572;&#51201;-&#47784;&#45944;&#51032;-&#51221;&#54869;&#46020;&#50752;-AUC-&#44050;&#51008;-&#45796;&#51020;&#44284;-&#44057;&#45796;.">&#182;</a></h3><h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Logistic-Classifier&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; Logistic Classifier&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Logistic-Classifier&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE: 2.607
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- 가장 큰 결정 함수의 인덱스: [ 0  1 10  8  0  6  9  1  2  3]
- 인덱스를 classses_에 연결: [  0.   1.  10.   8.   0.   6.   9.   1.   2.   3.]
- Validation set의 예측(상위 10개): [  5.   5.   5.   3.  10.  10.   4.   5.  10.   5.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.14
- Test set의 예측(상위 10개): [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-KNN&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; KNN&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-KNN&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE:1.445
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [  5.   5.   5.   3.  10.  10.   4.   5.  10.   5.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.30
- Test set의 예측(상위 10개): [ 8.  8.  5.  8.  5.  8.  6.  5.  5.  9.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Naive-Bayes-classifier&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; Naive Bayes classifier&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Naive-Bayes-classifier&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE: 3.633
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [  4.   1.  10.   7.  10.   9.   0.   1.  10.   1.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.04
- Test set의 예측(상위 10개): [  9.  10.   1.   1.   9.   9.   9.   1.   1.   9.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Decision-Tree&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; Decision Tree&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Decision-Tree&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE: 1.611
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [  4.   5.   5.   5.   5.   8.   5.   3.  10.   5.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.29
- Test set의 예측(상위 10개): [  8.  10.   3.   8.   5.   8.   8.   3.   5.   8.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Random-Forest&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; Random Forest&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Random-Forest&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE: 1.478
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [ 5.  5.  5.  5.  5.  8.  5.  5.  5.  5.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.35
- Test set의 예측(상위 10개): [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-SVM&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; SVM&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-SVM&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE: 1.415
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- 가장 큰 결정 함수의 인덱스: [31 40 38 43 50 52 43 43 41 43]
- Validation set의 예측(상위 10개): [ 5.  5.  5.  5.  5.  8.  5.  5.  5.  5.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.34
- Test set의 예측(상위 10개): [  8.  10.   1.   8.   7.  10.   8.   0.   1.   9.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Xgboost&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; Xgboost&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Xgboost&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- MAE: 1.548
- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.33
- Test set의 예측(상위 10개): [ 4.  5.  5.  5.  5.  5.  5.  5.  5.  5.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-SoftMax&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; SoftMax&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-SoftMax&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [ 5.  7.  5.  6.  5.  3.  5.  5.  5.  9.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.37
- Test set의 예측(상위 10개): [ 3.  3.  4.  4.  4.  4.  3.  4.  4.  3.]

</code></pre>
<h3 id="Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Keras-+-Relu-+-SoftMax&#51032;-&#44208;&#44284;&#44050;"><strong><em><code>Parameter &#51312;&#51221;&#51004;&#47196; &#52286;&#51008; &#52572;&#51201; Keras + Relu + SoftMax&#51032; &#44208;&#44284;&#44050;</code></em></strong><a class="anchor-link" href="#Parameter-&#51312;&#51221;&#51004;&#47196;-&#52286;&#51008;-&#52572;&#51201;-Keras-+-Relu-+-SoftMax&#51032;-&#44208;&#44284;&#44050;">&#182;</a></h3>
<pre><code>- 훈련 데이터에 있는 클래스 종류: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
- Validation set의 예측(상위 10개): [ 5.  7. 10.  3.  6.  5.  5.  6.  5.  9.]
- 실제 Validation set(상위 10개): [  0.   7.   7.   5.  10.  10.   5.   5.   7.   5.]
- Validation Set의 정확도: 0.32
- Test set의 예측(상위 10개): [ 10.  5.  1.  8.  5.  7.  7.  5.  5.  6.] 


</code></pre>
<h2 id="--Data-Interpretation">- Data Interpretation<a class="anchor-link" href="#--Data-Interpretation">&#182;</a></h2><h3 id="9&#44060;&#51032;-&#47784;&#45944;&#51012;-&#46028;&#47140;&#48376;-&#44208;&#44284;-&#51648;&#46020;-&#54617;&#49845;-&#47784;&#45944;&#50640;&#49436;&#45716;-Random-Forest,-SVM,-Xgboost&#44032;-&#44032;&#51109;-&#51339;&#51008;-Validation-set-&#51221;&#54869;&#46020;&#47484;-&#48372;&#50668;&#51500;&#45796;.-&#48708;&#51648;&#46020;-&#54617;&#49845;-&#47784;&#45944;&#50640;&#49436;&#45716;-SoftMax-&#47784;&#45944;&#51060;-37%&#51032;-Validation-set-&#51221;&#54869;&#46020;&#47484;-&#48372;&#50668;&#51468;&#51004;&#47196;&#50024;-9&#44060;&#51032;-&#47784;&#45944;-&#51473;-&#44032;&#51109;-&#51339;&#51008;-&#44208;&#44284;&#47932;&#51012;-&#48372;&#50668;&#51500;&#45796;.">9&#44060;&#51032; &#47784;&#45944;&#51012; &#46028;&#47140;&#48376; &#44208;&#44284; &#51648;&#46020; &#54617;&#49845; &#47784;&#45944;&#50640;&#49436;&#45716; Random Forest, SVM, Xgboost&#44032; &#44032;&#51109; &#51339;&#51008; Validation set &#51221;&#54869;&#46020;&#47484; &#48372;&#50668;&#51500;&#45796;. &#48708;&#51648;&#46020; &#54617;&#49845; &#47784;&#45944;&#50640;&#49436;&#45716; SoftMax &#47784;&#45944;&#51060; 37%&#51032; Validation set &#51221;&#54869;&#46020;&#47484; &#48372;&#50668;&#51468;&#51004;&#47196;&#50024; 9&#44060;&#51032; &#47784;&#45944; &#51473; &#44032;&#51109; &#51339;&#51008; &#44208;&#44284;&#47932;&#51012; &#48372;&#50668;&#51500;&#45796;.<a class="anchor-link" href="#9&#44060;&#51032;-&#47784;&#45944;&#51012;-&#46028;&#47140;&#48376;-&#44208;&#44284;-&#51648;&#46020;-&#54617;&#49845;-&#47784;&#45944;&#50640;&#49436;&#45716;-Random-Forest,-SVM,-Xgboost&#44032;-&#44032;&#51109;-&#51339;&#51008;-Validation-set-&#51221;&#54869;&#46020;&#47484;-&#48372;&#50668;&#51500;&#45796;.-&#48708;&#51648;&#46020;-&#54617;&#49845;-&#47784;&#45944;&#50640;&#49436;&#45716;-SoftMax-&#47784;&#45944;&#51060;-37%&#51032;-Validation-set-&#51221;&#54869;&#46020;&#47484;-&#48372;&#50668;&#51468;&#51004;&#47196;&#50024;-9&#44060;&#51032;-&#47784;&#45944;-&#51473;-&#44032;&#51109;-&#51339;&#51008;-&#44208;&#44284;&#47932;&#51012;-&#48372;&#50668;&#51500;&#45796;.">&#182;</a></h3><h3 id="SoftMax-&#47784;&#45944;&#51012;-&#50420;-&#51060;&#50976;&#45716;-&#51068;&#45800;-&#47784;&#46304;-&#48320;&#49688;&#46308;&#51060;-Categorical-value&#51060;&#44592;&#50640;-One-Hot-Encoding&#51012;-&#54644;-numerical-type&#51004;&#47196;-&#48148;&#45012;&#51460;-&#54596;&#50836;&#44032;-&#51080;&#50632;&#45796;.-Softmax-&#47784;&#45944;&#51032;-&#51077;&#47141;&#48155;&#51008;-&#44050;&#51008;--0~1&#49324;&#51060;&#51032;-&#44050;&#51004;&#47196;-&#47784;&#46160;-&#51221;&#44508;&#54868;&#46104;&#47728;-&#52636;&#47141;-&#44050;&#46308;&#51032;-&#52509;&#54633;&#51008;-&#54637;&#49345;-1&#51060;-&#46104;&#45716;-&#53945;&#49457;&#51012;-&#44032;&#51652;&#45796;.-&#52636;&#47141;&#51008;-&#48516;&#47448;&#54616;&#44256;-&#49910;&#51008;-&#53364;&#47000;&#49688;&#51032;-&#49688;-&#47564;&#53372;-&#44396;&#49457;&#46104;&#47728;-&#44032;&#51109;-&#53360;-&#52636;&#47141;-&#44050;&#51012;-&#48512;&#50668;&#48155;&#51008;-&#53364;&#47000;&#49828;&#44032;-&#54869;&#47456;&#51060;-&#44032;&#51109;-&#45458;&#51008;-&#44163;&#51004;&#47196;-&#51060;&#50857;&#54664;&#45796;.-&#44536;&#47084;&#45208;-&#49457;&#45733;&#51060;-&#49373;&#44033;&#48372;&#45796;-&#45458;&#44172;-&#45208;&#50724;&#51648;-&#50506;&#50520;&#44592;-&#46412;&#47928;&#50640;-&#48372;&#50756;&#51032;-&#54596;&#50836;&#49457;&#51012;-&#45712;&#44808;&#45796;.">SoftMax &#47784;&#45944;&#51012; &#50420; &#51060;&#50976;&#45716; &#51068;&#45800; &#47784;&#46304; &#48320;&#49688;&#46308;&#51060; Categorical value&#51060;&#44592;&#50640; One Hot Encoding&#51012; &#54644; numerical type&#51004;&#47196; &#48148;&#45012;&#51460; &#54596;&#50836;&#44032; &#51080;&#50632;&#45796;. Softmax &#47784;&#45944;&#51032; &#51077;&#47141;&#48155;&#51008; &#44050;&#51008;  0~1&#49324;&#51060;&#51032; &#44050;&#51004;&#47196; &#47784;&#46160; &#51221;&#44508;&#54868;&#46104;&#47728; &#52636;&#47141; &#44050;&#46308;&#51032; &#52509;&#54633;&#51008; &#54637;&#49345; 1&#51060; &#46104;&#45716; &#53945;&#49457;&#51012; &#44032;&#51652;&#45796;. &#52636;&#47141;&#51008; &#48516;&#47448;&#54616;&#44256; &#49910;&#51008; &#53364;&#47000;&#49688;&#51032; &#49688; &#47564;&#53372; &#44396;&#49457;&#46104;&#47728; &#44032;&#51109; &#53360; &#52636;&#47141; &#44050;&#51012; &#48512;&#50668;&#48155;&#51008; &#53364;&#47000;&#49828;&#44032; &#54869;&#47456;&#51060; &#44032;&#51109; &#45458;&#51008; &#44163;&#51004;&#47196; &#51060;&#50857;&#54664;&#45796;. &#44536;&#47084;&#45208; &#49457;&#45733;&#51060; &#49373;&#44033;&#48372;&#45796; &#45458;&#44172; &#45208;&#50724;&#51648; &#50506;&#50520;&#44592; &#46412;&#47928;&#50640; &#48372;&#50756;&#51032; &#54596;&#50836;&#49457;&#51012; &#45712;&#44808;&#45796;.<a class="anchor-link" href="#SoftMax-&#47784;&#45944;&#51012;-&#50420;-&#51060;&#50976;&#45716;-&#51068;&#45800;-&#47784;&#46304;-&#48320;&#49688;&#46308;&#51060;-Categorical-value&#51060;&#44592;&#50640;-One-Hot-Encoding&#51012;-&#54644;-numerical-type&#51004;&#47196;-&#48148;&#45012;&#51460;-&#54596;&#50836;&#44032;-&#51080;&#50632;&#45796;.-Softmax-&#47784;&#45944;&#51032;-&#51077;&#47141;&#48155;&#51008;-&#44050;&#51008;--0~1&#49324;&#51060;&#51032;-&#44050;&#51004;&#47196;-&#47784;&#46160;-&#51221;&#44508;&#54868;&#46104;&#47728;-&#52636;&#47141;-&#44050;&#46308;&#51032;-&#52509;&#54633;&#51008;-&#54637;&#49345;-1&#51060;-&#46104;&#45716;-&#53945;&#49457;&#51012;-&#44032;&#51652;&#45796;.-&#52636;&#47141;&#51008;-&#48516;&#47448;&#54616;&#44256;-&#49910;&#51008;-&#53364;&#47000;&#49688;&#51032;-&#49688;-&#47564;&#53372;-&#44396;&#49457;&#46104;&#47728;-&#44032;&#51109;-&#53360;-&#52636;&#47141;-&#44050;&#51012;-&#48512;&#50668;&#48155;&#51008;-&#53364;&#47000;&#49828;&#44032;-&#54869;&#47456;&#51060;-&#44032;&#51109;-&#45458;&#51008;-&#44163;&#51004;&#47196;-&#51060;&#50857;&#54664;&#45796;.-&#44536;&#47084;&#45208;-&#49457;&#45733;&#51060;-&#49373;&#44033;&#48372;&#45796;-&#45458;&#44172;-&#45208;&#50724;&#51648;-&#50506;&#50520;&#44592;-&#46412;&#47928;&#50640;-&#48372;&#50756;&#51032;-&#54596;&#50836;&#49457;&#51012;-&#45712;&#44808;&#45796;.">&#182;</a></h3><h3 id="SoftMax-&#47784;&#45944;&#51012;-&#48372;&#50756;&#54616;&#44592;-&#50948;&#54644;-Keras&#47484;-&#53685;&#54644;-&#44256;&#49549;-&#44228;&#49328;&#51012;-&#54616;&#44256;-Relu-Activation-Function&#51012;-&#49324;&#50857;&#54644;-hidden-layer-&#44050;&#51012;-&#44396;&#54644;-SoftMax-&#47784;&#45944;&#50640;-&#51201;&#50857;&#49884;&#53020;-&#48372;&#50520;&#45796;.-&#44536;&#47084;&#45208;-&#50724;&#55176;&#47140;-SoftMax-&#47784;&#45944;-&#54616;&#45208;&#47564;&#51012;-&#49324;&#50857;&#54620;-&#44163;&#48372;&#45796;-&#49457;&#45733;&#51060;-&#46504;&#50612;&#51648;&#45716;-&#44208;&#44284;&#47932;&#51012;-&#48372;&#50668;&#51500;&#45796;.">SoftMax &#47784;&#45944;&#51012; &#48372;&#50756;&#54616;&#44592; &#50948;&#54644; Keras&#47484; &#53685;&#54644; &#44256;&#49549; &#44228;&#49328;&#51012; &#54616;&#44256; Relu Activation Function&#51012; &#49324;&#50857;&#54644; hidden layer &#44050;&#51012; &#44396;&#54644; SoftMax &#47784;&#45944;&#50640; &#51201;&#50857;&#49884;&#53020; &#48372;&#50520;&#45796;. &#44536;&#47084;&#45208; &#50724;&#55176;&#47140; SoftMax &#47784;&#45944; &#54616;&#45208;&#47564;&#51012; &#49324;&#50857;&#54620; &#44163;&#48372;&#45796; &#49457;&#45733;&#51060; &#46504;&#50612;&#51648;&#45716; &#44208;&#44284;&#47932;&#51012; &#48372;&#50668;&#51500;&#45796;.<a class="anchor-link" href="#SoftMax-&#47784;&#45944;&#51012;-&#48372;&#50756;&#54616;&#44592;-&#50948;&#54644;-Keras&#47484;-&#53685;&#54644;-&#44256;&#49549;-&#44228;&#49328;&#51012;-&#54616;&#44256;-Relu-Activation-Function&#51012;-&#49324;&#50857;&#54644;-hidden-layer-&#44050;&#51012;-&#44396;&#54644;-SoftMax-&#47784;&#45944;&#50640;-&#51201;&#50857;&#49884;&#53020;-&#48372;&#50520;&#45796;.-&#44536;&#47084;&#45208;-&#50724;&#55176;&#47140;-SoftMax-&#47784;&#45944;-&#54616;&#45208;&#47564;&#51012;-&#49324;&#50857;&#54620;-&#44163;&#48372;&#45796;-&#49457;&#45733;&#51060;-&#46504;&#50612;&#51648;&#45716;-&#44208;&#44284;&#47932;&#51012;-&#48372;&#50668;&#51500;&#45796;.">&#182;</a></h3><h3 id="&#44033;-&#47784;&#45944;&#51032;-Parameter&#46308;&#51012;-Grid-Search&#47484;-&#53685;&#54644;-&#51312;&#51208;&#54644;&#44032;&#47728;-&#52572;&#51201;-&#47784;&#45944;&#51012;-&#52286;&#50500;-&#50696;&#52769;&#51012;-&#54644;&#48372;&#50520;&#51648;&#47564;-&#45936;&#51060;&#53552;&#44032;-&#52509;-1000&#44060;-&#51221;&#46020;-&#48150;&#50640;-&#46104;&#51648;-&#50506;&#44592;&#50640;-&#45908;-&#51060;&#49345;&#51032;-&#49457;&#45733;&#51012;-&#45132;&#50612;&#50732;&#47540;-&#49688;-&#50630;&#50632;&#45796;.-Parameter&#46308;&#51012;-&#51312;&#44552;-&#45908;-&#49464;&#48128;&#54616;&#44172;-&#49688;&#51221;&#54620;&#45796;&#47732;-&#50557;&#44036;&#51032;-&#49345;&#49849;-&#54952;&#44284;&#45716;-&#48380;-&#49688;-&#51080;&#51012;-&#44163;&#51004;&#47196;-&#50696;&#49345;&#46104;&#45208;-&#44536;-&#52264;&#51060;&#44032;-&#48120;&#48120;&#54624;-&#44163;&#51004;&#47196;-&#48372;&#51060;&#44592;&#50640;-&#45908;-&#51060;&#49345;-&#49884;&#46020;&#54616;&#51648;-&#50506;&#50520;&#45796;.-&#45908;-&#47566;&#51008;-&#45936;&#51060;&#53552;-&#49483;&#51012;-&#51060;&#50857;&#54644;-&#47784;&#45944;&#47553;&#51012;-&#54644;&#48376;&#45796;&#47732;-&#48516;&#47749;-&#45908;-&#45458;&#51008;-&#49457;&#45733;&#51012;-&#48372;&#51068;-&#44163;&#51060;&#46972;&#44256;-&#49373;&#44033;&#46108;&#45796;.">&#44033; &#47784;&#45944;&#51032; Parameter&#46308;&#51012; Grid Search&#47484; &#53685;&#54644; &#51312;&#51208;&#54644;&#44032;&#47728; &#52572;&#51201; &#47784;&#45944;&#51012; &#52286;&#50500; &#50696;&#52769;&#51012; &#54644;&#48372;&#50520;&#51648;&#47564; &#45936;&#51060;&#53552;&#44032; &#52509; 1000&#44060; &#51221;&#46020; &#48150;&#50640; &#46104;&#51648; &#50506;&#44592;&#50640; &#45908; &#51060;&#49345;&#51032; &#49457;&#45733;&#51012; &#45132;&#50612;&#50732;&#47540; &#49688; &#50630;&#50632;&#45796;. Parameter&#46308;&#51012; &#51312;&#44552; &#45908; &#49464;&#48128;&#54616;&#44172; &#49688;&#51221;&#54620;&#45796;&#47732; &#50557;&#44036;&#51032; &#49345;&#49849; &#54952;&#44284;&#45716; &#48380; &#49688; &#51080;&#51012; &#44163;&#51004;&#47196; &#50696;&#49345;&#46104;&#45208; &#44536; &#52264;&#51060;&#44032; &#48120;&#48120;&#54624; &#44163;&#51004;&#47196; &#48372;&#51060;&#44592;&#50640; &#45908; &#51060;&#49345; &#49884;&#46020;&#54616;&#51648; &#50506;&#50520;&#45796;. &#45908; &#47566;&#51008; &#45936;&#51060;&#53552; &#49483;&#51012; &#51060;&#50857;&#54644; &#47784;&#45944;&#47553;&#51012; &#54644;&#48376;&#45796;&#47732; &#48516;&#47749; &#45908; &#45458;&#51008; &#49457;&#45733;&#51012; &#48372;&#51068; &#44163;&#51060;&#46972;&#44256; &#49373;&#44033;&#46108;&#45796;.<a class="anchor-link" href="#&#44033;-&#47784;&#45944;&#51032;-Parameter&#46308;&#51012;-Grid-Search&#47484;-&#53685;&#54644;-&#51312;&#51208;&#54644;&#44032;&#47728;-&#52572;&#51201;-&#47784;&#45944;&#51012;-&#52286;&#50500;-&#50696;&#52769;&#51012;-&#54644;&#48372;&#50520;&#51648;&#47564;-&#45936;&#51060;&#53552;&#44032;-&#52509;-1000&#44060;-&#51221;&#46020;-&#48150;&#50640;-&#46104;&#51648;-&#50506;&#44592;&#50640;-&#45908;-&#51060;&#49345;&#51032;-&#49457;&#45733;&#51012;-&#45132;&#50612;&#50732;&#47540;-&#49688;-&#50630;&#50632;&#45796;.-Parameter&#46308;&#51012;-&#51312;&#44552;-&#45908;-&#49464;&#48128;&#54616;&#44172;-&#49688;&#51221;&#54620;&#45796;&#47732;-&#50557;&#44036;&#51032;-&#49345;&#49849;-&#54952;&#44284;&#45716;-&#48380;-&#49688;-&#51080;&#51012;-&#44163;&#51004;&#47196;-&#50696;&#49345;&#46104;&#45208;-&#44536;-&#52264;&#51060;&#44032;-&#48120;&#48120;&#54624;-&#44163;&#51004;&#47196;-&#48372;&#51060;&#44592;&#50640;-&#45908;-&#51060;&#49345;-&#49884;&#46020;&#54616;&#51648;-&#50506;&#50520;&#45796;.-&#45908;-&#47566;&#51008;-&#45936;&#51060;&#53552;-&#49483;&#51012;-&#51060;&#50857;&#54644;-&#47784;&#45944;&#47553;&#51012;-&#54644;&#48376;&#45796;&#47732;-&#48516;&#47749;-&#45908;-&#45458;&#51008;-&#49457;&#45733;&#51012;-&#48372;&#51068;-&#44163;&#51060;&#46972;&#44256;-&#49373;&#44033;&#46108;&#45796;.">&#182;</a></h3><h2 id="&#44208;&#44284;-&#48708;&#44368;">&#44208;&#44284; &#48708;&#44368;<a class="anchor-link" href="#&#44208;&#44284;-&#48708;&#44368;">&#182;</a></h2><h3 id="&#49892;&#51228;-&#45936;&#51060;&#53552;&#50752;-&#50696;&#52769;-&#44050;&#51012;-&#48708;&#44368;&#54616;&#47140;&#47732;-&#50948;&#51032;-&#47784;&#45944;&#47553;&#47560;&#45796;-&#47560;&#51648;&#47561;&#50640;-test-set&#50640;-&#51032;&#54620;-&#50696;&#52769;&#44050;&#51012;-&#48977;&#50500;&#45480;&#45796;.">&#49892;&#51228; &#45936;&#51060;&#53552;&#50752; &#50696;&#52769; &#44050;&#51012; &#48708;&#44368;&#54616;&#47140;&#47732; &#50948;&#51032; &#47784;&#45944;&#47553;&#47560;&#45796; &#47560;&#51648;&#47561;&#50640; test set&#50640; &#51032;&#54620; &#50696;&#52769;&#44050;&#51012; &#48977;&#50500;&#45480;&#45796;.<a class="anchor-link" href="#&#49892;&#51228;-&#45936;&#51060;&#53552;&#50752;-&#50696;&#52769;-&#44050;&#51012;-&#48708;&#44368;&#54616;&#47140;&#47732;-&#50948;&#51032;-&#47784;&#45944;&#47553;&#47560;&#45796;-&#47560;&#51648;&#47561;&#50640;-test-set&#50640;-&#51032;&#54620;-&#50696;&#52769;&#44050;&#51012;-&#48977;&#50500;&#45480;&#45796;.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
