{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus241 datasets: Wine quality data example\n",
    "* Source:  ML repository\n",
    "* Wine quality by experts (0 - 10)\n",
    "* Predictors:  Wine chemical composition\n",
    "* This can be done as either classification, or regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Import lots of tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixedAcidity  volatileAcidity  citricAcid  residualSugar  chlorides  \\\n",
      "0           7.4             0.70        0.00            1.9      0.076   \n",
      "1           7.8             0.88        0.00            2.6      0.098   \n",
      "2           7.8             0.76        0.04            2.3      0.092   \n",
      "3          11.2             0.28        0.56            1.9      0.075   \n",
      "4           7.4             0.70        0.00            1.9      0.076   \n",
      "\n",
      "   freeSulfurDioxide  totalSulfurDioxide  density    pH  sulphates  alcohol  \\\n",
      "0               11.0                34.0   0.9978  3.51       0.56      9.4   \n",
      "1               25.0                67.0   0.9968  3.20       0.68      9.8   \n",
      "2               15.0                54.0   0.9970  3.26       0.65      9.8   \n",
      "3               17.0                60.0   0.9980  3.16       0.58      9.8   \n",
      "4               11.0                34.0   0.9978  3.51       0.56      9.4   \n",
      "\n",
      "   quality  \n",
      "0        5  \n",
      "1        5  \n",
      "2        5  \n",
      "3        6  \n",
      "4        5  \n",
      "(1599, 11)\n",
      "['fixedAcidity', 'volatileAcidity', 'citricAcid', 'residualSugar', 'chlorides', 'freeSulfurDioxide', 'totalSulfurDioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# load default data set\n",
    "wineall = pd.read_csv(\"winequality-red.csv\")\n",
    "# print(wineall.shape)\n",
    "print(wineall.head())\n",
    "X = wineall.values[:,0:11].copy()\n",
    "y = wineall.quality.values\n",
    "print(X.shape)\n",
    "print([x for x in wineall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(wineall.iloc[:10, :13])\n",
    "size = int(len(wineall)* 0.8)\n",
    "Train_X = wineall.iloc[:size, :11]\n",
    "Test_X = wineall.iloc[size:, :11]\n",
    "Train_Y = wineall.iloc[:size, 11]\n",
    "Test_Y = wineall.iloc[size:, 11]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.679\n",
      "Accuracy on test set: 0.581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "tree.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(Train_X, Train_Y)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(Test_X, Test_Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Lasso & Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Train:  0.3693102258825097\n",
      "Ridge Test:  0.28741462976163346\n",
      "Lasso Train:  0.2788392551518688\n",
      "Lasso Test:  0.1156891074875579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# ridge\n",
    "ridge = Ridge(alpha=0.05)\n",
    "ridge.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"Ridge Train: \", ridge.score(Train_X,Train_Y))\n",
    "print(\"Ridge Test: \", ridge.score(Test_X,Test_Y))\n",
    "\n",
    "# lasso\n",
    "lasso = Lasso(alpha=0.05)\n",
    "lasso.fit(Train_X, Train_Y)\n",
    "print(\"Lasso Train: \", lasso.score(Train_X,Train_Y))\n",
    "print(\"Lasso Test: \", lasso.score(Test_X, Test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Train accuracy: 0.5254104769351056\n",
      "Linear SVC Test accuracy: 0.521875\n",
      "fraction y = 1: 5.6360225140712945\n",
      "Linear SVC Train accuracy: 0.5136825645035183\n",
      "Linear SVC Test accuracy: 0.49375\n",
      "fraction y = 1: 5.6360225140712945\n",
      "Linear SVC Train accuracy: 0.49726348709929635\n",
      "Linear SVC Test accuracy: 0.425\n",
      "fraction y = 1: 5.6360225140712945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# LinearSVCMod = LinearSVC(C=10000.)\n",
    "LinearSVCMod = LinearSVC(C=10., random_state=2, max_iter=10000)\n",
    "LinearSVCMod.fit(Train_X,Train_Y)\n",
    "print('Linear SVC Train accuracy:', LinearSVCMod.score(Train_X,Train_Y))\n",
    "print('Linear SVC Test accuracy:', LinearSVCMod.score(Test_X,Test_Y))\n",
    "print('fraction y = 1:', np.mean(y))\n",
    "\n",
    "LinearSVCMod = LinearSVC(C=10., random_state=4, max_iter=10000)\n",
    "LinearSVCMod.fit(Train_X,Train_Y)\n",
    "print('Linear SVC Train accuracy:', LinearSVCMod.score(Train_X,Train_Y))\n",
    "print('Linear SVC Test accuracy:', LinearSVCMod.score(Test_X,Test_Y))\n",
    "print('fraction y = 1:', np.mean(y))\n",
    "\n",
    "LinearSVCMod = LinearSVC(C=10., random_state=6, max_iter=10000)\n",
    "LinearSVCMod.fit(Train_X,Train_Y)\n",
    "print('Linear SVC Train accuracy:', LinearSVCMod.score(Train_X,Train_Y))\n",
    "print('Linear SVC Test accuracy:', LinearSVCMod.score(Test_X,Test_Y))\n",
    "print('fraction y = 1:', np.mean(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 monte-carlo Comparing two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Mean Score of Training Set:  0.6325000000000001\n",
      "KNN Mean Score: 0.508\n",
      "Difference of Training Set:  0.12450000000000006\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(n_estimators=100,max_depth=5,learning_rate=0.01)\n",
    "cvf = ShuffleSplit(n_splits=25, test_size=0.25)\n",
    "scores1 = cross_val_score(gbrt, Train_X, Train_Y, cv=cvf)\n",
    "print(\"Gradient Boosting Mean Score of Training Set: \", np.mean(scores1))\n",
    "\n",
    "# KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "cvf = ShuffleSplit(n_splits=25, test_size=0.25)\n",
    "scores2 = cross_val_score(knn, Train_X, Train_Y, cv=cvf)\n",
    "print(\"KNN Mean Score:\", np.mean(scores2))\n",
    "\n",
    "print(\"Difference of Training Set: \", abs(np.mean(scores1) - np.mean(scores2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Random Forest vs Single Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  0.61425\n",
      "Single Tree: 0.581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "forest = RandomForestClassifier(n_estimators=20,max_features=4, max_depth=5)\n",
    "cvf = ShuffleSplit(n_splits=25, test_size=0.25)\n",
    "scores = cross_val_score(forest, Train_X, Train_Y, cv=cvf)\n",
    "print(\"Random Forest: \", np.mean(scores))\n",
    "\n",
    "\n",
    "# Single Tree: Decision Tree \n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "tree.fit(Train_X, Train_Y)\n",
    "print(\"Single Tree: {:.3f}\".format(tree.score(Test_X, Test_Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Two ML Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.880\n",
      "Accuracy on test set: 0.447\n",
      "Accuracy on training set:  0.5684128225175918\n",
      "Accuracy on test set:  0.6\n"
     ]
    }
   ],
   "source": [
    "# SVM with kernal\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=10,kernel='rbf',gamma=0.05)\n",
    "svc.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svc.score(Train_X, Train_Y)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svc.score(Test_X, Test_Y)))\n",
    "\n",
    "# Naive Bayes With Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB(priors=None)\n",
    "trainFit = gnb.fit(Train_X, Train_Y)\n",
    "print(\"Accuracy on training set: \", trainFit.score(Train_X, Train_Y))\n",
    "print(\"Accuracy on test set: \", trainFit.score(Test_X, Test_Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters C=1000 + gamma=1 : 0.487\n",
      "Parameters C=10000 + gamma=1 : 0.487\n",
      "Parameters C=1000 + gamma=0.1 : 0.463\n",
      "Parameters C=1000 + gamma=0.01 : 0.444\n"
     ]
    }
   ],
   "source": [
    "# C=1000\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=1000,kernel='rbf',gamma=1.)\n",
    "svc.fit(Train_X, Train_Y)\n",
    "\n",
    "# print(\"Accuracy on training set: {:.3f}\".format(svc.score(Train_X, Train_Y)))\n",
    "print(\"Parameters C=1000 + gamma=1 : {:.3f}\".format(svc.score(Test_X, Test_Y)))\n",
    "\n",
    "# C=10000\n",
    "svc = SVC(C=10000,kernel='rbf',gamma=1.)\n",
    "svc.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"Parameters C=10000 + gamma=1 : {:.3f}\".format(svc.score(Test_X, Test_Y)))\n",
    "\n",
    "# SVM with kernal 3 \n",
    "svc = SVC(C=1000,kernel='rbf',gamma=0.1)\n",
    "svc.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"Parameters C=1000 + gamma=0.1 : {:.3f}\".format(svc.score(Test_X, Test_Y)))\n",
    "\n",
    "# SVM with kernal 3 \n",
    "svc = SVC(C=1000,kernel='rbf',gamma=0.01)\n",
    "svc.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"Parameters C=1000 + gamma=0.01 : {:.3f}\".format(svc.score(Test_X, Test_Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxintang/py3_venv/py3_env/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 1 training set: 0.62\n",
      "MLP 1 test set: 0.57\n",
      "MLP 2 training set: 0.59\n",
      "MLP 2 test set: 0.52\n",
      "MLP 3 training set: 0.60\n",
      "MLP 3 test set: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinxintang/py3_venv/py3_env/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 4 training set: 0.61\n",
      "MLP 4 test set: 0.53\n",
      "MLP 5 training set: 0.60\n",
      "MLP 5 test set: 0.56\n"
     ]
    }
   ],
   "source": [
    "# MLP 1 \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP 1 training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP 1 test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# MLP 2 \n",
    "mlp = MLPClassifier(random_state=20)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP 2 training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP 2 test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# MLP 3\n",
    "mlp = MLPClassifier(random_state=30)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP 3 training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP 3 test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# MLP 4\n",
    "mlp = MLPClassifier(random_state=40)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP 4 training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP 4 test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# MLP 5 \n",
    "mlp = MLPClassifier(random_state=50)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP 5 training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP 5 test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Width & Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP training set: 0.59\n",
      "MLP test set: 0.57\n",
      "MLP training set: 0.58\n",
      "MLP test set: 0.56\n",
      "MLP training set: 0.61\n",
      "MLP test set: 0.58\n",
      "MLP training set: 0.61\n",
      "MLP test set: 0.59\n",
      "MLP training set: 0.61\n",
      "MLP test set: 0.57\n",
      "MLP training set: 0.66\n",
      "MLP test set: 0.58\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "mlp = MLPClassifier(max_iter=1000,hidden_layer_sizes=[20])\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "# 2\n",
    "mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=[40])\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# 3\n",
    "mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=[60])\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# 4\n",
    "mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=[20, 20])\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# 5\n",
    "mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=[20, 20, 20])\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "\n",
    "# 6\n",
    "mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=[20, 20, 20, 20])\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP training set: 0.97\n",
      "MLP test set: 0.50\n",
      "MLP training set: 0.90\n",
      "MLP test set: 0.49\n",
      "MLP training set: 0.82\n",
      "MLP test set: 0.57\n",
      "MLP training set: 0.97\n",
      "MLP test set: 0.50\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='tanh',\n",
    "                    random_state=10, hidden_layer_sizes=[40, 40, 40, 40], \n",
    "                    max_iter=10000, alpha=0.001)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "# 2\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='tanh',\n",
    "                    random_state=20, hidden_layer_sizes=[40, 40, 40, 40], \n",
    "                    max_iter=10000, alpha=0.001)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "# 3\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='tanh',\n",
    "                    random_state=30, hidden_layer_sizes=[40, 40, 40, 40], \n",
    "                    max_iter=10000, alpha=0.001)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))\n",
    "\n",
    "# 4\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='tanh',\n",
    "                    random_state=40, hidden_layer_sizes=[40, 40, 40, 40], \n",
    "                    max_iter=10000, alpha=0.001)\n",
    "mlp.fit(Train_X, Train_Y)\n",
    "\n",
    "print(\"MLP training set: {:.2f}\".format(mlp.score(Train_X, Train_Y)))\n",
    "print(\"MLP test set: {:.2f}\".format(mlp.score(Test_X, Test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
